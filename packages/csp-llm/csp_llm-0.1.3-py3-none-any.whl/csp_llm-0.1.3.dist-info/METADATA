Metadata-Version: 2.4
Name: csp_llm
Version: 0.1.3
Summary: Python app using llm via MCP for modeling and solving a csp problem in pycsp3
Author-email: Alain Kemgue <kemgue@cril.fr>
Maintainer-email: Alain Kemgue <kemgue@cril.fr>
License: MIT
Project-URL: Homepage, https://github.com/kemgue/csp_llm
Project-URL: Repository, https://github.com/kemgue/csp_llm
Project-URL: Bug Tracker, https://github.com/kemgue/csp_llm/issues
Keywords: pycsp3,csp,ai,llm,openai,anthropic
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: streamlit>=1.28.0
Requires-Dist: streamlit-ace>=0.1.1
Requires-Dist: pycsp3>=2.3.0
Requires-Dist: openai>=1.0.0
Requires-Dist: anthropic>=0.7.0
Requires-Dist: python-dotenv>=1.0.1
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=5.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.0.0; extra == "docs"
Dynamic: license-file

## ğŸ’¡ A propos de csp-llm

csp-llm est un paquet python fonctionnant sous forme d'agent IA pour permettre la gÃ©nÃ©ration et l'exÃ©cution automatique du code [PyCSP3](https://github.com/xcsp3team/pycsp3/) d'un problÃ¨me de contrainte. 

Il propose une interface web utilisateur interactive et paramÃ©trable, qui permet de saisir ou d'importer la description d'un problÃ¨me de contrainte en langage naturel. La description du problÃ¨me est alors envoyÃ©e Ã  un modÃ¨le LLM prÃ©-configurÃ© qui va gÃ©nÃ©rer et afficher le code Ã  l'utilisateur. L'utilisateur peut soit demander Ã  ce que le code soit directement exÃ©cutÃ© ou alors il peut apporter des modifications au code gÃ©nÃ©rÃ© avant de demander son exÃ©cution. 


L'application intÃ¨gre les technologies modernes permettant de faire fonctionner tout type de modÃ¨le LLM (modÃ¨les LLM dÃ©ployÃ©s au sein du CRIL, les modÃ¨les d'Anthropic, les modÃ¨les d'OpenAI, les modÃ¨les de Google, etc.)

Une fois installÃ©e, l'application propose quelques exemples de problÃ¨mes de contraintes avec lesquels l'utilisateur peut s'amuser Ã  faire des tests.


**NB** : *Il peut arriver que le code gÃ©nÃ©rÃ© contienne des erreurs, la possibilitÃ© est alors donnÃ©e Ã  l'utilisateur via l'interface de les corriger.*

## ğŸ›‘ Exigences

- Fonctionner sur les plateforme Linux et Mac (testÃ© sur bash linux et zsh mac)
- Avoir un accÃ¨s Ã  une plateforme de LLM. Les modÃ¨les de LLM du CRIL sont proposÃ©es par dÃ©faut. Les personnes qui ont un compte sur le LAN peuvent utiliser leur clÃ© API. Pour plus d'informations, prendre contact avec Alain Kemgue( kemgue@cril.fr )
- Avoir installÃ© une version de python3 (**3.10** ou plus)
- Avoir installÃ© une version de java pour faire fonctionner pycsp3 (java 8 ou plus)

## ğŸ“¦ Installation

Il est conseillÃ© d'installer l'application dans un environnement virtuel python.

### Installation de l'environnement virtuel

```bash
python3 -m venv venv
source venv/bin/activate

```

### Installation du paquet csp-llm qui se trouve sur PyPi

```bash
pip install csp_llm

```

### Lancer l'application

```bash
(venv) ordi@alain% launch-csp-llm     
ğŸš€ Launching the application...
ğŸ’¡ Application dependencies
missing ScriptRunContext! This warning can be ignored when running in bare mode.
âœ… anthropic 0.55.0
âœ… openai 1.92.2
âœ… streamlit 1.46.1
âœ… streamlit_ace 0.1.1
âœ… dotenv
âœ… pycsp3 2.5.1
âœ… Java 21.0.7 detected (>= 8)
ğŸŒ Application available at: http://localhost:8501
ğŸ’¡ Press Ctrl+C to stop
--------------------------------------------------

  You can now view your Streamlit app in your browser.

  URL: http://localhost:8501

**************************************************
```

L'application est alors disponible sur le lien http://localhost:8501

Vous pouvez changer de port et d'hÃ´te en passant des paramÃ¨tres au script de lancement.

```bash

(venv) ordi@alain% launch-csp-llm --help              
usage: launch-csp-llm [-h] [--host HOST] [--port PORT] [-ev]

Launch the application

options:
  -h, --help   show this help message and exit
  --host HOST
  --port PORT
  -ev
```

Exemple de lancement sur le port 3000 et l'hÃ´te 0.0.0.0( rend l'application accessible sur tout le rÃ©seau )

```bash
(venv) ordi@alain% launch-csp-llm --port 3000 --host 0.0.0.0
ğŸš€ Launching the application...
ğŸ’¡ Application dependencies
âœ… anthropic 0.55.0
âœ… openai 1.92.2
âœ… streamlit 1.46.1
âœ… streamlit_ace 0.1.1
âœ… dotenv
âœ… pycsp3 2.5.1
âœ… Java 21.0.7 detected (>= 8)
ğŸŒ Application available at: http://0.0.0.0:3000
ğŸ’¡ Press Ctrl+C to stop
--------------------------------------------------

  You can now view your Streamlit app in your browser.

  URL: http://0.0.0.0:3000

**************************************************

```
