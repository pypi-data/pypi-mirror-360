# keynet-train

MLflowì™€ í†µí•©ëœ ëª¨ë¸ í›ˆë ¨ ìœ í‹¸ë¦¬í‹°

## ì„¤ì¹˜

```bash
pip install keynet-train
```

## ì£¼ìš” ê¸°ëŠ¥

### ğŸš€ ìë™í™”ëœ í›ˆë ¨ API

- ëª¨ë¸ì—ì„œ ìë™ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ 
- PyTorch ëª¨ë¸ì„ ONNXë¡œ ìë™ ë³€í™˜
- MLflowì— ìë™ ë¡œê¹… ë° ë²„ì „ ê´€ë¦¬

### ğŸ“Š ì§€ì› í”„ë ˆì„ì›Œí¬

- PyTorch (TorchScript, ONNX ë³€í™˜)
- ONNX (ë„¤ì´í‹°ë¸Œ ì§€ì›)
- ë‹¤ì¤‘ ì…ë ¥/ì¶œë ¥ ëª¨ë¸ ì§€ì›

### ğŸ”§ MLflow í†µí•©

- ì‹¤í—˜ ìë™ ìƒì„± ë° ê´€ë¦¬
- ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ìë™ ì €ì¥
- ë©”íŠ¸ë¦­ ë° íŒŒë¼ë¯¸í„° ì¶”ì 

## ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from keynet_train import trace
import torch

# ğŸ¯ decoratorì— ìƒ˜í”Œ ì…ë ¥ì„ ì œê³µí•˜ê³ , í•¨ìˆ˜ì—ì„œëŠ” ëª¨ë¸ë§Œ ë°˜í™˜
@trace("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    model = MyModel()

    # í•™ìŠµ ì½”ë“œ...
    for epoch in range(10):
        # ì‹¤ì œ í•™ìŠµ ë¡œì§
        pass

    return model  # âš ï¸ ë°˜ë“œì‹œ torch.nn.Moduleë§Œ ë°˜í™˜
```

## ğŸ“‹ ë°˜í™˜ê°’ ì œì•½ì‚¬í•­

**`@trace` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” ë°˜ë“œì‹œ `torch.nn.Module` ê°ì²´ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.**

### âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•

```python
@trace("experiment", torch.randn(1, 784))
def train_mnist():
    model = torch.nn.Sequential(
        torch.nn.Linear(784, 128),
        torch.nn.ReLU(),
        torch.nn.Linear(128, 10)
    )

    # í›ˆë ¨ ë¡œì§
    optimizer = torch.optim.Adam(model.parameters())
    for epoch in range(100):
        # ì‹¤ì œ í›ˆë ¨...
        loss = train_one_epoch(model, optimizer, train_loader)

        # ë©”íŠ¸ë¦­ì€ mlflow.log_* í•¨ìˆ˜ë¡œ ê¸°ë¡
        mlflow.log_metric("train_loss", loss, step=epoch)

    return model  # ğŸ¯ ëª¨ë¸ë§Œ ë°˜í™˜!
```

### âŒ ì˜ëª»ëœ ì‚¬ìš©ë²•ë“¤

```python
@trace("experiment", torch.randn(1, 784))
def wrong_usage1():
    model = MyModel()
    loss = train(model)
    return model, loss  # âŒ íŠœí”Œ ë°˜í™˜ ë¶ˆê°€

@trace("experiment", torch.randn(1, 784))
def wrong_usage2():
    model = MyModel()
    train(model)
    return {
        "model": model,
        "accuracy": 0.95
    }  # âŒ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ ë¶ˆê°€

@trace("experiment", torch.randn(1, 784))
def wrong_usage3():
    model = MyModel()
    train(model)
    return "model_saved.pth"  # âŒ ë¬¸ìì—´ ë°˜í™˜ ë¶ˆê°€
```

### ğŸ’¡ ì™œ ì´ëŸ° ì œì•½ì´ ìˆë‚˜ìš”?

`@trace` ë°ì½”ë ˆì´í„°ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìë™í™”í•©ë‹ˆë‹¤:

1. **MLflow ëª¨ë¸ ë¡œê¹…**: `mlflow.pytorch.log_model(pytorch_model=model, ...)`
2. **ONNX ë³€í™˜**: `torch.onnx.export(model, ...)`
3. **Triton ë°°í¬**: ìë™ `config.pbtxt` ìƒì„±

ì´ ëª¨ë“  ì‘ì—…ì´ `torch.nn.Module` ê°ì²´ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ, ë‹¤ë¥¸ íƒ€ì…ì˜ ë°˜í™˜ê°’ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ğŸ“ ONNX ëª¨ë¸ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª… ê·œì¹™

`@trace` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ë•Œ ìƒì„±ë˜ëŠ” ONNX ëª¨ë¸ì˜ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª…ì€ ë‹¤ìŒê³¼ ê°™ì´ ê²°ì •ë©ë‹ˆë‹¤:

### ì…ë ¥ íŒŒë¼ë¯¸í„° (Inputs)

```python
# âœ… Dictionary í˜•íƒœë¡œ ì…ë ¥í•˜ë©´ í‚¤ ì´ë¦„ì„ ì‚¬ìš© (ê¶Œì¥)
@trace("my_experiment", {"image": torch.randn(1, 3, 224, 224), "label": torch.randn(1, 10)})
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "image", "label"
    ...

# âœ… ë‹¨ì¼ í…ì„œë¡œ ì…ë ¥í•˜ë©´ ìë™ ìƒì„±
@trace("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "input_0"
    ...
```

### ì¶œë ¥ íŒŒë¼ë¯¸í„° (Outputs)

```python
# ì¶œë ¥ëª…ì€ í•­ìƒ ìë™ ìƒì„±ë©ë‹ˆë‹¤
@trace("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    # ë‹¨ì¼ ì¶œë ¥: "output_0"
    return model

# ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ê²½ìš°
def train_multi_output_model():
    class MultiOutputModel(torch.nn.Module):
        def forward(self, x):
            return output1, output2  # íŠœí”Œ ë°˜í™˜

    # ì‹¤ì œë¡œëŠ” MLflowê°€ íŠœí”Œì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ì²˜ë¦¬í•˜ì—¬ "output_0"ë§Œ ìƒì„±ë¨
    return model
```

### âš ï¸ ì¤‘ìš”í•œ ì œí•œì‚¬í•­

- **ì§€ì›ë˜ëŠ” ì…ë ¥ í˜•íƒœ**: `torch.Tensor` ë˜ëŠ” `Dict[str, torch.Tensor]`ë§Œ ì§€ì›
- **íŠœí”Œ ì…ë ¥ ë¯¸ì§€ì›**: `(tensor1, tensor2)` í˜•íƒœì˜ íŠœí”Œ ì…ë ¥ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŒ
- **ë‹¤ì¤‘ ì¶œë ¥ ì²˜ë¦¬**: PyTorch ëª¨ë¸ì´ íŠœí”Œë¡œ ë‹¤ì¤‘ ì¶œë ¥ì„ ë°˜í™˜í•´ë„ MLflow signature ì¶”ë¡ ì— ì˜í•´ `output_0` í•˜ë‚˜ë¡œ ì²˜ë¦¬ë¨
- **MLflow ì˜ì¡´ì„±**: íŒŒë¼ë¯¸í„°ëª… ìƒì„±ì€ MLflowì˜ ìë™ signature ì¶”ë¡ ì— ì˜ì¡´í•˜ë¯€ë¡œ ì¼ë¶€ ì œí•œì‚¬í•­ì´ ìˆìŒ

### ğŸ’¡ ê¶Œì¥ì‚¬í•­

```python
# ğŸ¯ ìµœì ì˜ ì‚¬ìš©ë²•: Dictionary ì…ë ¥ìœ¼ë¡œ ëª…ì‹œì ì¸ ì´ë¦„ ì§€ì •
@trace("experiment", {
    "image": torch.randn(1, 3, 224, 224),
    "mask": torch.randn(1, 1, 224, 224)
})
def train_model():
    # ìƒì„±ë˜ëŠ” config.pbtxtì—ì„œ ëª…í™•í•œ ì…ë ¥ëª… í™•ì¸ ê°€ëŠ¥:
    # input { name: "image", data_type: TYPE_FP32, dims: [-1, 3, 224, 224] }
    # input { name: "mask", data_type: TYPE_FP32, dims: [-1, 1, 224, 224] }
    return model
```

> **Note:** ìƒì„±ëœ ONNX ëª¨ë¸ì€ Triton Inference Server ë°°í¬ ì‹œ ìë™ìœ¼ë¡œ `config.pbtxt` íŒŒì¼ì´ ìƒì„±ë˜ì–´ ì •í™•í•œ ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë‹¤ì¤‘ ì…ë ¥ ëª¨ë¸

```python
@trace("multi_input_exp", {
    "image": torch.randn(1, 3, 224, 224),
    "mask": torch.randn(1, 1, 224, 224)
})
def train_multi_input():
    model = MultiInputModel()

    # ëª¨ë¸ì´ ì—¬ëŸ¬ ì…ë ¥ì„ ë°›ëŠ” ê²½ìš°
    class MultiInputModel(torch.nn.Module):
        def forward(self, image, mask):
            # imageì™€ maskë¥¼ í•¨ê»˜ ì²˜ë¦¬
            combined = torch.cat([image, mask], dim=1)
            return self.classifier(combined)

    # í›ˆë ¨ ë¡œì§...
    return model
```

## ë¼ì´ì„ ìŠ¤

MIT License
