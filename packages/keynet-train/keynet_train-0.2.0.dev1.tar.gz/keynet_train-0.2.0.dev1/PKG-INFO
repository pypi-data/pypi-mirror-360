Metadata-Version: 2.4
Name: keynet-train
Version: 0.2.0.dev1
Summary: Training utilities for keynet - MLflow and model training support
Project-URL: Homepage, https://github.com/WIM-Corporation/keynet
Project-URL: Bug Tracker, https://github.com/WIM-Corporation/keynet/issues
Author-email: hbjs <hbjs97@naver.com>
License: MIT
Keywords: keynet,machine-learning,mlflow,training
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.9
Requires-Dist: keynet-core
Requires-Dist: mlflow==3.1.1
Requires-Dist: numpy<2.0,>=1.25.0
Requires-Dist: onnx
Requires-Dist: onnxruntime<1.18.0,>=1.17.0
Requires-Dist: pika>=1.3.2
Requires-Dist: torch
Description-Content-Type: text/markdown

# keynet-train

MLflowì™€ í†µí•©ëœ ëª¨ë¸ í›ˆë ¨ ìœ í‹¸ë¦¬í‹°

## ì„¤ì¹˜

```bash
pip install keynet-train
```

## ì£¼ìš” ê¸°ëŠ¥

### ğŸš€ ìë™í™”ëœ í›ˆë ¨ API

- ëª¨ë¸ì—ì„œ ìë™ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¶”ë¡ 
- PyTorch ëª¨ë¸ì„ ONNXë¡œ ìë™ ë³€í™˜
- MLflowì— ìë™ ë¡œê¹… ë° ë²„ì „ ê´€ë¦¬
- í”„ë ˆì„ì›Œí¬ ë…ë¦½ì ì¸ ONNX ëª¨ë¸ ë¡œê¹… ì§€ì›

### ğŸ“Š ì§€ì› í”„ë ˆì„ì›Œí¬

#### PyTorch ë„¤ì´í‹°ë¸Œ ì§€ì›
- `@trace_pytorch` ë°ì½”ë ˆì´í„°ë¡œ ìë™ ONNX ë³€í™˜ ë° ë°°í¬
- í•™ìŠµë¶€í„° ë°°í¬ê¹Œì§€ ì™„ì „ ìë™í™”

#### í”„ë ˆì„ì›Œí¬ ë…ë¦½ì  ì§€ì› 
- `log_onnx_model` í•¨ìˆ˜ë¡œ **ëª¨ë“  í”„ë ˆì„ì›Œí¬**ì˜ ONNX ëª¨ë¸ ë°°í¬
- TensorFlow, JAX, MXNet, PaddlePaddle ë“± ONNX ë‚´ë³´ë‚´ê¸°ë¥¼ ì§€ì›í•˜ëŠ” ëª¨ë“  í”„ë ˆì„ì›Œí¬
- PyTorch ì™¸ í”„ë ˆì„ì›Œí¬ ì‚¬ìš©ìë¥¼ ìœ„í•œ í†µí•© ë°°í¬ íŒŒì´í”„ë¼ì¸

### ğŸ”§ MLflow í†µí•©

- ì‹¤í—˜ ìë™ ìƒì„± ë° ê´€ë¦¬
- ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ìë™ ì €ì¥
- ë©”íŠ¸ë¦­ ë° íŒŒë¼ë¯¸í„° ì¶”ì 

## ğŸš€ ê¸°ë³¸ ì‚¬ìš©ë²•

### PyTorch ëª¨ë¸ í•™ìŠµ

```python
from keynet_train import trace_pytorch
import torch

# ğŸ¯ decoratorì— ìƒ˜í”Œ ì…ë ¥ì„ ì œê³µí•˜ê³ , í•¨ìˆ˜ì—ì„œëŠ” ëª¨ë¸ë§Œ ë°˜í™˜
@trace_pytorch("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    model = MyModel()

    # í•™ìŠµ ì½”ë“œ...
    for epoch in range(10):
        # ì‹¤ì œ í•™ìŠµ ë¡œì§
        pass

    return model  # âš ï¸ ë°˜ë“œì‹œ torch.nn.Moduleë§Œ ë°˜í™˜
```

### ğŸŒ í”„ë ˆì„ì›Œí¬ ë…ë¦½ì  ONNX ëª¨ë¸ ë°°í¬

`log_onnx_model`ì€ ëª¨ë“  ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì—ì„œ ONNXë¡œ ë‚´ë³´ë‚¸ ëª¨ë¸ì„ 
í†µí•© ë°°í¬í•  ìˆ˜ ìˆëŠ” APIì…ë‹ˆë‹¤. PyTorchì˜ `@trace_pytorch`ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ê±°ë‚˜,
ì´ë¯¸ ONNX íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤.

#### ì§€ì› ì‹œë‚˜ë¦¬ì˜¤

1. **PyTorch**: ìˆ˜ë™ ONNX ë³€í™˜ í›„ ë°°í¬ê°€ í•„ìš”í•œ ê²½ìš°
2. **TensorFlow/Keras**: tf2onnxë¡œ ë³€í™˜ í›„ ë°°í¬
3. **JAX/Flax**: jax2onnx ë“±ìœ¼ë¡œ ë³€í™˜ í›„ ë°°í¬
4. **ê¸°íƒ€**: ONNX í‘œì¤€ì„ ì§€ì›í•˜ëŠ” ëª¨ë“  í”„ë ˆì„ì›Œí¬

#### TensorFlow ì˜ˆì œ

```python
from keynet_train import log_onnx_model
import tensorflow as tf
import tf2onnx

# TensorFlow ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜
model = tf.keras.models.load_model('my_model.h5')
spec = (tf.TensorSpec((None, 224, 224, 3), tf.float32, name="input"),)
model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec)

# ONNX íŒŒì¼ë¡œ ì €ì¥
with open("model.onnx", "wb") as f:
    f.write(model_proto.SerializeToString())

# ğŸš€ MLflow ë¡œê¹… + ì¶”ë¡  ì„œë²„ ë°°í¬
upload_path = log_onnx_model(
    experiment_name="tensorflow_experiment",
    onnx_model_path="model.onnx",
    metadata={"framework": "tensorflow", "model_type": "classification"}
)
```

#### PyTorch ìˆ˜ë™ ë³€í™˜ ì˜ˆì œ

```python
from keynet_train import log_onnx_model
import torch

# PyTorch ëª¨ë¸ì„ ìˆ˜ë™ìœ¼ë¡œ ONNX ë³€í™˜
model = MyModel()
model.load_state_dict(torch.load('model.pth'))
dummy_input = torch.randn(1, 3, 224, 224)

torch.onnx.export(model, dummy_input, "model.onnx", 
                  input_names=['input'], output_names=['output'])

# ë³€í™˜ëœ ONNX ëª¨ë¸ ë°°í¬
upload_path = log_onnx_model(
    experiment_name="pytorch_manual",
    onnx_model_path="model.onnx",
    metadata={"framework": "pytorch", "conversion": "manual"}
)
```

## ğŸ“‹ ë°˜í™˜ê°’ ì œì•½ì‚¬í•­

**`@trace_pytorch` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ëŠ” í•¨ìˆ˜ëŠ” ë°˜ë“œì‹œ `torch.nn.Module` ê°ì²´ë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.**

### âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©ë²•

```python
@trace_pytorch("experiment", torch.randn(1, 784))
def train_mnist():
    model = torch.nn.Sequential(
        torch.nn.Linear(784, 128),
        torch.nn.ReLU(),
        torch.nn.Linear(128, 10)
    )

    # í›ˆë ¨ ë¡œì§
    optimizer = torch.optim.Adam(model.parameters())
    for epoch in range(100):
        # ì‹¤ì œ í›ˆë ¨...
        loss = train_one_epoch(model, optimizer, train_loader)

        # ë©”íŠ¸ë¦­ì€ mlflow.log_* í•¨ìˆ˜ë¡œ ê¸°ë¡
        mlflow.log_metric("train_loss", loss, step=epoch)

    return model  # ğŸ¯ ëª¨ë¸ë§Œ ë°˜í™˜!
```

### âŒ ì˜ëª»ëœ ì‚¬ìš©ë²•ë“¤

```python
@trace_pytorch("experiment", torch.randn(1, 784))
def wrong_usage1():
    model = MyModel()
    loss = train(model)
    return model, loss  # âŒ íŠœí”Œ ë°˜í™˜ ë¶ˆê°€

@trace_pytorch("experiment", torch.randn(1, 784))
def wrong_usage2():
    model = MyModel()
    train(model)
    return {
        "model": model,
        "accuracy": 0.95
    }  # âŒ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜ ë¶ˆê°€

@trace_pytorch("experiment", torch.randn(1, 784))
def wrong_usage3():
    model = MyModel()
    train(model)
    return "model_saved.pth"  # âŒ ë¬¸ìì—´ ë°˜í™˜ ë¶ˆê°€
```

### ğŸ’¡ ì™œ ì´ëŸ° ì œì•½ì´ ìˆë‚˜ìš”?

`@trace_pytorch` ë°ì½”ë ˆì´í„°ëŠ” ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ ì‘ì—…ì„ ìë™í™”í•©ë‹ˆë‹¤:

1. **MLflow ëª¨ë¸ ë¡œê¹…**: `mlflow.pytorch.log_model(pytorch_model=model, ...)`
2. **ONNX ë³€í™˜**: `torch.onnx.export(model, ...)`
3. **Triton ë°°í¬**: ìë™ `config.pbtxt` ìƒì„±

ì´ ëª¨ë“  ì‘ì—…ì´ `torch.nn.Module` ê°ì²´ë¥¼ í•„ìš”ë¡œ í•˜ë¯€ë¡œ, ë‹¤ë¥¸ íƒ€ì…ì˜ ë°˜í™˜ê°’ì€ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

## ğŸ“ ONNX ëª¨ë¸ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª… ê·œì¹™

`@trace_pytorch` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•  ë•Œ ìƒì„±ë˜ëŠ” ONNX ëª¨ë¸ì˜ ì…ì¶œë ¥ íŒŒë¼ë¯¸í„°ëª…ì€ ë‹¤ìŒê³¼ ê°™ì´ ê²°ì •ë©ë‹ˆë‹¤:

### ì…ë ¥ íŒŒë¼ë¯¸í„° (Inputs)

```python
# âœ… Dictionary í˜•íƒœë¡œ ì…ë ¥í•˜ë©´ í‚¤ ì´ë¦„ì„ ì‚¬ìš© (ê¶Œì¥)
@trace_pytorch("my_experiment", {"image": torch.randn(1, 3, 224, 224), "label": torch.randn(1, 10)})
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "image", "label"
    ...

# âœ… ë‹¨ì¼ í…ì„œë¡œ ì…ë ¥í•˜ë©´ ìë™ ìƒì„±
@trace_pytorch("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    # ìƒì„±ë˜ëŠ” ONNXì˜ ì…ë ¥ëª…: "input_0"
    ...
```

### ì¶œë ¥ íŒŒë¼ë¯¸í„° (Outputs)

```python
# ì¶œë ¥ëª…ì€ í•­ìƒ ìë™ ìƒì„±ë©ë‹ˆë‹¤
@trace_pytorch("my_experiment", torch.randn(1, 3, 224, 224))
def train_model():
    # ë‹¨ì¼ ì¶œë ¥: "output_0"
    return model

# ë‹¤ì¤‘ ì¶œë ¥ ëª¨ë¸ì˜ ê²½ìš°
def train_multi_output_model():
    class MultiOutputModel(torch.nn.Module):
        def forward(self, x):
            return output1, output2  # íŠœí”Œ ë°˜í™˜

    # ì‹¤ì œë¡œëŠ” MLflowê°€ íŠœí”Œì„ í•˜ë‚˜ì˜ ë°°ì—´ë¡œ ì²˜ë¦¬í•˜ì—¬ "output_0"ë§Œ ìƒì„±ë¨
    return model
```

### âš ï¸ ì¤‘ìš”í•œ ì œí•œì‚¬í•­

- **ì§€ì›ë˜ëŠ” ì…ë ¥ í˜•íƒœ**: `torch.Tensor` ë˜ëŠ” `Dict[str, torch.Tensor]`ë§Œ ì§€ì›
- **íŠœí”Œ ì…ë ¥ ë¯¸ì§€ì›**: `(tensor1, tensor2)` í˜•íƒœì˜ íŠœí”Œ ì…ë ¥ì€ í˜„ì¬ ì§€ì›ë˜ì§€ ì•ŠìŒ
- **ë‹¤ì¤‘ ì¶œë ¥ ì²˜ë¦¬**: PyTorch ëª¨ë¸ì´ íŠœí”Œë¡œ ë‹¤ì¤‘ ì¶œë ¥ì„ ë°˜í™˜í•´ë„ MLflow signature ì¶”ë¡ ì— ì˜í•´ `output_0` í•˜ë‚˜ë¡œ ì²˜ë¦¬ë¨
- **MLflow ì˜ì¡´ì„±**: íŒŒë¼ë¯¸í„°ëª… ìƒì„±ì€ MLflowì˜ ìë™ signature ì¶”ë¡ ì— ì˜ì¡´í•˜ë¯€ë¡œ ì¼ë¶€ ì œí•œì‚¬í•­ì´ ìˆìŒ

### ğŸ’¡ ê¶Œì¥ì‚¬í•­

```python
# ğŸ¯ ìµœì ì˜ ì‚¬ìš©ë²•: Dictionary ì…ë ¥ìœ¼ë¡œ ëª…ì‹œì ì¸ ì´ë¦„ ì§€ì •
@trace_pytorch("experiment", {
    "image": torch.randn(1, 3, 224, 224),
    "mask": torch.randn(1, 1, 224, 224)
})
def train_model():
    # ìƒì„±ë˜ëŠ” config.pbtxtì—ì„œ ëª…í™•í•œ ì…ë ¥ëª… í™•ì¸ ê°€ëŠ¥:
    # input { name: "image", data_type: TYPE_FP32, dims: [-1, 3, 224, 224] }
    # input { name: "mask", data_type: TYPE_FP32, dims: [-1, 1, 224, 224] }
    return model
```

> **Note:** ìƒì„±ëœ ONNX ëª¨ë¸ì€ Triton Inference Server ë°°í¬ ì‹œ ìë™ìœ¼ë¡œ `config.pbtxt` íŒŒì¼ì´ ìƒì„±ë˜ì–´ ì •í™•í•œ ì…ì¶œë ¥ ìŠ¤í‚¤ë§ˆë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë‹¤ì¤‘ ì…ë ¥ ëª¨ë¸

```python
@trace_pytorch("multi_input_exp", {
    "image": torch.randn(1, 3, 224, 224),
    "mask": torch.randn(1, 1, 224, 224)
})
def train_multi_input():
    model = MultiInputModel()

    # ëª¨ë¸ì´ ì—¬ëŸ¬ ì…ë ¥ì„ ë°›ëŠ” ê²½ìš°
    class MultiInputModel(torch.nn.Module):
        def forward(self, image, mask):
            # imageì™€ maskë¥¼ í•¨ê»˜ ì²˜ë¦¬
            combined = torch.cat([image, mask], dim=1)
            return self.classifier(combined)

    # í›ˆë ¨ ë¡œì§...
    return model
```

## ğŸ”„ Dynamic Axes (ê°€ë³€ í¬ê¸° ì§€ì›)

ONNX ë³€í™˜ ì‹œ ì…ì¶œë ¥ í…ì„œì˜ íŠ¹ì • ì°¨ì›ì„ ë™ì (ê°€ë³€) í¬ê¸°ë¡œ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ê¸°ë³¸ ë™ì‘

```python
# ê¸°ë³¸ì ìœ¼ë¡œ ë°°ì¹˜ ì°¨ì›(0ë²ˆ)ì€ ìë™ìœ¼ë¡œ ë™ì  í¬ê¸°ë¡œ ì„¤ì •ë©ë‹ˆë‹¤
@trace_pytorch("experiment", torch.randn(1, 3, 224, 224))
def train_model():
    # ONNX ì…ë ¥ shape: [-1, 3, 224, 224]
    # -1ì€ ê°€ë³€ ë°°ì¹˜ í¬ê¸°ë¥¼ ì˜ë¯¸
    return model
```

### ì»¤ìŠ¤í…€ Dynamic Axes

```python
# ì‹œí€€ìŠ¤ ê¸¸ì´ê°€ ê°€ë³€ì ì¸ ëª¨ë¸
@trace_pytorch(
    "seq_model",
    torch.randn(1, 128, 768),  # [batch, seq_len, hidden]
    dynamic_axes={
        "input_0": {
            0: "batch_size",
            1: "sequence_length"  # 1ë²ˆ ì°¨ì›ë„ ê°€ë³€ìœ¼ë¡œ
        },
        "output_0": {
            0: "batch_size",
            1: "sequence_length"
        }
    }
)
def train_sequence_model():
    return SequenceModel()

# ë‹¤ì¤‘ ì…ë ¥ì—ì„œ ê°ê° ë‹¤ë¥¸ dynamic axes ì„¤ì •
@trace_pytorch(
    "multimodal",
    {
        "image": torch.randn(1, 3, 224, 224),
        "text": torch.randn(1, 50, 512)
    },
    dynamic_axes={
        "image": {0: "batch"},           # ì´ë¯¸ì§€ëŠ” ë°°ì¹˜ë§Œ
        "text": {0: "batch", 1: "len"}, # í…ìŠ¤íŠ¸ëŠ” ê¸¸ì´ë„
        "output_0": {0: "batch"}
    }
)
def train_multimodal():
    return MultiModalModel()
```

### ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

- **NLP**: ê°€ë³€ ê¸¸ì´ ì‹œí€€ìŠ¤ ì²˜ë¦¬
- **Vision**: ë‹¤ì–‘í•œ í•´ìƒë„ ì´ë¯¸ì§€ ì§€ì›
- **Detection**: ê°€ë³€ ê°œìˆ˜ì˜ ê°ì²´ ì¶œë ¥

> **Note**: ë™ì  í¬ê¸° ì„¤ì •ì´ ì‹¤íŒ¨í•˜ë©´ ìë™ìœ¼ë¡œ ê³ ì • í¬ê¸°ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.

## ë¼ì´ì„ ìŠ¤

MIT License
