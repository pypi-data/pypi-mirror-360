# config/model_policy.yaml

default:
  model: gpt-4o-mini
  temperature: 0.0
  provider: openai

agents:
  vision_agent:
    model: gpt-4o  # OpenAI's vision model
    temperature: 0.0
    provider: openai
  interpretation_agent:
    model: gpt-4o-mini
    temperature: 0.7
    provider: openai
  consensus_agent:
    model: gpt-4o
    temperature: 0.0
    provider: openai
  question_agent:
    model: gpt-3.5-turbo
    temperature: 0.0
    provider: openai
  github_agent:
    model: gpt-3.5-turbo
    temperature: 0.5
    provider: openai
  codegen_agent:
    model: gpt-4o
    temperature: 0.2
    provider: openai
  state_agent:
    model: gpt-3.5-turbo
    temperature: 0.0
    provider: openai
  hello_agent:
    model: gpt-3.5-turbo
    temperature: 0.7
    provider: openai

models:
  context_lengths:
    gpt-4o-mini: 128000
    gpt-4o: 128000
    gpt-3.5-turbo: 16384

  encodings:
    gpt-4o-mini: cl100k_base
    gpt-4o: cl100k_base
    gpt-3.5-turbo: cl100k_base
