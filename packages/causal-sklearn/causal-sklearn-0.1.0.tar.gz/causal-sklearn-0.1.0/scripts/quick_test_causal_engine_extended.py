#!/usr/bin/env python3
"""
CausalEngine æ‰©å±•å™ªå£°é²æ£’æ€§åˆ†æè„šæœ¬

ğŸ¯ ç›®æ ‡ï¼šå…¨é¢åˆ†æå„ç§ç®—æ³•åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹çš„é²æ£’æ€§è¡¨ç°
ğŸ”¬ æ ¸å¿ƒï¼š0%-100%å™ªå£°çº§åˆ«ä¸‹çš„ç®—æ³•æ€§èƒ½å¯¹æ¯”

ä¸»è¦ç‰¹æ€§ï¼š
- å›å½’ç®—æ³•9ç§ï¼šsklearn MLP, PyTorch MLP, CausalEngine(4ç§æ¨¡å¼), Huber, Pinball, Cauchy
- åˆ†ç±»ç®—æ³•8ç§ï¼šsklearn MLP, PyTorch MLP, sklearn OvR, PyTorch Shared OvR, CausalEngine(4ç§æ¨¡å¼)  
- å™ªå£°çº§åˆ«ï¼š0%, 10%, 20%, ..., 100% (11ä¸ªçº§åˆ«)
- å®Œæ•´æŒ‡æ ‡ï¼šå›å½’(MAE, MdAE, RMSE, RÂ²) + åˆ†ç±»(Accuracy, Precision, Recall, F1)
- æŠ˜çº¿å›¾å¯è§†åŒ–ï¼šæ¸…æ™°å±•ç¤ºç®—æ³•é²æ£’æ€§å¯¹æ¯”

ä½¿ç”¨æ–¹æ³•ï¼š
1. ç›´æ¥è¿è¡Œï¼špython scripts/quick_test_causal_engine_extended.py
2. è°ƒæ•´å‚æ•°ï¼šä¿®æ”¹ä¸‹æ–¹çš„ EXTENDED_CONFIG
3. å•ç‹¬æµ‹è¯•ï¼šè°ƒç”¨ test_regression_noise_robustness() æˆ– test_classification_noise_robustness()
"""

import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, median_absolute_error
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.datasets import make_regression, make_classification
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import os
import sys
import warnings
from tqdm import tqdm
import pandas as pd

# è®¾ç½®matplotlibåç«¯ï¼Œé¿å…å¼¹å‡ºçª—å£
plt.switch_backend('Agg')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ‰€æœ‰å›å½’å™¨å’Œåˆ†ç±»å™¨
from causal_sklearn.regressor import (
    MLPCausalRegressor, MLPPytorchRegressor, 
    MLPHuberRegressor, MLPPinballRegressor, MLPCauchyRegressor
)
from causal_sklearn.classifier import (
    MLPCausalClassifier, MLPPytorchClassifier, 
    MLPSklearnOvRClassifier, MLPPytorchSharedOvRClassifier
)
from causal_sklearn.data_processing import inject_shuffle_noise

warnings.filterwarnings('ignore')

# =============================================================================
# é…ç½®éƒ¨åˆ† - åœ¨è¿™é‡Œä¿®æ”¹å®éªŒå‚æ•°
# =============================================================================

EXTENDED_CONFIG = {
    # å™ªå£°çº§åˆ«è®¾ç½®
    'noise_levels': np.linspace(0, 1, 11),  # 0%, 10%, 20%, ..., 100%
    
    # æ•°æ®ç”Ÿæˆå‚æ•°
    'n_samples': 3000,      # å¢åŠ æ ·æœ¬é‡ï¼Œæé«˜ç¨³å®šæ€§
    'n_features': 10,       # é€‚ä¸­ç‰¹å¾æ•°
    'random_state': 42,     # å›ºå®šéšæœºç§å­
    'test_size': 0.2,       # æµ‹è¯•é›†æ¯”ä¾‹
    
    # å›å½’ä»»åŠ¡å‚æ•°
    'regression_noise': 1.0,        # å›å½’æ•°æ®æœ¬èº«çš„å™ªå£°
    'n_classes': 3,                 # åˆ†ç±»ä»»åŠ¡ç±»åˆ«æ•°
    'class_sep': 1.0,               # åˆ†ç±»ä»»åŠ¡ç±»åˆ«åˆ†ç¦»åº¦
    
    # ç½‘ç»œç»“æ„ï¼ˆæ‰€æœ‰ç®—æ³•ç»Ÿä¸€ï¼‰- ä¼˜åŒ–ç¨³å®šæ€§
    'hidden_layers': (64, 32),      # ä¿æŒç½‘ç»œç»“æ„
    'max_iter': 2000,               # å¢åŠ æœ€å¤§è¿­ä»£æ¬¡æ•°
    'learning_rate': 0.001,         # é™ä½å­¦ä¹ ç‡æé«˜ç¨³å®šæ€§
    'patience': 50,                 # å¢åŠ æ—©åœè€å¿ƒ
    'tol': 1e-4,                    # æ”¶æ•›å®¹å¿åº¦
    
    # ç®—æ³•å¼€å…³ï¼ˆå¯ä»¥å…³é—­æŸäº›ç®—æ³•åŠ å¿«æµ‹è¯•ï¼‰
    'test_regression': True,
    'test_classification': True,
    
    # ç¨³å®šæ€§æ”¹è¿›å‚æ•°
    'n_runs': 3,                     # å¤šæ¬¡è¿è¡Œæ¬¡æ•°
    'base_random_seed': 42,          # åŸºç¡€éšæœºç§å­
    
    # è¾“å‡ºæ§åˆ¶
    'output_dir': 'results/extended_robustness',
    'save_plots': True,
    'save_data': True,
    'verbose': True,
    'figure_dpi': 300
}

# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def _ensure_output_dir(output_dir):
    """ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨"""
    if not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)

def _get_output_path(output_dir, filename):
    """è·å–è¾“å‡ºæ–‡ä»¶è·¯å¾„"""
    return os.path.join(output_dir, filename)

# =============================================================================
# å›å½’é²æ£’æ€§æµ‹è¯•
# =============================================================================

def test_regression_noise_robustness(config):
    """æµ‹è¯•å›å½’ç®—æ³•çš„å™ªå£°é²æ£’æ€§"""
    print("\n" + "="*80)
    print("ğŸ”¬ å›å½’ç®—æ³•å™ªå£°é²æ£’æ€§æµ‹è¯•")
    print("="*80)
    
    noise_levels = config['noise_levels']
    results = {}
    
    # å®šä¹‰æ‰€æœ‰å›å½’ç®—æ³•
    algorithms = {
        # 'sklearn_mlp': ('sklearn MLP', None),
        'pytorch_mlp': ('PyTorch MLP', None),
        'causal_deterministic': ('CausalEngine (deterministic)', 'deterministic'),
        # 'causal_exogenous': ('CausalEngine (exogenous)', 'exogenous'),
        # 'causal_endogenous': ('CausalEngine (endogenous)', 'endogenous'),
        'causal_standard': ('CausalEngine (standard)', 'standard'),
        'huber': ('Huber Regressor', None),
        'pinball': ('Pinball Regressor', None),
        'cauchy': ('Cauchy Regressor', None)
    }
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    for algo_key, (algo_name, _) in algorithms.items():
        results[algo_key] = {
            'name': algo_name,
            'noise_levels': [],
            'mae': [], 'mdae': [], 'rmse': [], 'r2': []
        }
    
    # ç”ŸæˆåŸºç¡€æ•°æ®ï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
    print(f"ğŸ“Š ç”Ÿæˆå›å½’æ•°æ®: {config['n_samples']}æ ·æœ¬, {config['n_features']}ç‰¹å¾")
    X, y = make_regression(
        n_samples=config['n_samples'],
        n_features=config['n_features'],
        noise=config['regression_noise'],
        random_state=config['random_state']
    )
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train_clean, y_test = train_test_split(
        X, y, test_size=config['test_size'], random_state=config['random_state']
    )
    
    # æ ‡å‡†åŒ–
    scaler_X = StandardScaler()
    scaler_y = StandardScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    y_train_clean_scaled = scaler_y.fit_transform(y_train_clean.reshape(-1, 1)).flatten()
    y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()
    
    # åœ¨ä¸åŒå™ªå£°çº§åˆ«ä¸‹æµ‹è¯•
    for noise_level in tqdm(noise_levels, desc="å™ªå£°çº§åˆ«"):
        print(f"\nğŸ“Š æµ‹è¯•å™ªå£°çº§åˆ«: {noise_level:.1%}")
        
        # å¯¹è®­ç»ƒæ ‡ç­¾æ³¨å…¥å™ªå£° - ä½¿ç”¨ä¸“é—¨çš„inject_shuffle_noiseå‡½æ•°
        if noise_level > 0:
            # ä½¿ç”¨é¡¹ç›®æ ‡å‡†çš„å™ªå£°æ³¨å…¥æ–¹æ³•
            y_train_noisy, noise_indices = inject_shuffle_noise(
                y_train_clean_scaled,
                noise_ratio=noise_level,
                random_state=42
            )
        else:
            y_train_noisy = y_train_clean_scaled.copy()
        
        # æµ‹è¯•æ¯ä¸ªç®—æ³•
        for algo_key, (algo_name, causal_mode) in algorithms.items():
            try:
                if config['verbose']:
                    print(f"  ğŸ”§ è®­ç»ƒ {algo_name}...")
                
                # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
                if algo_key == 'sklearn_mlp':
                    model = MLPRegressor(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate_init=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        validation_fraction=0.1,
                        n_iter_no_change=config['patience']
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'pytorch_mlp':
                    model = MLPPytorchRegressor(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key.startswith('causal_'):
                    model = MLPCausalRegressor(
                        perception_hidden_layers=config['hidden_layers'],
                        mode=causal_mode,
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'huber':
                    model = MLPHuberRegressor(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'pinball':
                    model = MLPPinballRegressor(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'cauchy':
                    model = MLPCauchyRegressor(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                y_pred_scaled = model.predict(X_test_scaled)
                
                # è½¬æ¢å›åŸå§‹å°ºåº¦è¯„ä¼°
                y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
                
                # è®¡ç®—æŒ‡æ ‡
                mae = mean_absolute_error(y_test, y_pred)
                mdae = median_absolute_error(y_test, y_pred)
                rmse = np.sqrt(mean_squared_error(y_test, y_pred))
                r2 = r2_score(y_test, y_pred)
                
                # å­˜å‚¨ç»“æœ
                results[algo_key]['noise_levels'].append(noise_level)
                results[algo_key]['mae'].append(mae)
                results[algo_key]['mdae'].append(mdae)
                results[algo_key]['rmse'].append(rmse)
                results[algo_key]['r2'].append(r2)
                
                if config['verbose']:
                    print(f"    MAE: {mae:.4f}, RMSE: {rmse:.4f}, RÂ²: {r2:.4f}")
                
            except Exception as e:
                print(f"    âŒ {algo_name} è®­ç»ƒå¤±è´¥: {str(e)}")
                # æ·»åŠ NaNå€¼ä¿æŒæ•°ç»„é•¿åº¦ä¸€è‡´
                results[algo_key]['noise_levels'].append(noise_level)
                results[algo_key]['mae'].append(np.nan)
                results[algo_key]['mdae'].append(np.nan)
                results[algo_key]['rmse'].append(np.nan)
                results[algo_key]['r2'].append(np.nan)
    
    return results

# =============================================================================
# åˆ†ç±»é²æ£’æ€§æµ‹è¯•
# =============================================================================

def test_classification_noise_robustness(config):
    """æµ‹è¯•åˆ†ç±»ç®—æ³•çš„å™ªå£°é²æ£’æ€§"""
    print("\n" + "="*80)
    print("ğŸ¯ åˆ†ç±»ç®—æ³•å™ªå£°é²æ£’æ€§æµ‹è¯•")
    print("="*80)
    
    noise_levels = config['noise_levels']
    results = {}
    
    # å®šä¹‰æ‰€æœ‰åˆ†ç±»ç®—æ³•
    algorithms = {
        # 'sklearn_mlp': ('sklearn MLP', None),
        'pytorch_mlp': ('PyTorch MLP', None),
        'sklearn_ovr': ('sklearn OvR MLP', None),
        'pytorch_shared_ovr': ('PyTorch Shared OvR', None),
        'causal_deterministic': ('CausalEngine (deterministic)', 'deterministic'),
        # 'causal_exogenous': ('CausalEngine (exogenous)', 'exogenous'),
        # 'causal_endogenous': ('CausalEngine (endogenous)', 'endogenous'),
        'causal_standard': ('CausalEngine (standard)', 'standard')
    }
    
    # åˆå§‹åŒ–ç»“æœå­—å…¸
    for algo_key, (algo_name, _) in algorithms.items():
        results[algo_key] = {
            'name': algo_name,
            'noise_levels': [],
            'accuracy': [], 'precision': [], 'recall': [], 'f1': []
        }
    
    # ç”ŸæˆåŸºç¡€æ•°æ®
    print(f"ğŸ“Š ç”Ÿæˆåˆ†ç±»æ•°æ®: {config['n_samples']}æ ·æœ¬, {config['n_features']}ç‰¹å¾, {config['n_classes']}ç±»åˆ«")
    X, y = make_classification(
        n_samples=config['n_samples'],
        n_features=config['n_features'],
        n_classes=config['n_classes'],
        n_clusters_per_class=1,
        class_sep=config['class_sep'],
        random_state=config['random_state']
    )
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train_clean, y_test = train_test_split(
        X, y, test_size=config['test_size'], random_state=config['random_state']
    )
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler_X = StandardScaler()
    X_train_scaled = scaler_X.fit_transform(X_train)
    X_test_scaled = scaler_X.transform(X_test)
    
    # åœ¨ä¸åŒå™ªå£°çº§åˆ«ä¸‹æµ‹è¯•
    for noise_level in tqdm(noise_levels, desc="å™ªå£°çº§åˆ«"):
        print(f"\nğŸ“Š æµ‹è¯•å™ªå£°çº§åˆ«: {noise_level:.1%}")
        
        # å¯¹è®­ç»ƒæ ‡ç­¾æ³¨å…¥å™ªå£° - ä½¿ç”¨ä¸“é—¨çš„inject_shuffle_noiseå‡½æ•°
        if noise_level > 0:
            # ä½¿ç”¨é¡¹ç›®æ ‡å‡†çš„å™ªå£°æ³¨å…¥æ–¹æ³•
            y_train_noisy, noise_indices = inject_shuffle_noise(
                y_train_clean,
                noise_ratio=noise_level,
                random_state=42
            )
        else:
            y_train_noisy = y_train_clean.copy()
        
        # æµ‹è¯•æ¯ä¸ªç®—æ³•
        for algo_key, (algo_name, causal_mode) in algorithms.items():
            try:
                if config['verbose']:
                    print(f"  ğŸ”§ è®­ç»ƒ {algo_name}...")
                
                # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
                if algo_key == 'sklearn_mlp':
                    model = MLPClassifier(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate_init=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        validation_fraction=0.1,
                        n_iter_no_change=config['patience']
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'pytorch_mlp':
                    model = MLPPytorchClassifier(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'sklearn_ovr':
                    model = MLPSklearnOvRClassifier(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate_init=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        validation_fraction=0.1,
                        n_iter_no_change=config['patience'],
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key == 'pytorch_shared_ovr':
                    model = MLPPytorchSharedOvRClassifier(
                        hidden_layer_sizes=config['hidden_layers'],
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                    
                elif algo_key.startswith('causal_'):
                    model = MLPCausalClassifier(
                        perception_hidden_layers=config['hidden_layers'],
                        mode=causal_mode,
                        max_iter=config['max_iter'],
                        learning_rate=config['learning_rate'],
                        random_state=config['random_state'],
                        early_stopping=True,
                        verbose=False
                    )
                    model.fit(X_train_scaled, y_train_noisy)
                
                # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
                y_pred = model.predict(X_test_scaled)
                
                # è®¡ç®—æŒ‡æ ‡
                accuracy = accuracy_score(y_test, y_pred)
                precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)
                recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)
                f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)
                
                # å­˜å‚¨ç»“æœ
                results[algo_key]['noise_levels'].append(noise_level)
                results[algo_key]['accuracy'].append(accuracy)
                results[algo_key]['precision'].append(precision)
                results[algo_key]['recall'].append(recall)
                results[algo_key]['f1'].append(f1)
                
                if config['verbose']:
                    print(f"    Acc: {accuracy:.4f}, F1: {f1:.4f}")
                
            except Exception as e:
                print(f"    âŒ {algo_name} è®­ç»ƒå¤±è´¥: {str(e)}")
                # æ·»åŠ NaNå€¼ä¿æŒæ•°ç»„é•¿åº¦ä¸€è‡´
                results[algo_key]['noise_levels'].append(noise_level)
                results[algo_key]['accuracy'].append(np.nan)
                results[algo_key]['precision'].append(np.nan)
                results[algo_key]['recall'].append(np.nan)
                results[algo_key]['f1'].append(np.nan)
    
    return results

# =============================================================================
# å¯è§†åŒ–å‡½æ•°
# =============================================================================

def create_robustness_plots(regression_results, classification_results, config):
    """åˆ›å»ºé²æ£’æ€§åˆ†ææŠ˜çº¿å›¾"""
    if not config.get('save_plots', False):
        return
    
    _ensure_output_dir(config['output_dir'])
    
    print("\nğŸ“Š åˆ›å»ºé²æ£’æ€§åˆ†æå›¾è¡¨")
    print("-" * 50)
    
    # è®¾ç½®å›¾è¡¨é£æ ¼
    plt.style.use('seaborn-v0_8')
    colors = plt.cm.Set3(np.linspace(0, 1, 12))  # 12ç§ä¸åŒé¢œè‰²
    
    # åˆ›å»ºå›å½’é²æ£’æ€§å›¾è¡¨
    if regression_results and config.get('test_regression', True):
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        n_runs = config.get('n_runs', 1)
        title_suffix = f' (Averaged over {n_runs} runs)' if n_runs > 1 else ''
        fig.suptitle(f'Regression Algorithms Noise Robustness Analysis{title_suffix}', fontsize=16, fontweight='bold')
        
        metrics = ['mae', 'mdae', 'rmse', 'r2']
        metric_names = ['MAE', 'MdAE', 'RMSE', 'RÂ²']
        
        for i, (metric, metric_name) in enumerate(zip(metrics, metric_names)):
            ax = axes[i//2, i%2]
            
            color_idx = 0
            for algo_key, data in regression_results.items():
                if data[metric]:  # ç¡®ä¿æœ‰æ•°æ®
                    noise_levels = np.array(data['noise_levels']) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                    values = np.array(data[metric])
                    
                    # è¿‡æ»¤NaNå€¼
                    valid_mask = ~np.isnan(values)
                    if valid_mask.any():
                        # åˆ¤æ–­æ˜¯å¦ä¸ºå› æœç®—æ³•
                        is_causal = algo_key.startswith('causal_')
                        linestyle = '-' if is_causal else '--'  # å› æœç®—æ³•å®çº¿ï¼Œå…¶ä»–è™šçº¿
                        
                        # åªç»˜åˆ¶å¹³å‡å€¼çº¿æ¡ï¼Œä¸æ˜¾ç¤ºè¯¯å·®æ¡
                        ax.plot(noise_levels[valid_mask], values[valid_mask], 
                               marker='o', linewidth=2, markersize=4, linestyle=linestyle,
                               label=data['name'], color=colors[color_idx])
                        color_idx += 1
            
            ax.set_xlabel('Noise Level (%)')
            ax.set_ylabel(metric_name)
            ax.set_title(f'{metric_name} vs Noise Level')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
            
            # å¯¹RÂ²ä½¿ç”¨ç‰¹æ®Šçš„yè½´èŒƒå›´
            if metric == 'r2':
                ax.set_ylim(-0.1, 1.1)
        
        plt.tight_layout()
        regression_path = _get_output_path(config['output_dir'], 'regression_robustness.png')
        plt.savefig(regression_path, dpi=config['figure_dpi'], bbox_inches='tight')
        print(f"ğŸ“Š å›å½’é²æ£’æ€§å›¾è¡¨å·²ä¿å­˜ä¸º {regression_path}")
        plt.close()
    
    # åˆ›å»ºåˆ†ç±»é²æ£’æ€§å›¾è¡¨
    if classification_results and config.get('test_classification', True):
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        n_runs = config.get('n_runs', 1)
        title_suffix = f' (Averaged over {n_runs} runs)' if n_runs > 1 else ''
        fig.suptitle(f'Classification Algorithms Noise Robustness Analysis{title_suffix}', fontsize=16, fontweight='bold')
        
        metrics = ['accuracy', 'precision', 'recall', 'f1']
        metric_names = ['Accuracy', 'Precision', 'Recall', 'F1']
        
        for i, (metric, metric_name) in enumerate(zip(metrics, metric_names)):
            ax = axes[i//2, i%2]
            
            color_idx = 0
            for algo_key, data in classification_results.items():
                if data[metric]:  # ç¡®ä¿æœ‰æ•°æ®
                    noise_levels = np.array(data['noise_levels']) * 100  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                    values = np.array(data[metric])
                    
                    # è¿‡æ»¤NaNå€¼
                    valid_mask = ~np.isnan(values)
                    if valid_mask.any():
                        # åˆ¤æ–­æ˜¯å¦ä¸ºå› æœç®—æ³•
                        is_causal = algo_key.startswith('causal_')
                        linestyle = '-' if is_causal else '--'  # å› æœç®—æ³•å®çº¿ï¼Œå…¶ä»–è™šçº¿
                        
                        # åªç»˜åˆ¶å¹³å‡å€¼çº¿æ¡ï¼Œä¸æ˜¾ç¤ºè¯¯å·®æ¡
                        ax.plot(noise_levels[valid_mask], values[valid_mask], 
                               marker='o', linewidth=2, markersize=4, linestyle=linestyle,
                               label=data['name'], color=colors[color_idx])
                        color_idx += 1
            
            ax.set_xlabel('Noise Level (%)')
            ax.set_ylabel(metric_name)
            ax.set_title(f'{metric_name} vs Noise Level')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, alpha=0.3)
            ax.set_ylim(0, 1.1)
        
        plt.tight_layout()
        classification_path = _get_output_path(config['output_dir'], 'classification_robustness.png')
        plt.savefig(classification_path, dpi=config['figure_dpi'], bbox_inches='tight')
        print(f"ğŸ“Š åˆ†ç±»é²æ£’æ€§å›¾è¡¨å·²ä¿å­˜ä¸º {classification_path}")
        plt.close()

# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def run_single_robustness_analysis(config, run_idx=0):
    """è¿è¡Œå•æ¬¡é²æ£’æ€§åˆ†æ"""
    if config['verbose']:
        print(f"\nğŸ”„ ç¬¬ {run_idx + 1}/{config['n_runs']} æ¬¡è¿è¡Œ (éšæœºç§å­: {config['random_state']})")
    
    regression_results = None
    classification_results = None
    
    # å›å½’é²æ£’æ€§æµ‹è¯•
    if config.get('test_regression', True):
        regression_results = test_regression_noise_robustness(config)
    
    # åˆ†ç±»é²æ£’æ€§æµ‹è¯•
    if config.get('test_classification', True):
        classification_results = test_classification_noise_robustness(config)
    
    return regression_results, classification_results

def aggregate_results(all_regression_results, all_classification_results):
    """èšåˆå¤šæ¬¡è¿è¡Œçš„ç»“æœ"""
    aggregated_regression = {}
    aggregated_classification = {}
    
    # èšåˆå›å½’ç»“æœ
    if all_regression_results and len(all_regression_results) > 0:
        first_reg_result = all_regression_results[0]
        if first_reg_result:
            for algo_key in first_reg_result.keys():
                aggregated_regression[algo_key] = {
                    'name': first_reg_result[algo_key]['name'],
                    'noise_levels': first_reg_result[algo_key]['noise_levels'],
                    'mae': [], 'mdae': [], 'rmse': [], 'r2': [],
                    'mae_std': [], 'mdae_std': [], 'rmse_std': [], 'r2_std': []
                }
                
                # æ”¶é›†æ‰€æœ‰è¿è¡Œçš„ç»“æœ
                metrics = ['mae', 'mdae', 'rmse', 'r2']
                for metric in metrics:
                    all_values = []
                    for run_result in all_regression_results:
                        if run_result and algo_key in run_result:
                            all_values.append(run_result[algo_key][metric])
                    
                    if all_values:
                        # è®¡ç®—æ¯ä¸ªå™ªå£°çº§åˆ«çš„å‡å€¼å’Œæ ‡å‡†å·®
                        all_values = np.array(all_values)  # shape: (n_runs, n_noise_levels)
                        means = np.nanmean(all_values, axis=0)
                        stds = np.nanstd(all_values, axis=0)
                        
                        aggregated_regression[algo_key][metric] = means.tolist()
                        aggregated_regression[algo_key][f'{metric}_std'] = stds.tolist()
    
    # èšåˆåˆ†ç±»ç»“æœ
    if all_classification_results and len(all_classification_results) > 0:
        first_cls_result = all_classification_results[0]
        if first_cls_result:
            for algo_key in first_cls_result.keys():
                aggregated_classification[algo_key] = {
                    'name': first_cls_result[algo_key]['name'],
                    'noise_levels': first_cls_result[algo_key]['noise_levels'],
                    'accuracy': [], 'precision': [], 'recall': [], 'f1': [],
                    'accuracy_std': [], 'precision_std': [], 'recall_std': [], 'f1_std': []
                }
                
                # æ”¶é›†æ‰€æœ‰è¿è¡Œçš„ç»“æœ
                metrics = ['accuracy', 'precision', 'recall', 'f1']
                for metric in metrics:
                    all_values = []
                    for run_result in all_classification_results:
                        if run_result and algo_key in run_result:
                            all_values.append(run_result[algo_key][metric])
                    
                    if all_values:
                        # è®¡ç®—æ¯ä¸ªå™ªå£°çº§åˆ«çš„å‡å€¼å’Œæ ‡å‡†å·®
                        all_values = np.array(all_values)  # shape: (n_runs, n_noise_levels)
                        means = np.nanmean(all_values, axis=0)
                        stds = np.nanstd(all_values, axis=0)
                        
                        aggregated_classification[algo_key][metric] = means.tolist()
                        aggregated_classification[algo_key][f'{metric}_std'] = stds.tolist()
    
    return aggregated_regression, aggregated_classification

def run_robustness_analysis(config=None):
    """è¿è¡Œå®Œæ•´çš„å¤šæ¬¡é²æ£’æ€§åˆ†æ"""
    if config is None:
        config = EXTENDED_CONFIG
    
    print("ğŸš€ CausalEngine æ‰©å±•å™ªå£°é²æ£’æ€§åˆ†æ (å¤šæ¬¡è¿è¡Œç‰ˆæœ¬)")
    print("=" * 70)
    print(f"å™ªå£°çº§åˆ«: {config['noise_levels'][0]:.0%} - {config['noise_levels'][-1]:.0%} ({len(config['noise_levels'])}ä¸ªçº§åˆ«)")
    print(f"æ•°æ®è§„æ¨¡: {config['n_samples']}æ ·æœ¬, {config['n_features']}ç‰¹å¾")
    print(f"è¿è¡Œæ¬¡æ•°: {config['n_runs']}æ¬¡ (éšæœºç§å­: {config['base_random_seed']} - {config['base_random_seed'] + config['n_runs'] - 1})")
    print(f"å­¦ä¹ ç‡: {config['learning_rate']}, æœ€å¤§è¿­ä»£: {config['max_iter']}, æ—©åœè€å¿ƒ: {config['patience']}")
    
    all_regression_results = []
    all_classification_results = []
    
    # å¤šæ¬¡è¿è¡Œ
    for run_idx in range(config['n_runs']):
        # ä¸ºæ¯æ¬¡è¿è¡Œè®¾ç½®ä¸åŒçš„éšæœºç§å­
        run_config = config.copy()
        run_config['random_state'] = config['base_random_seed'] + run_idx
        
        regression_result, classification_result = run_single_robustness_analysis(run_config, run_idx)
        
        all_regression_results.append(regression_result)
        all_classification_results.append(classification_result)
    
    # èšåˆç»“æœ
    print(f"\nğŸ“Š èšåˆ {config['n_runs']} æ¬¡è¿è¡Œçš„ç»“æœ...")
    aggregated_regression, aggregated_classification = aggregate_results(
        all_regression_results, all_classification_results
    )
    
    # åˆ›å»ºå¯è§†åŒ–ï¼ˆä½¿ç”¨èšåˆåçš„ç»“æœï¼‰
    create_robustness_plots(aggregated_regression, aggregated_classification, config)
    
    # ä¿å­˜ç»“æœæ•°æ®
    if config.get('save_data', True):
        _ensure_output_dir(config['output_dir'])
        
        if aggregated_regression:
            reg_data_path = _get_output_path(config['output_dir'], 'regression_results_aggregated.npy')
            np.save(reg_data_path, aggregated_regression)
            print(f"ğŸ“Š èšåˆå›å½’ç»“æœå·²ä¿å­˜ä¸º {reg_data_path}")
        
        if aggregated_classification:
            cls_data_path = _get_output_path(config['output_dir'], 'classification_results_aggregated.npy')
            np.save(cls_data_path, aggregated_classification)
            print(f"ğŸ“Š èšåˆåˆ†ç±»ç»“æœå·²ä¿å­˜ä¸º {cls_data_path}")
    
    print(f"\nâœ… å¤šæ¬¡è¿è¡Œé²æ£’æ€§åˆ†æå®Œæˆ!")
    print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {config['output_dir']}")
    print(f"ğŸ¯ ç¨³å®šæ€§æå‡: é€šè¿‡ {config['n_runs']} æ¬¡è¿è¡Œå–å¹³å‡ï¼Œé™ä½éšæœºæ³¢åŠ¨")
    
    return aggregated_regression, aggregated_classification

# =============================================================================
# å…¥å£ç‚¹
# =============================================================================

if __name__ == '__main__':
    # è¿è¡Œå®Œæ•´åˆ†æ
    regression_results, classification_results = run_robustness_analysis()