#!/usr/bin/env python3
"""
æµ‹è¯• causal_split åŠŸèƒ½çš„è„šæœ¬
===============================

å±•ç¤º causal_split å¦‚ä½•è¿›è¡Œæ•°æ®åˆ†å‰²å’Œå¼‚å¸¸æ³¨å…¥ï¼ŒåŒ…æ‹¬ï¼š
1. åŸºæœ¬æ•°æ®åˆ†å‰²åŠŸèƒ½
2. å¼‚å¸¸æ³¨å…¥ç­–ç•¥æµ‹è¯• (shuffle vs outlier)
3. ä¸åŒä»»åŠ¡ç±»å‹ (å›å½’ vs åˆ†ç±»)
4. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
5. å¯è§†åŒ–å¼‚å¸¸æ³¨å…¥æ•ˆæœ
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
import sys
import os
import warnings

# å¿½ç•¥seabornç‰¹å®šFutureWarningï¼Œä¿æŒè¾“å‡ºæ¸…æ´
warnings.filterwarnings('ignore', message="use_inf_as_na option is deprecated")

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from causal_sklearn.utils import causal_split, add_label_anomalies, validate_anomaly_injection, print_anomaly_summary
from sklearn.datasets import make_regression, make_classification


def test_basic_split():
    """æµ‹è¯•åŸºæœ¬çš„æ•°æ®åˆ†å‰²åŠŸèƒ½"""
    print("ğŸ”„ 1. åŸºæœ¬æ•°æ®åˆ†å‰²æµ‹è¯•")
    print("-" * 40)
    
    # ç”Ÿæˆæµ‹è¯•æ•°æ®
    X, y = make_regression(n_samples=1000, n_features=5, noise=0.1, random_state=42)
    
    # åŸºæœ¬åˆ†å‰²ï¼ˆæ— å¼‚å¸¸æ³¨å…¥ï¼‰
    X_train, X_test, y_train, y_test = causal_split(
        X, y,
        test_size=0.2,
        random_state=42,
        verbose=True
    )
    
    print(f"âœ… åŸºæœ¬åˆ†å‰²å®Œæˆ: è®­ç»ƒé›† {len(X_train)}, æµ‹è¯•é›† {len(X_test)}")
    return X, y


def test_anomaly_strategies(X, y):
    """æµ‹è¯• 'shuffle' å¼‚å¸¸æ³¨å…¥ç­–ç•¥"""
    print(f"\nğŸ¯ 2. 'Shuffle' å¼‚å¸¸æ³¨å…¥ç­–ç•¥æµ‹è¯• (å›å½’)")
    print("-" * 40)

    strategy = 'shuffle'
    anomaly_ratio = 0.2

    print(f"\n--- æµ‹è¯•ç­–ç•¥: {strategy} ---")

    split_results, anomaly_info = causal_split(
        X, y,
        test_size=0.2,
        random_state=42,
        anomaly_ratio=anomaly_ratio,
        anomaly_type='regression',
        anomaly_strategy=strategy,
        verbose=False,  # ä¿æŒæ§åˆ¶å°æ¸…æ´
        return_anomaly_info=True
    )
    X_train, X_test, y_train, y_test = split_results

    print(f"  - è®¾å®šçš„å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.2f}")
    if anomaly_info and anomaly_info['n_anomalies'] > 0:
        original_values = anomaly_info['original_values']
        new_values = y_train[anomaly_info['anomaly_indices']]
        mae = np.mean(np.abs(new_values - original_values))
        print(f"  - å®é™…æ³¨å…¥çš„å¼‚å¸¸: {anomaly_info['n_anomalies']} (å è®­ç»ƒé›† {anomaly_info['n_anomalies'] / len(y_train):.2%})")
        print(f"  - è¢«ä¿®æ”¹æ ‡ç­¾çš„ MAE: {mae:.4f}")
    else:
        print("  - æœªæ³¨å…¥å¼‚å¸¸ã€‚")

    results = {
        strategy: {
            'X_train': X_train,
            'y_train': y_train,
            'anomaly_info': anomaly_info
        }
    }
    return results


def test_classification_anomalies():
    """æµ‹è¯•åˆ†ç±»ä»»åŠ¡çš„'shuffle'å¼‚å¸¸æ³¨å…¥"""
    print(f"\nğŸ·ï¸ 3. 'Shuffle' å¼‚å¸¸æ³¨å…¥æµ‹è¯• (åˆ†ç±»)")
    print("-" * 40)

    # ç”Ÿæˆåˆ†ç±»æ•°æ®
    X_cls, y_cls = make_classification(n_samples=500, n_features=4, n_classes=3,
                                       n_informative=4, n_redundant=0, random_state=42)

    strategy = 'shuffle'
    anomaly_ratio = 0.15

    print(f"\n--- æµ‹è¯•åˆ†ç±»ç­–ç•¥: {strategy} ---")

    split_results, anomaly_info = causal_split(
        X_cls, y_cls,
        test_size=0.25,
        random_state=42,
        anomaly_ratio=anomaly_ratio,
        anomaly_type='classification',
        anomaly_strategy=strategy,
        verbose=False, # ä¿æŒæ§åˆ¶å°æ¸…æ´
        return_anomaly_info=True
    )
    X_train, X_test, y_train, y_test = split_results
    
    print(f"  - è®¾å®šçš„å¼‚å¸¸æ¯”ä¾‹: {anomaly_ratio:.2f}")
    if anomaly_info and anomaly_info['changes_made'] > 0:
        actual_change_ratio = anomaly_info['changes_made'] / len(y_train)
        print(f"  - å®é™…æ³¨å…¥çš„å¼‚å¸¸: {anomaly_info['n_anomalies']}")
        print(f"  - å®é™…è¢«æ”¹å˜çš„æ ‡ç­¾å æ¯”: {actual_change_ratio:.2%}")
    else:
        print("  - æœªæ³¨å…¥å¼‚å¸¸æˆ–æ²¡æœ‰æ ‡ç­¾è¢«æ”¹å˜ã€‚")


def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæ¡ä»¶"""
    print(f"\nâš ï¸ 4. è¾¹ç•Œæ¡ä»¶æµ‹è¯•")
    print("-" * 40)
    
    # å°æ•°æ®é›†
    X_small = np.random.randn(10, 3)
    y_small = np.random.randn(10)
    
    print("\n--- å°æ•°æ®é›†ï¼ˆ10æ ·æœ¬ï¼‰---")
    split_results, anomaly_info = causal_split(
        X_small, y_small,
        test_size=0.3,
        random_state=42,
        anomaly_ratio=0.1,  # æœŸæœ›1ä¸ªå¼‚å¸¸ï¼Œä½†å¯èƒ½ä¸º0
        anomaly_type='regression',
        anomaly_strategy='shuffle',
        verbose=True,
        return_anomaly_info=True
    )
    X_train, X_test, y_train, y_test = split_results
    
    # é›¶å¼‚å¸¸æ¯”ä¾‹
    print("\n--- é›¶å¼‚å¸¸æ¯”ä¾‹æµ‹è¯• ---")
    X_train, X_test, y_train, y_test = causal_split(
        X_small, y_small,
        test_size=0.3,
        random_state=42,
        anomaly_ratio=0.0,
        verbose=True
    )


def visualize_anomaly_effects(results):
    """å¯è§†åŒ–'shuffle'ç­–ç•¥çš„å¼‚å¸¸æ³¨å…¥æ•ˆæœ"""
    print(f"\nğŸ“Š 5. å¼‚å¸¸æ³¨å…¥æ•ˆæœå¯è§†åŒ– ('shuffle' ç­–ç•¥)")
    print("-" * 40)

    try:
        strategy = 'shuffle'
        if strategy not in results:
            print(f"âš ï¸ ç»“æœä¸­æœªæ‰¾åˆ° '{strategy}' ç­–ç•¥çš„ä¿¡æ¯ï¼Œè·³è¿‡å¯è§†åŒ–ã€‚")
            return

        data = results[strategy]
        
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))

        y_train = data['y_train']
        anomaly_info = data['anomaly_info']

        # éªŒè¯ "shuffle" ç­–ç•¥æ˜¯å¦ä¿æŒäº†æ ‡ç­¾çš„æ•´ä½“åˆ†å¸ƒ
        ax.set_title(f'Distribution Validation for Shuffle Strategy')
        sns.kdeplot(y_train, ax=ax, label='Overall Label Distribution', color='blue', fill=True, alpha=0.1)
        
        if anomaly_info['n_anomalies'] > 0:
            original_values = anomaly_info['original_values']
            shuffled_indices = anomaly_info['anomaly_indices']
            shuffled_new_values = y_train[shuffled_indices]
            
            sns.kdeplot(shuffled_new_values, ax=ax, label='Shuffled Labels Distribution', color='red', linewidth=2.5, linestyle='--')
            sns.kdeplot(original_values, ax=ax, label='Original Labels Distribution (pre-shuffle)', color='green', linewidth=2)

        ax.set_xlabel('Label Value')
        ax.set_ylabel('Density')
        ax.legend()

        plt.tight_layout()
        save_path = os.path.join(os.path.dirname(__file__), 'anomaly_visualization.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
        plt.close()

    except Exception as e:
        print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥ (å¯èƒ½æ˜¯æ˜¾ç¤ºç¯å¢ƒé—®é¢˜): {e}")


def test_reproducibility():
    """æµ‹è¯•å¯é‡ç°æ€§"""
    print(f"\nğŸ” 6. å¯é‡ç°æ€§æµ‹è¯•")
    print("-" * 40)
    
    X, y = make_regression(n_samples=100, n_features=3, random_state=42)
    
    # è¿è¡Œä¸¤æ¬¡ç›¸åŒçš„åˆ†å‰²
    results1 = causal_split(X, y, test_size=0.2, random_state=42, 
                           anomaly_ratio=0.1, anomaly_strategy='shuffle',
                           return_anomaly_info=True)
    
    results2 = causal_split(X, y, test_size=0.2, random_state=42,
                           anomaly_ratio=0.1, anomaly_strategy='shuffle', 
                           return_anomaly_info=True)
    
    # æ£€æŸ¥æ˜¯å¦å®Œå…¨ä¸€è‡´
    X_train1, X_test1, y_train1, y_test1 = results1[0]
    anomaly_info1 = results1[1]
    
    X_train2, X_test2, y_train2, y_test2 = results2[0]
    anomaly_info2 = results2[1]
    
    train_identical = np.allclose(X_train1, X_train2) and np.allclose(y_train1, y_train2)
    test_identical = np.allclose(X_test1, X_test2) and np.allclose(y_test1, y_test2)
    anomaly_identical = (anomaly_info1['anomaly_indices'] == anomaly_info2['anomaly_indices'])
    
    if train_identical and test_identical and anomaly_identical:
        print("âœ… å¯é‡ç°æ€§æµ‹è¯•é€šè¿‡ï¼šç›¸åŒéšæœºç§å­äº§ç”Ÿå®Œå…¨ç›¸åŒçš„ç»“æœ")
    else:
        print("âŒ å¯é‡ç°æ€§æµ‹è¯•å¤±è´¥ï¼šç»“æœä¸ä¸€è‡´")


def generate_summary_report():
    """ç”Ÿæˆæµ‹è¯•æ‘˜è¦æŠ¥å‘Š"""
    print(f"\nğŸ“‹ 7. æµ‹è¯•æ‘˜è¦æŠ¥å‘Š (èšç„¦ 'shuffle' ç­–ç•¥)")
    print("=" * 50)
    
    summary = {
        "åŠŸèƒ½": [
            "âœ… åŸºæœ¬æ•°æ®åˆ†å‰²",
            "âœ… 'Shuffle' å¼‚å¸¸æ³¨å…¥ (å›å½’)",
            "âœ… 'Shuffle' å¼‚å¸¸æ³¨å…¥ (åˆ†ç±»)", 
            "âœ… è¾¹ç•Œæ¡ä»¶å¤„ç†",
            "âœ… è¯¦ç»†ä¿¡æ¯æŠ¥å‘Š",
            "âœ… å¯é‡ç°æ€§ä¿è¯"
        ],
        "æ ¸å¿ƒç­–ç•¥": [
            "ğŸ¯ shuffle: éšæœºåŒ–è®­ç»ƒé›†æ ‡ç­¾ï¼Œæ¨¡æ‹Ÿå› æœå…³ç³»çš„ç ´åï¼ŒåŒæ—¶ä¿æŒæ ‡ç­¾çš„è¾¹ç¼˜åˆ†å¸ƒä¸å˜ã€‚"
        ],
        "æ ¸å¿ƒç‰¹æ€§": [
            "ğŸ”’ æµ‹è¯•é›†å§‹ç»ˆä¿æŒçº¯å‡€",
            "ğŸ“Š é€šè¿‡å¯è§†åŒ–éªŒè¯åˆ†å¸ƒä¸€è‡´æ€§",
            "âš¡ é«˜æ•ˆçš„å®ç°ï¼ˆåŸºäºsklearnï¼‰"
        ]
    }
    
    for category, items in summary.items():
        print(f"\n{category}:")
        for item in items:
            print(f"  {item}")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª causal_split åŠŸèƒ½å…¨é¢æµ‹è¯•")
    print("=" * 60)
    print("ç›®æ ‡ï¼šéªŒè¯æ•°æ®åˆ†å‰²å’Œå¼‚å¸¸æ³¨å…¥çš„æ‰€æœ‰åŠŸèƒ½")
    print()
    
    # 1. åŸºæœ¬åˆ†å‰²æµ‹è¯•
    X, y = test_basic_split()
    
    # 2. å¼‚å¸¸ç­–ç•¥å¯¹æ¯”
    results = test_anomaly_strategies(X, y)
    
    # 3. åˆ†ç±»ä»»åŠ¡æµ‹è¯•
    test_classification_anomalies()
    
    # 4. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
    test_edge_cases()
    
    # 5. å¯è§†åŒ–ï¼ˆå¯é€‰ï¼‰
    visualize_anomaly_effects(results)
    
    # 6. å¯é‡ç°æ€§æµ‹è¯•
    test_reproducibility()
    
    # 7. ç”Ÿæˆæ‘˜è¦æŠ¥å‘Š
    generate_summary_report()
    
    print(f"\nğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("ğŸ’¡ causal_split å‡½æ•°å·¥ä½œæ­£å¸¸ï¼Œå¯ä»¥å®‰å…¨ç”¨äºæ•°æ®åˆ†å‰²å’Œå¼‚å¸¸æ³¨å…¥")


if __name__ == "__main__":
    main()