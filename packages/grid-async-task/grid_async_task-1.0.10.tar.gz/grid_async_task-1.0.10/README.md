# grid å¼‚æ­¥ä»»åŠ¡å¤„ç†æ’ä»¶

ä¸€ä¸ªé€šç”¨çš„å¼‚æ­¥ä»»åŠ¡å¤„ç†æ’ä»¶ï¼Œæ”¯æŒRabbitMQé˜Ÿåˆ—ç›‘å¬ã€ä»»åŠ¡é‡è¯•ã€è¿›åº¦é€šçŸ¥ã€å›è°ƒç­‰åŠŸèƒ½ã€‚ä¸“ä¸ºKubernetes + KEDAè‡ªåŠ¨æ‰©ç¼©å®¹ç¯å¢ƒè®¾è®¡ã€‚

## åŠŸèƒ½ç‰¹æ€§

- ğŸš€ **RabbitMQé˜Ÿåˆ—ç›‘å¬**: æ”¯æŒä»RabbitMQé˜Ÿåˆ—è·å–ä»»åŠ¡ï¼Œæ¯æ¬¡å¤„ç†ä¸€ä¸ªä»»åŠ¡
- ğŸ”„ **æ™ºèƒ½é‡è¯•æœºåˆ¶**: æ”¯æŒä»»åŠ¡æ‰§è¡Œå¤±è´¥æ—¶çš„é‡è¯•ï¼Œå¯é…ç½®é‡è¯•æ¬¡æ•°å’Œç­–ç•¥
- ğŸ“Š **è¿›åº¦é€šçŸ¥**: æ”¯æŒä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿›åº¦é€šçŸ¥
- ğŸ“ **å¤šç§å›è°ƒæ–¹å¼**: æ”¯æŒHTTPå’ŒRabbitMQä¸¤ç§å›è°ƒé€šçŸ¥æ–¹å¼
- ğŸ’¾ **ä»»åŠ¡æŒä¹…åŒ–**: åŸºäºMySQLçš„ä»»åŠ¡çŠ¶æ€æŒä¹…åŒ–å­˜å‚¨
- ğŸ“ **è¯¦ç»†æ—¥å¿—**: å®Œæ•´çš„ä»»åŠ¡æ‰§è¡Œæ—¥å¿—è®°å½•
- ğŸ”” **é£ä¹¦é€šçŸ¥**: ä»»åŠ¡å¤±è´¥æ—¶çš„é£ä¹¦webhooké€šçŸ¥
- ğŸ—ï¸ **é«˜å¯ç”¨è®¾è®¡**: æ”¯æŒç½‘ç»œä¸­æ–­é‡è¿ã€æ•°æ®åº“è¿æ¥æ± ç­‰
- â° **ç©ºé—²è¶…æ—¶**: æ”¯æŒç©ºé—²è¶…æ—¶è‡ªåŠ¨é€€å‡ºï¼Œä¼˜åŒ–èµ„æºä½¿ç”¨
- âš™ï¸ **ç¯å¢ƒé…ç½®**: é€šè¿‡ç¯å¢ƒå˜é‡æˆ–.envæ–‡ä»¶è¿›è¡Œé…ç½®

## å®‰è£…

```bash
pip install grid-async-task
```

## å¿«é€Ÿå¼€å§‹

### 1. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶æˆ–è®¾ç½®ç¯å¢ƒå˜é‡ï¼š

```env
# ====================================
# Gridå¼‚æ­¥ä»»åŠ¡å¤„ç†æ’ä»¶é…ç½® (å¿…å¡«)
# ====================================

# RabbitMQ AMQPè¿æ¥URL
GRID_ASYNC_TASK_AMQP_URL=amqp://guest:guest@localhost:5672/

# ä»»åŠ¡é˜Ÿåˆ—åç§°
GRID_ASYNC_TASK_QUEUE=task_queue

# MySQLè¿æ¥URL 
GRID_ASYNC_TASK_MYSQL_URL=mysql+pymysql://root:password@localhost:3306/task_db?charset=utf8mb4

# ====================================
# å¯é€‰é…ç½®é¡¹
# ====================================

# æ•°æ®åº“è¡¨é…ç½®ï¼ˆé¿å…è¡¨åå†²çªï¼‰
GRID_ASYNC_TASK_TABLE_PREFIX=grid_async_task_
GRID_ASYNC_TASK_TABLE_NAME=tasks

# ä»»åŠ¡é‡è¯•é…ç½®
GRID_ASYNC_TASK_MAX_RETRY_COUNT=3
GRID_ASYNC_TASK_RETRY_DELAY=60

# ç©ºé—²è¶…æ—¶é…ç½®ï¼ˆç§’ï¼‰ï¼Œ0è¡¨ç¤ºæ°¸ä¸é€€å‡º
GRID_ASYNC_TASK_IDLE_TIMEOUT=0

# æ—¥å¿—é…ç½®
GRID_ASYNC_TASK_LOG_LEVEL=INFO
GRID_ASYNC_TASK_LOG_DIR=logs

# é£ä¹¦é€šçŸ¥ï¼ˆå¯é€‰ï¼Œä»»åŠ¡å¤±è´¥æ—¶å‘é€é€šçŸ¥ï¼‰
GRID_ASYNC_TASK_FEISHU_WEBHOOK_URL=https://open.feishu.cn/open-apis/bot/v2/hook/xxx
```

**é…ç½®è¯´æ˜**ï¼š
- ğŸ“‹ å‚è€ƒé¡¹ç›®ç›®å½•ä¸‹çš„ `env_example.txt` æ–‡ä»¶æŸ¥çœ‹å®Œæ•´é…ç½®ç¤ºä¾‹
- ğŸ”’ æ•æ„Ÿä¿¡æ¯ï¼ˆå¯†ç ã€å¯†é’¥ç­‰ï¼‰è¯·å¦¥å–„ä¿ç®¡ï¼Œä¸è¦æäº¤åˆ°ä»£ç ä»“åº“

### 2. åˆ›å»ºä»»åŠ¡å¤„ç†å™¨

```python
from grid_async_task import TaskHandler, TaskProcessor

class MyTaskHandler(TaskHandler):
    def execute(self, task_data):
        """æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡é€»è¾‘"""
        # æŠ¥å‘Šè¿›åº¦
        self.report_progress(20, "å¼€å§‹å¤„ç†...")
        
        # æ‰§è¡Œä»»åŠ¡é€»è¾‘
        result = self.process_data(task_data)
        
        # æŠ¥å‘Šè¿›åº¦
        self.report_progress(100, "å¤„ç†å®Œæˆ")
        
        return result
    
    def process_data(self, data):
        # ä½ çš„å…·ä½“ä¸šåŠ¡é€»è¾‘
        return {"status": "success", "result": data}

# å¯åŠ¨ä»»åŠ¡å¤„ç†å™¨
processor = TaskProcessor(handler=MyTaskHandler())
processor.start()
```

### 3. ä»»åŠ¡ç”Ÿäº§è€…ç¤ºä¾‹

```python
from grid_async_task import TaskProducer

# åŸºæœ¬ä½¿ç”¨ - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤é˜Ÿåˆ—
producer = TaskProducer()
producer.send_task({
    "task_id": "unique_task_id",
    "task_type": "data_processing",
    "data": {"input": "test_data"},
    "callback_url": "http://your-api.com/callback",
    "retry_count": 3
})
```

### 4. åŠ¨æ€é˜Ÿåˆ—åŠŸèƒ½ï¼ˆNEWï¼ï¼‰

**TaskProducer** ç°åœ¨æ”¯æŒåŠ¨æ€ä¼ å…¥é˜Ÿåˆ—åç§°ï¼Œè®©æ‚¨å¯ä»¥å°†ä¸åŒç±»å‹çš„ä»»åŠ¡å‘é€åˆ°ä¸åŒçš„é˜Ÿåˆ—ä¸­ï¼Œå®ç°æ›´çµæ´»çš„ä»»åŠ¡è°ƒåº¦ã€‚

#### åŸºæœ¬ç”¨æ³•

```python
from grid_async_task import TaskProducer

# æ–¹å¼1ï¼šæŒ‡å®šé»˜è®¤é˜Ÿåˆ—
producer = TaskProducer(default_queue="my_custom_queue")
task_id = producer.send_task(task_data)  # å‘é€åˆ° my_custom_queue

# æ–¹å¼2ï¼šåŠ¨æ€æŒ‡å®šé˜Ÿåˆ—
producer = TaskProducer()
task_id = producer.send_task(task_data, queue_name="high_priority_queue")

# æ–¹å¼3ï¼šä½¿ç”¨ä¾¿æ·æ–¹æ³•
task_id = producer.send_task_to_queue(task_data, "gpu_queue")
```

#### æ‰¹é‡å‘é€ä»»åŠ¡

```python
# æ‰¹é‡å‘é€åˆ°æŒ‡å®šé˜Ÿåˆ—
batch_tasks = [
    {"task_data": {"task_type": "validation", "data": {"file": f"file_{i}"}}
     for i in range(10)
]
task_ids = producer.batch_send_tasks(batch_tasks, queue_name="validation_queue")

# æ‰¹é‡å‘é€åˆ°é»˜è®¤é˜Ÿåˆ—
task_ids = producer.batch_send_tasks(batch_tasks)
```

#### é˜Ÿåˆ—ç®¡ç†

```python
# æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²å£°æ˜
if not producer.is_queue_declared("new_queue"):
    producer.send_task(task_data, queue_name="new_queue")  # è‡ªåŠ¨å£°æ˜é˜Ÿåˆ—

# æŸ¥çœ‹å·²å£°æ˜çš„é˜Ÿåˆ—
declared_queues = producer.get_declared_queues()
print(f"å·²å£°æ˜çš„é˜Ÿåˆ—: {declared_queues}")
```

#### å®é™…åº”ç”¨åœºæ™¯

```python
# æŒ‰ä¼˜å…ˆçº§åˆ†å‘ä»»åŠ¡
high_priority_task = {
    "task_type": "urgent_analysis", 
    "data": {"priority": "high"}
}
producer.send_task(high_priority_task, queue_name="high_priority_queue")

low_priority_task = {
    "task_type": "batch_processing", 
    "data": {"priority": "low"}
}
producer.send_task(low_priority_task, queue_name="low_priority_queue")

# æŒ‰èµ„æºç±»å‹åˆ†å‘ä»»åŠ¡
gpu_task = {"task_type": "ml_training", "data": {"model": "cnn"}}
producer.send_task(gpu_task, queue_name="gpu_queue")

cpu_task = {"task_type": "data_processing", "data": {"format": "csv"}}
producer.send_task(cpu_task, queue_name="cpu_queue")
```

## åè®®è¯´æ˜

### ä»»åŠ¡æ¶ˆæ¯åè®®

#### RabbitMQ æ¶ˆæ¯æ ¼å¼

å‘é€åˆ°é˜Ÿåˆ—çš„æ¶ˆæ¯å¿…é¡»æ˜¯ JSON æ ¼å¼ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š

```json
{
    "task_id": "string",              // å¿…éœ€ï¼šä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦
    "task_type": "string",            // å¯é€‰ï¼šä»»åŠ¡ç±»å‹ï¼Œé»˜è®¤ "default"
    "data": {},                       // å¯é€‰ï¼šä»»åŠ¡å…·ä½“æ•°æ®ï¼Œä»»æ„ JSON å¯¹è±¡
    "max_retry_count": 3,             // å¯é€‰ï¼šæœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ 0
    "callback_url": "string",         // å¯é€‰ï¼šHTTP å›è°ƒåœ°å€
    "callback_type": "http|rabbitmq", // å¯é€‰ï¼šå›è°ƒç±»å‹ï¼Œé»˜è®¤ "http"
    "callback_data": {}               // å¯é€‰ï¼šå›è°ƒé™„åŠ æ•°æ®
}
```

#### å­—æ®µè¯´æ˜

| å­—æ®µ | ç±»å‹ | å¿…éœ€ | è¯´æ˜ |
|-----|------|------|------|
| `task_id` | string | âœ“ | ä»»åŠ¡å”¯ä¸€æ ‡è¯†ç¬¦ï¼Œå»ºè®®ä½¿ç”¨UUID |
| `task_type` | string | âœ— | ä»»åŠ¡ç±»å‹æ ‡è¯†ï¼Œç”¨äºä¸šåŠ¡åˆ†ç±» |
| `data` | object | âœ— | ä»»åŠ¡æ‰§è¡Œæ‰€éœ€çš„å…·ä½“æ•°æ® |
| `max_retry_count` | int | âœ— | æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œ0è¡¨ç¤ºä¸é‡è¯• |
| `callback_url` | string | âœ— | ä»»åŠ¡å®Œæˆåçš„HTTPå›è°ƒåœ°å€ |
| `callback_type` | string | âœ— | å›è°ƒæ–¹å¼ï¼š`http` æˆ– `rabbitmq` |
| `callback_data` | object | âœ— | å›è°ƒæ—¶æºå¸¦çš„é¢å¤–æ•°æ® |

### ä»»åŠ¡çŠ¶æ€å®šä¹‰

| çŠ¶æ€ | è¯´æ˜ |
|------|------|
| `pending` | ç­‰å¾…å¤„ç† |
| `running` | æ‰§è¡Œä¸­ |
| `success` | æ‰§è¡ŒæˆåŠŸ |
| `failed` | æ‰§è¡Œå¤±è´¥ |
| `retrying` | é‡è¯•ä¸­ |

### å›è°ƒåè®®

#### HTTP å›è°ƒ

å½“ä»»åŠ¡å®Œæˆæ—¶ï¼Œç³»ç»Ÿä¼šå‘ `callback_url` å‘é€ POST è¯·æ±‚ï¼š

```json
{
    "task_id": "string",        // ä»»åŠ¡ID
    "status": "success|failed", // ä»»åŠ¡çŠ¶æ€
    "result": {},               // ä»»åŠ¡ç»“æœæ•°æ®
    "timestamp": "string",      // å®Œæˆæ—¶é—´ (ISO 8601)
    "callback_data": {}         // ä»»åŠ¡æäº¤æ—¶çš„å›è°ƒæ•°æ®
}
```

**HTTP å›è°ƒè¦æ±‚ï¼š**
- è¯·æ±‚æ–¹æ³•ï¼š`POST`
- Content-Typeï¼š`application/json`
- è¶…æ—¶æ—¶é—´ï¼š30ç§’
- é‡è¯•æ¬¡æ•°ï¼š3æ¬¡
- æˆåŠŸåˆ¤æ–­ï¼šè¿”å›çŠ¶æ€ç  `200`

#### RabbitMQ å›è°ƒ

å½“ `callback_type` ä¸º `rabbitmq` æ—¶ï¼Œå›è°ƒæ¶ˆæ¯ä¼šå‘é€åˆ°æŒ‡å®šé˜Ÿåˆ—ï¼š

```json
{
    "task_id": "string",
    "status": "success|failed",
    "result": {},
    "timestamp": "string",
    "callback_data": {
        "queue_name": "callback_queue"  // å¯é€‰ï¼šæŒ‡å®šé˜Ÿåˆ—åï¼Œé»˜è®¤ "callback_queue"
    }
}
```

### è¿›åº¦é€šçŸ¥åè®®

ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­çš„è¿›åº¦ä¼šæ›´æ–°åˆ°æ•°æ®åº“ï¼Œå¯é€šè¿‡æŸ¥è¯¢APIè·å–ï¼š

```json
{
    "task_id": "string",
    "progress": 75,                    // è¿›åº¦ç™¾åˆ†æ¯” (0-100)
    "progress_message": "å¤„ç†ä¸­...",   // è¿›åº¦æè¿°
    "status": "running",
    "updated_at": "2024-01-15T10:30:00Z"
}
```

### å¤šè¯­è¨€æ¥å…¥ç¤ºä¾‹

#### Python

```python
import json
import pika
import uuid

# è¿æ¥RabbitMQ
connection = pika.BlockingConnection(
    pika.ConnectionParameters('localhost')
)
channel = connection.channel()

# å‘é€ä»»åŠ¡
task = {
    "task_id": str(uuid.uuid4()),
    "task_type": "data_processing",
    "data": {"input": "test_data"},
    "callback_url": "http://your-api.com/callback",
    "max_retry_count": 3
}

channel.basic_publish(
    exchange='',
    routing_key='task_queue',
    body=json.dumps(task),
    properties=pika.BasicProperties(delivery_mode=2)
)
```

#### Node.js

```javascript
const amqp = require('amqplib');
const { v4: uuidv4 } = require('uuid');

async function sendTask() {
    const connection = await amqp.connect('amqp://localhost');
    const channel = await connection.createChannel();
    
    const task = {
        task_id: uuidv4(),
        task_type: 'data_processing',
        data: { input: 'test_data' },
        callback_url: 'http://your-api.com/callback',
        max_retry_count: 3
    };
    
    await channel.sendToQueue(
        'task_queue', 
        Buffer.from(JSON.stringify(task)),
        { persistent: true }
    );
}
```

#### Java (Spring Boot)

```java
@Service
public class TaskProducer {
    
    @Autowired
    private RabbitTemplate rabbitTemplate;
    
    public String sendTask(String taskType, Object data, String callbackUrl) {
        String taskId = UUID.randomUUID().toString();
        
        Map<String, Object> task = new HashMap<>();
        task.put("task_id", taskId);
        task.put("task_type", taskType);
        task.put("data", data);
        task.put("callback_url", callbackUrl);
        task.put("max_retry_count", 3);
        
        rabbitTemplate.convertAndSend("task_queue", task);
        return taskId;
    }
}
```

#### Go

```go
package main

import (
    "encoding/json"
    "github.com/google/uuid"
    "github.com/streadway/amqp"
)

type Task struct {
    TaskID         string      `json:"task_id"`
    TaskType       string      `json:"task_type"`
    Data           interface{} `json:"data"`
    CallbackURL    string      `json:"callback_url"`
    MaxRetryCount  int         `json:"max_retry_count"`
}

func sendTask() error {
    conn, err := amqp.Dial("amqp://localhost")
    if err != nil {
        return err
    }
    defer conn.Close()
    
    ch, err := conn.Channel()
    if err != nil {
        return err
    }
    defer ch.Close()
    
    task := Task{
        TaskID:        uuid.New().String(),
        TaskType:      "data_processing",
        Data:          map[string]string{"input": "test_data"},
        CallbackURL:   "http://your-api.com/callback",
        MaxRetryCount: 3,
    }
    
    body, _ := json.Marshal(task)
    
    return ch.Publish(
        "",           // exchange
        "task_queue", // routing key
        false,        // mandatory
        false,        // immediate
        amqp.Publishing{
            DeliveryMode: amqp.Persistent,
            ContentType:  "application/json",
            Body:         body,
        })
}
```

#### PHP

```php
<?php
require_once __DIR__ . '/vendor/autoload.php';
use PhpAmqpLib\Connection\AMQPStreamConnection;
use PhpAmqpLib\Message\AMQPMessage;

function sendTask() {
    $connection = new AMQPStreamConnection('localhost', 5672, 'guest', 'guest');
    $channel = $connection->channel();
    
    $task = [
        'task_id' => uniqid(),
        'task_type' => 'data_processing',
        'data' => ['input' => 'test_data'],
        'callback_url' => 'http://your-api.com/callback',
        'max_retry_count' => 3
    ];
    
    $msg = new AMQPMessage(
        json_encode($task),
        ['delivery_mode' => AMQPMessage::DELIVERY_MODE_PERSISTENT]
    );
    
    $channel->basic_publish($msg, '', 'task_queue');
    
    $channel->close();
    $connection->close();
}
?>
```

### é”™è¯¯å¤„ç†

#### å¸¸è§é”™è¯¯ç 

| é”™è¯¯ç±»å‹ | è¯´æ˜ | å¤„ç†å»ºè®® |
|---------|------|----------|
| `ValidationError` | ä»»åŠ¡æ•°æ®éªŒè¯å¤±è´¥ | æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå¿…éœ€å­—æ®µ |
| `ConnectionError` | æ•°æ®åº“è¿æ¥å¤±è´¥ | æ£€æŸ¥æ•°æ®åº“é…ç½®å’Œç½‘ç»œ |
| `TimeoutError` | ä»»åŠ¡æ‰§è¡Œè¶…æ—¶ | å¢åŠ è¶…æ—¶æ—¶é—´æˆ–ä¼˜åŒ–ä»»åŠ¡é€»è¾‘ |
| `RetryExhausted` | é‡è¯•æ¬¡æ•°è€—å°½ | æ£€æŸ¥ä»»åŠ¡é€»è¾‘æˆ–å¢åŠ é‡è¯•æ¬¡æ•° |

#### é”™è¯¯å›è°ƒæ ¼å¼

```json
{
    "task_id": "string",
    "status": "failed",
    "result": {
        "error": "é”™è¯¯æè¿°",
        "error_type": "ValidationError"
    },
    "timestamp": "2024-01-15T10:30:00Z",
    "callback_data": {}
}
```

**æ³¨æ„ï¼š** ä¸ºäº†å®‰å…¨è€ƒè™‘ï¼Œè¯¦ç»†çš„é”™è¯¯å †æ ˆä¿¡æ¯ï¼ˆtracebackï¼‰ä¸ä¼šåœ¨å›è°ƒé€šçŸ¥ä¸­è¿”å›ï¼Œåªä¼šåœ¨é£ä¹¦webhooké€šçŸ¥ä¸­åŒ…å«ï¼Œä¾¿äºå¼€å‘äººå‘˜è°ƒè¯•ã€‚

## è¯¦ç»†é…ç½®

### ç¯å¢ƒå˜é‡é…ç½®

| å˜é‡å | æè¿° | é»˜è®¤å€¼ |
|--------|------|--------|
| `RABBITMQ_HOST` | RabbitMQä¸»æœº | localhost |
| `RABBITMQ_PORT` | RabbitMQç«¯å£ | 5672 |
| `RABBITMQ_USERNAME` | RabbitMQç”¨æˆ·å | guest |
| `RABBITMQ_PASSWORD` | RabbitMQå¯†ç  | guest |
| `RABBITMQ_VHOST` | RabbitMQè™šæ‹Ÿä¸»æœº | / |
| `RABBITMQ_QUEUE` | ä»»åŠ¡é˜Ÿåˆ—åç§° | task_queue |
| `MYSQL_HOST` | MySQLä¸»æœº | localhost |
| `MYSQL_PORT` | MySQLç«¯å£ | 3306 |
| `MYSQL_DATABASE` | æ•°æ®åº“å | task_db |
| `MYSQL_USERNAME` | æ•°æ®åº“ç”¨æˆ·å | root |
| `MYSQL_PASSWORD` | æ•°æ®åº“å¯†ç  | password |
| `FEISHU_WEBHOOK_URL` | é£ä¹¦webhookåœ°å€ | - |
| `LOG_LEVEL` | æ—¥å¿—çº§åˆ« | INFO |
| `LOG_DIR` | æ—¥å¿—ç›®å½• | logs |

### ä»»åŠ¡è¡¨ç»“æ„

æ’ä»¶ä¼šè‡ªåŠ¨åˆ›å»ºä»¥ä¸‹ä»»åŠ¡è¡¨ï¼š

```sql
CREATE TABLE IF NOT EXISTS async_tasks (
    id VARCHAR(255) PRIMARY KEY,
    task_type VARCHAR(100) NOT NULL,
    status ENUM('pending', 'running', 'success', 'failed', 'retrying') DEFAULT 'pending',
    data JSON,
    result JSON,
    error_message TEXT,
    progress INT DEFAULT 0,
    retry_count INT DEFAULT 0,
    max_retry_count INT DEFAULT 0,
    callback_url VARCHAR(500),
    callback_type ENUM('http', 'rabbitmq') DEFAULT 'http',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    started_at TIMESTAMP NULL,
    completed_at TIMESTAMP NULL
);
```

## APIå‚è€ƒ

### TaskProducer

ä»»åŠ¡ç”Ÿäº§è€…ç”¨äºå‘é€ä»»åŠ¡åˆ°RabbitMQé˜Ÿåˆ—ï¼š

```python
class TaskProducer:
    def __init__(self, default_queue: Optional[str] = None):
        """
        åˆå§‹åŒ–ä»»åŠ¡ç”Ÿäº§è€…
        
        Args:
            default_queue: é»˜è®¤é˜Ÿåˆ—åç§°ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é˜Ÿåˆ—åç§°
        """
    
    def send_task(self, task_data: Dict[str, Any], task_id: Optional[str] = None, 
                  queue_name: Optional[str] = None) -> str:
        """
        å‘é€ä»»åŠ¡åˆ°æŒ‡å®šé˜Ÿåˆ—
        
        Args:
            task_data: ä»»åŠ¡æ•°æ®
            task_id: ä»»åŠ¡IDï¼Œå¦‚æœä¸æä¾›åˆ™è‡ªåŠ¨ç”Ÿæˆ
            queue_name: é˜Ÿåˆ—åç§°ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é˜Ÿåˆ—
            
        Returns:
            ä»»åŠ¡ID
        """
    
    def send_task_to_queue(self, task_data: Dict[str, Any], queue_name: str, 
                          task_id: Optional[str] = None) -> str:
        """å‘é€ä»»åŠ¡åˆ°æŒ‡å®šé˜Ÿåˆ—çš„ä¾¿æ·æ–¹æ³•"""
    
    def batch_send_tasks(self, tasks: List[Dict[str, Any]], 
                        queue_name: Optional[str] = None) -> List[str]:
        """æ‰¹é‡å‘é€ä»»åŠ¡åˆ°æŒ‡å®šé˜Ÿåˆ—"""
    
    def get_declared_queues(self) -> set:
        """è·å–å·²å£°æ˜çš„é˜Ÿåˆ—åˆ—è¡¨"""
    
    def is_queue_declared(self, queue_name: str) -> bool:
        """æ£€æŸ¥é˜Ÿåˆ—æ˜¯å¦å·²å£°æ˜"""
    
    def close(self):
        """å…³é—­è¿æ¥"""
```

### TaskHandler

è‡ªå®šä¹‰ä»»åŠ¡å¤„ç†å™¨éœ€è¦ç»§æ‰¿ `TaskHandler` ç±»ï¼š

```python
class TaskHandler:
    def execute(self, task_data):
        """æ‰§è¡Œä»»åŠ¡çš„æ ¸å¿ƒæ–¹æ³•ï¼Œå­ç±»å¿…é¡»å®ç°"""
        raise NotImplementedError
    
    def report_progress(self, progress, message=""):
        """æŠ¥å‘Šä»»åŠ¡è¿›åº¦"""
        pass
    
    def get_task_id(self):
        """è·å–å½“å‰ä»»åŠ¡ID"""
        return self.task_id
```

### TaskProcessor

ä»»åŠ¡å¤„ç†å™¨çš„ä¸»è¦é…ç½®é€‰é¡¹ï¼š

```python
processor = TaskProcessor(
    handler=MyTaskHandler(),
    max_retry_count=3,           # æœ€å¤§é‡è¯•æ¬¡æ•°
    retry_delay=60,              # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    progress_interval=10,        # è¿›åº¦æŠ¥å‘Šé—´éš”ï¼ˆç§’ï¼‰
    enable_auto_ack=True,        # è‡ªåŠ¨ç¡®è®¤æ¶ˆæ¯
    prefetch_count=1             # é¢„å–æ¶ˆæ¯æ•°é‡
)
```

## Dockeréƒ¨ç½²

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

CMD ["python", "-m", "grid_async_task.cli"]
```

## Kubernetes + KEDAé…ç½®

```yaml
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: task-processor-scaler
spec:
  scaleTargetRef:
    name: task-processor
  minReplicaCount: 0
  maxReplicaCount: 10
  triggers:
  - type: rabbitmq
    metadata:
      host: amqp://user:password@rabbitmq:5672/
      queueName: task_queue
      queueLength: "1"
```

## å¼€å‘

### æœ¬åœ°å¼€å‘ç¯å¢ƒ

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/grid/grid-async-task-plugin.git
cd grid-async-task-plugin

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# è¿è¡Œæµ‹è¯•
python -m pytest tests/

# æ„å»ºåŒ…
python setup.py sdist bdist_wheel
```

## ğŸ”§ æ•…éšœæ’é™¤

### é…ç½®é”™è¯¯é—®é¢˜

å¦‚æœçœ‹åˆ°ä»¥ä¸‹é”™è¯¯ä¿¡æ¯ï¼š

```
Gridå¼‚æ­¥ä»»åŠ¡æ’ä»¶é…ç½®é”™è¯¯ï¼šç¼ºå°‘å¿…éœ€çš„ç¯å¢ƒå˜é‡é…ç½®
ç¼ºå°‘çš„é…ç½®é¡¹ï¼šamqp_url, rabbitmq_queue, mysql_url
```

**è§£å†³æ–¹æ³•**ï¼š
1. æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®ï¼ˆæ³¨æ„ `GRID_ASYNC_TASK_` å‰ç¼€ï¼‰
2. å‚è€ƒé¡¹ç›®ç›®å½•ä¸‹çš„ `env_example.txt` æ–‡ä»¶é…ç½®ç¤ºä¾‹
3. ç¡®è®¤é…ç½®æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼æ­£ç¡®

### å¸¸è§é…ç½®ç¤ºä¾‹

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡æ–¹å¼1ï¼šå¯¼å‡ºç¯å¢ƒå˜é‡
export GRID_ASYNC_TASK_AMQP_URL="amqp://guest:guest@localhost:5672/"
export GRID_ASYNC_TASK_QUEUE="task_queue"
export GRID_ASYNC_TASK_MYSQL_URL="mysql+pymysql://root:password@localhost:3306/task_db?charset=utf8mb4"

# è®¾ç½®ç¯å¢ƒå˜é‡æ–¹å¼2ï¼š.envæ–‡ä»¶
echo 'GRID_ASYNC_TASK_AMQP_URL=amqp://guest:guest@localhost:5672/' > .env
echo 'GRID_ASYNC_TASK_QUEUE=task_queue' >> .env
echo 'GRID_ASYNC_TASK_MYSQL_URL=mysql+pymysql://root:password@localhost:3306/task_db?charset=utf8mb4' >> .env
```

### è¿æ¥é—®é¢˜æ’æŸ¥

1. **RabbitMQè¿æ¥å¤±è´¥**
   - æ£€æŸ¥ AMQP URL æ ¼å¼æ˜¯å¦æ­£ç¡®
   - ç¡®è®¤ RabbitMQ æœåŠ¡è¿è¡ŒçŠ¶æ€
   - éªŒè¯ç”¨æˆ·åå¯†ç å’Œè™šæ‹Ÿä¸»æœºé…ç½®

2. **MySQLè¿æ¥å¤±è´¥**
   - æ£€æŸ¥ MySQL URL æ ¼å¼å’Œè¿æ¥å‚æ•°
   - ç¡®è®¤æ•°æ®åº“æœåŠ¡è¿è¡ŒçŠ¶æ€
   - éªŒè¯æ•°æ®åº“ç”¨æˆ·æƒé™

3. **æ—¥å¿—æŸ¥çœ‹**
   - é»˜è®¤æ—¥å¿—ä¿å­˜åœ¨ `logs/` ç›®å½•
   - è°ƒæ•´ `GRID_ASYNC_TASK_LOG_LEVEL=DEBUG` è·å–è¯¦ç»†æ—¥å¿—

### æŠ€æœ¯æ”¯æŒ

- ğŸ“– æŸ¥çœ‹é¡¹ç›® Wiki è·å–æ›´å¤šå¸®åŠ©
- ğŸ› é‡åˆ° Bugï¼Ÿè¯·åœ¨ GitHub Issues ä¸­æŠ¥å‘Š
- ğŸ’¬ è®¨è®ºå’Œå»ºè®®è¯·ä½¿ç”¨ GitHub Discussions

## è®¸å¯è¯

MIT License 