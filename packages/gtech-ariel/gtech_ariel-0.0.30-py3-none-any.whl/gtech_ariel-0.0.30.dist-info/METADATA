Metadata-Version: 2.4
Name: gtech-ariel
Version: 0.0.30
Summary: Google EMEA gTech Ads Data Science Team's solution to automatically translate and dub video ads into multiple languages using AI.
Home-page: https://github.com/google-marketing-solutions/ariel
Author: Google EMEA gTech Ads Data Science Team
License: Apache Software License 2.0
Keywords: python ai genai speech-to-text translation text-to-speech video dubbing youtube gcp
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: absl-py==2.3.0
Requires-Dist: aiohappyeyeballs==2.6.1
Requires-Dist: aiohttp==3.12.13
Requires-Dist: aiosignal==1.3.2
Requires-Dist: alembic==1.16.2
Requires-Dist: annotated-types==0.7.0
Requires-Dist: antlr4-python3-runtime==4.9.3
Requires-Dist: anyio==4.9.0
Requires-Dist: appnope==0.1.4
Requires-Dist: asteroid-filterbanks==0.4.0
Requires-Dist: astunparse==1.6.3
Requires-Dist: attrs==25.3.0
Requires-Dist: av==14.4.0
Requires-Dist: backcall==0.2.0
Requires-Dist: cachetools==5.5.2
Requires-Dist: certifi==2025.6.15
Requires-Dist: cffi==1.17.1
Requires-Dist: charset-normalizer==3.4.2
Requires-Dist: click==8.2.1
Requires-Dist: cloudpickle==3.1.1
Requires-Dist: coloredlogs==15.0.1
Requires-Dist: colorlog==6.9.0
Requires-Dist: contourpy==1.3.2
Requires-Dist: ctranslate2==4.6.0
Requires-Dist: cycler==0.12.1
Requires-Dist: decorator==4.4.2
Requires-Dist: demucs==4.0.1
Requires-Dist: docopt==0.6.2
Requires-Dist: docstring-parser==0.16
Requires-Dist: dora-search==0.1.12
Requires-Dist: einops==0.8.1
Requires-Dist: elevenlabs==2.3.0
Requires-Dist: faster-whisper==1.1.1
Requires-Dist: filelock==3.18.0
Requires-Dist: flatbuffers==25.2.10
Requires-Dist: fonttools==4.58.4
Requires-Dist: frozenlist==1.7.0
Requires-Dist: fsspec==2025.5.1
Requires-Dist: future==1.0.0
Requires-Dist: gast==0.6.0
Requires-Dist: google-api-core==2.25.1
Requires-Dist: google-api-python-client==2.172.0
Requires-Dist: google-auth==2.38.0
Requires-Dist: google-auth-httplib2==0.2.0
Requires-Dist: google-auth-oauthlib==1.2.2
Requires-Dist: google-cloud-aiplatform==1.97.0
Requires-Dist: google-cloud-bigquery==3.34.0
Requires-Dist: google-cloud-core==2.4.3
Requires-Dist: google-cloud-resource-manager==1.14.2
Requires-Dist: google-cloud-storage==2.19.0
Requires-Dist: google-cloud-texttospeech==2.27.0
Requires-Dist: google-crc32c==1.7.1
Requires-Dist: google-genai==1.20.0
Requires-Dist: google-pasta==0.2.0
Requires-Dist: google-resumable-media==2.7.2
Requires-Dist: googleapis-common-protos==1.70.0
Requires-Dist: grpc-google-iam-v1==0.14.2
Requires-Dist: grpcio==1.73.0
Requires-Dist: grpcio-status==1.71.0
Requires-Dist: gspread==6.2.1
Requires-Dist: gspread-dataframe==4.0.0
Requires-Dist: h11==0.16.0
Requires-Dist: h5py==3.14.0
Requires-Dist: hf-xet==1.1.4
Requires-Dist: httpcore==1.0.9
Requires-Dist: httplib2==0.22.0
Requires-Dist: httpx==0.28.1
Requires-Dist: huggingface-hub==0.33.0
Requires-Dist: humanfriendly==10.0
Requires-Dist: hyperpyyaml==1.2.2
Requires-Dist: idna==3.10
Requires-Dist: imageio==2.37.0
Requires-Dist: imageio-ffmpeg==0.6.0
Requires-Dist: ipython==7.34.0
Requires-Dist: jedi==0.19.2
Requires-Dist: jinja2==3.1.6
Requires-Dist: joblib==1.5.1
Requires-Dist: julius==0.2.7
Requires-Dist: keras==3.10.0
Requires-Dist: kiwisolver==1.4.8
Requires-Dist: lameenc==1.8.1
Requires-Dist: libclang==18.1.1
Requires-Dist: lightning==2.5.1.post0
Requires-Dist: lightning-utilities==0.14.3
Requires-Dist: mako==1.3.10
Requires-Dist: markdown==3.8.1
Requires-Dist: markdown-it-py==3.0.0
Requires-Dist: markupsafe==3.0.2
Requires-Dist: matplotlib==3.10.3
Requires-Dist: matplotlib-inline==0.1.7
Requires-Dist: mdurl==0.1.2
Requires-Dist: ml-dtypes==0.4.1
Requires-Dist: moviepy==2.2.1
Requires-Dist: mpmath==1.3.0
Requires-Dist: multidict==6.5.0
Requires-Dist: namex==0.1.0
Requires-Dist: networkx==3.5
Requires-Dist: numpy==2.0.2
Requires-Dist: oauthlib==3.3.0
Requires-Dist: omegaconf==2.3.0
Requires-Dist: onnxruntime==1.22.0
Requires-Dist: openunmix==1.3.0
Requires-Dist: opt-einsum==3.4.0
Requires-Dist: optree==0.16.0
Requires-Dist: optuna==4.4.0
Requires-Dist: packaging==24.2
Requires-Dist: pandas==2.2.3
Requires-Dist: parso==0.8.4
Requires-Dist: pexpect==4.9.0
Requires-Dist: pickleshare==0.7.5
Requires-Dist: pillow==11.2.1
Requires-Dist: primepy==1.3
Requires-Dist: proglog==0.1.12
Requires-Dist: prompt-toolkit==3.0.51
Requires-Dist: propcache==0.3.2
Requires-Dist: proto-plus==1.26.1
Requires-Dist: protobuf==5.29.5
Requires-Dist: ptyprocess==0.7.0
Requires-Dist: pyannote-audio==3.3.2
Requires-Dist: pyannote-core==5.0.0
Requires-Dist: pyannote-database==5.1.3
Requires-Dist: pyannote-metrics==3.2.1
Requires-Dist: pyannote-pipeline==3.0.1
Requires-Dist: pyasn1==0.6.1
Requires-Dist: pyasn1-modules==0.4.2
Requires-Dist: pycparser==2.22
Requires-Dist: pydantic==2.11.7
Requires-Dist: pydantic-core==2.33.2
Requires-Dist: pydub==0.25.1
Requires-Dist: pygments==2.19.1
Requires-Dist: pyloudnorm==0.1.1
Requires-Dist: pyparsing==3.2.3
Requires-Dist: python-dateutil==2.9.0.post0
Requires-Dist: python-dotenv==1.1.0
Requires-Dist: pytorch-lightning==2.5.1.post0
Requires-Dist: pytorch-metric-learning==2.8.1
Requires-Dist: pytz==2025.2
Requires-Dist: pyyaml==6.0.2
Requires-Dist: requests==2.32.4
Requires-Dist: requests-oauthlib==2.0.0
Requires-Dist: retrying==1.3.4
Requires-Dist: rich==13.9.4
Requires-Dist: rsa==4.9.1
Requires-Dist: ruamel-yaml==0.18.14
Requires-Dist: ruamel-yaml-clib==0.2.12
Requires-Dist: scikit-learn==1.6.1
Requires-Dist: scipy==1.15.3
Requires-Dist: semver==3.0.4
Requires-Dist: sentencepiece==0.2.0
Requires-Dist: shapely==2.1.1
Requires-Dist: shellingham==1.5.4
Requires-Dist: six==1.17.0
Requires-Dist: sniffio==1.3.1
Requires-Dist: sortedcontainers==2.4.0
Requires-Dist: soundfile==0.13.1
Requires-Dist: speechbrain==1.0.3
Requires-Dist: sqlalchemy==2.0.41
Requires-Dist: submitit==1.5.3
Requires-Dist: sympy==1.13.1
Requires-Dist: tabulate==0.9.0
Requires-Dist: tensorboard==2.18.0
Requires-Dist: tensorboard-data-server==0.7.2
Requires-Dist: tensorboardx==2.6.4
Requires-Dist: tensorflow==2.18.1
Requires-Dist: tensorflow-io-gcs-filesystem==0.37.1
Requires-Dist: termcolor==3.1.0
Requires-Dist: threadpoolctl==3.6.0
Requires-Dist: tokenizers==0.21.1
Requires-Dist: torch==2.6.0
Requires-Dist: torch-audiomentations==0.12.0
Requires-Dist: torch-pitch-shift==1.2.5
Requires-Dist: torchaudio==2.6.0
Requires-Dist: torchmetrics==1.7.3
Requires-Dist: tqdm==4.67.1
Requires-Dist: traitlets==5.14.3
Requires-Dist: treetable==0.2.5
Requires-Dist: typer==0.16.0
Requires-Dist: typing-extensions==4.14.0
Requires-Dist: typing-inspection==0.4.1
Requires-Dist: tzdata==2025.2
Requires-Dist: uritemplate==4.2.0
Requires-Dist: urllib3==2.5.0
Requires-Dist: wcwidth==0.2.13
Requires-Dist: websockets==15.0.1
Requires-Dist: werkzeug==3.1.3
Requires-Dist: wheel==0.45.1
Requires-Dist: wrapt==1.17.2
Requires-Dist: yarl==1.20.1
Dynamic: author
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: keywords
Dynamic: license
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# gTech Ads Ariel for AI Video Ad Dubbing

### Ariel is an open-source Python library that facilitates efficient and cost-effective dubbing of video ads into multiple languages.

[![python](https://img.shields.io/badge/Python->=3.10-3776AB.svg?style=flat&logo=python&logoColor=white)](https://www.python.org)
[![PyPI](https://img.shields.io/pypi/v/gtech-ariel?logo=pypi&logoColor=white&style=flat)](https://pypi.org/project/gtech-ariel/)
[![GitHub last commit](https://img.shields.io/github/last-commit/google-marketing-solutions/ariel)](https://github.com/google-marketing-solutions/ariel/commits)
[![Code Style: Google](https://img.shields.io/badge/code%20style-google-blueviolet.svg)](https://google.github.io/styleguide/pyguide.html)
[![Open in Colab](https://img.shields.io/badge/Dubbing_Workflow-blue?style=flat&logo=google%20colab&labelColor=grey)](https://colab.research.google.com/github/google-marketing-solutions/ariel/blob/main/examples/dubbing_workflow.ipynb)

<div align="center">
    <img src="ariel_logo.png" alt="Ariel Logo" width="300">
</div>

##### _This is not an official Google product._

[Overview](#overview) •
[Features](#features) •
[Benefits](#benefits) •
[Language Compatibility](#language-compatibility) •
[Before You Begin](#before-you-begin) •
[Getting Started](#getting-started) •
[Building Blocks](#building-blocks) •
[References](#references)

## Overview

Ariel is a cutting-edge solution designed to enhance the global reach of digital advertising. It enables advertisers to automate the translation and dubbing of their video ads into a wide range of languages.

## Features

*   **Automated Dubbing:** Streamline the generation of high-quality dubbed versions of video ads in various target languages.
*   **Scalability:** Handle large volumes of videos and diverse languages efficiently.
*   **User-Friendly:** Offers a straightforward API and/or user interface for simplified operation.
*   **Cost-Effective:** Significantly reduce dubbing costs compared to traditional methods. The primary expenses are limited to Gemini API and Text-To-Speech API calls.

## Benefits

*   **Enhanced Ad Performance:** Improve viewer engagement and potentially increase conversion rates with localized ads.
*   **Streamlined Production:** Minimize the time and cost associated with manual translation and voiceover work.
*   **Rapid Turnaround:** Quickly generate dubbed versions of ads to accelerate multilingual campaign deployment.
*   **Expanded Global Reach:** Reach broader audiences worldwide with localized advertising content.

## Language Compatibility

You can dub video ads from and to many languages.

<details>
<summary>Expand to see the full list of supported languages.</summary>

*   Arabic (ar-SA), (ar-EG)
*   Bengali (bn-BD), (bn-IN)
*   Bulgarian (bg-BG)
*   Chinese (Simplified) (zh-CN)
*   Chinese (Traditional) (zh-TW)
*   Croatian (hr-HR)
*   Czech (cs-CZ)
*   Danish (da-DK)
*   Dutch (nl-NL)
*   English (en-US), (en-GB), (en-CA), (en-AU)
*   Estonian (et-EE)
*   Finnish (fi-FI)
*   French (fr-FR), (fr-CA)
*   German (de-DE)
*   Greek (el-GR)
*   Gujarati (gu-IN)
*   Hebrew (he-IL) (Note: Not supported with ElevenLabs API)
*   Hindi (hi-IN)
*   Hungarian (hu-HU)
*   Indonesian (id-ID)
*   Italian (it-IT)
*   Japanese (ja-JP)
*   Kannada (kn-IN)
*   Korean (ko-KR)
*   Latvian (lv-LV)
*   Lithuanian (lt-LT)
*   Malayalam (ml-IN)
*   Marathi (mr-IN)
*   Norwegian (nb-NO), (nn-NO)
*   Polish (pl-PL)
*   Portuguese (pt-PT), (pt-BR)
*   Romanian (ro-RO)
*   Russian (ru-RU)
*   Serbian (sr-RS)
*   Slovak (sk-SK)
*   Slovenian (sl-SI)
*   Spanish (es-ES), (es-MX)
*   Swahili (sw-KE)
*   Swedish (sv-SE)
*   Tamil (ta-IN), (ta-LK)
*   Telugu (te-IN)
*   Thai (th-TH)
*   Turkish (tr-TR)
*   Ukrainian (uk-UA)
*   Vietnamese (vi-VN)
</details>

## Before You Begin

*   **System Requirements:**
    *   **Installed FFmpeg:** For video and audio processing. You don't need to install this if you're running from Google Colab.
    *   **GPU (Recommended):** For optimal performance, especially with larger videos. It's available for free in Google Colab.
*   **Accounts and Tokens:**
    *   **Google Cloud Platform (GCP) Project:** Set up a GCP project. See [here](https://cloud.google.com/resource-manager/docs/creating-managing-projects) for instructions.
        *   **Enabled Vertex AI API:** Enable the Vertex API in your GCP project. See [here](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal) for instructions.
        *   **Enabled Cloud Storage API:** Enable the Cloud Storage API in your GCP project. See [here](https://cloud.google.com/vertex-ai/generative-ai/docs/start/quickstarts/quickstart-multimodal) for instructions.
            *    You need access to create and delete Google Cloud Storage (GCS) buckets.
        *   **Enabled Text-To-Speech API:** Enable the Text-To-Speech API in your GCP project if you choose it for the Text-To-Speech part of the process. See [here](https://cloud.google.com/text-to-speech/docs/before-you-begin) for instructions.
        *   **Google Drive API:** Enable the Google Drive API if you use the demo notebook called 'dubbing_workflow.ipynb in Google Colab.
        *   **Google Sheets API:** Enable the Google Sheets API if you use the demo notebook called 'dubbing_workflow.ipynb in Google Colab and want to pass script voice metadata from Google Sheets.
    *   **Hugging Face Token:** To access the PyAnnote speaker diarization model. See [here](https://huggingface.co/docs/hub/en/security-tokens) on how to get the token.
        *   **Hugging Face Model License:** You must accept the user conditions for the PyAnnote speaker diarization [here](https://huggingface.co/pyannote/speaker-diarization-3.1) and segmentation models [here](https://huggingface.co/pyannote/segmentation-3.0).
    *   **[OPTIONAL] ElevenLabs API:** To access the ElevenLabs API. See [here](https://help.elevenlabs.io/hc/en-us/articles/14599447207697-How-to-authorize-yourself-using-your-xi-api-key).
        *   **Commercial Use:** You are responsible for selecting the right ElevenLabs license if you decide to use the outputs from Ariel in a commercial setting. See the pricing [here](https://elevenlabs.io/pricing). Else, ElevenLabs is free to use.
*   **Data handling:**
    *   **Input files:** Ariel can work with both video and audio ads and they need to be in the MP4 or MP3 file formats respectively. See [here](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-2.5-flash) for the limitations on the duration of the ads enforeced by Gemini models.
    *   **Storage:** Ariel reads, processes and saves all the files in your environment, e.g. Colab. Only on one instance it creates a temporary Google Cloud Storage (GCS) bucket to upload the input file there for the Gemini model to indentify unique speakers. The bucket with all its contents is removed immediately afterwards. You can modify the `gcp_region` argument to choose the best location to perform this operation.
    *   **Voice cloning:** You can clone voices from the input file to make the dubbing sound close to the original if you decide to use ElevenLabs. It's is your responsibility to ensure that you are legally allowed to do so.

## Getting started

To start using Ariel, just click on the this button: [![Open in Colab](https://img.shields.io/badge/Dubbing_Workflow-blue?style=flat&logo=google%20colab&labelColor=grey)](https://colab.research.google.com/github/google-marketing-solutions/ariel/blob/main/examples/dubbing_workflow.ipynb)

## Building Blocks

Ariel leverages a powerful combination of state-of-the-art AI and audio processing techniques to deliver accurate and efficient dubbing results:

1.  **Video Processing:** Extracts the audio track from the input video file.
2.  **Audio Processing:**
    *   **DEMUCS:** Employed for advanced audio source separation.
    *   **pyannote:** Performs speaker diarization to identify and separate individual speakers.
3.  **Speech-To-Text (STT):**
    *   **faster-whisper:** A high-performance speech-to-text model.
    *   **Gemini 1.5 Flash:** A powerful multimodal language model that contributes to enhanced transcription.
4.  **Translation:**
    *   **Gemini 1.5 Flash:** Leverages its language understanding for accurate and contextually relevant translation.
5.  **Text-to-Speech (TTS):**
    *   **GCP's Text-To-Speech:** Generates natural-sounding speech in the target language.
    *   **[OPTIONAL] ElevenLabs:** An alternative API to generate speech. It's recommened for the best results. **WARNING:** ElevenLabs is a paid solution and will generate extra costs. See the pricing [here](https://elevenlabs.io/pricing).

## 🆕 Ariel User Interface
For a more user-friendly experience, we're also providing an Ariel version that
can be deployed onto Google Cloud Platform with a GUI.

<img src="./ui/src/ui/public/assets/ariel_ui.png" alt="Ariel UI screenshot">

### Requirements
In order to use Ariel UI, you need the following:
1.  **Google Cloud Platform Project** to host the backend. The following components
    are created during deployment:
    *   **Cloud Storage Bucket** to store input & output videos, video dubbing artifacts and
        all other metadata files. This bucket is also used as an interaction point with GUI
        (files created/removed there are triggering the backend processing).
    *   **Cloud Run** instance that processes all the steps. This part is implemented as a
        Python Docker container (which is also built during installation).
    *   **Pub/Sub Infrastructure** based on EventArc, it notifies the container of new files.
1.  **Cloud Run with GPU Support** is needed to ensure Ariel backend runs swiftly.
    You can apply for a Quota increase in a supported region using the [link here](https://cloud.google.com/run/docs/configuring/services/gpu#before-you-begin). This could take up to two days, however it is generally much quicker than that.
1.  **AppsScript Project** to host the frontend, an Angular web-app. For this,
    you need *Google Workspace* access.

### Deployment
Please make sure you have fulfilled all prerequisites mentioned under [Requirements](#Requirements) first.

1.  Make sure your system has an up-to-date installation of [Node.js and npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm).
1.  Install [clasp](https://github.com/google/clasp) by running `npm install @google/clasp -g`, then login via `clasp login`.
1.  Navigate to the [Apps Script Settings page](https://script.google.com/home/usersettings) and `enable` the Apps Script API.
1.  Make sure your system has an up-to-date installation of the [gcloud CLI](https://cloud.google.com/sdk/docs/install), then login via `gcloud auth login`.
1.  Make sure your system has an up-to-date installation of `git` and use it to clone this repository:
    `git clone https://github.com/google-marketing-solutions/ariel`.
1.  Navigate to the directory where the source code lives: `cd ariel`.
1.  Run `npm start`. This will prompt you for configuration values and suggest reasonable defaults.

## References

*   **DEMUCS:** [https://github.com/facebookresearch/demucs](https://github.com/facebookresearch/demucs)
*   **pyannote:** [https://github.com/pyannote/pyannote-audio](https://github.com/pyannote/pyannote-audio)
*   **faster-whisper:** [https://github.com/SYSTRAN/faster-whisper](https://github.com/SYSTRAN/faster-whisper)
*   **ElevenLabs:** [https://elevenlabs.io/docs/introduction](https://elevenlabs.io/docs/introduction)
