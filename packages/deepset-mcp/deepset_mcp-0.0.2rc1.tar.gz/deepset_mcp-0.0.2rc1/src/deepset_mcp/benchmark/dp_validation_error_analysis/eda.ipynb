{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from deepset_mcp.benchmark.dp_validation_error_analysis.preprocessing_utils import add_error_class_column",
   "id": "35b01b4fc75710c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv(\"../../../../data/raw/metabase_validation_errors_last_3_months_exported_28-05-2025.csv\")",
   "id": "bef8e3aac2385ca4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "len(df)",
   "id": "7c405c24642c215c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=[\"Context Library Name\", \"Context Library Version\", \"Event\", \"Received At\", \"UUID Ts\", \"Timestamp\", \"Sent At\", \"Deepset Cloud Version\", \"Is External User\"])",
   "id": "71e4abde2034523e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "cff0d577c45e2609",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.rename(columns={\"ID\": \"event_id\", \"Pipeline Name\": \"pipeline_name\", \"Source\": \"event_source\", \"User ID\": \"user_id\", \"Event Text\": \"event_text\", \"Organization Name\": \"organization_name\", \"Deepset User\": \"is_deepset_user\", \"Deepset Orga\": \"is_deepset_org\", \"Original Timestamp\": \"event_timestamp\", \"Workspace Name\": \"workspace_name\", \"Workspace ID\": \"workspace_id\", \"Organization ID\": \"organization_id\", \"Error\": \"error_message\", \"Organization Type\": \"organization_type\", \"User Email\": \"user_email\", \"Environment\": \"environment\", \"Pipeline ID\": \"pipeline_id\"})",
   "id": "be34de3aba586b63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "5a052dc3bf8ab8cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = add_error_class_column(df)",
   "id": "c289bb3164ff80f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.error_class.value_counts()",
   "id": "38349fa857cd1ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add component types\n",
    "df['component_type'] = df['error_message'].str.extract(\n",
    "    r\"component of type ['\\\"']([^'\\\"]+)['\\\"']\",\n",
    "    expand=False\n",
    ")"
   ],
   "id": "4ac0cf0ef85ba777",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.component_type.value_counts()",
   "id": "800d8cfdb68e3594",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df['config_error_message'] = df['error_message'].str.extract(\n",
    "    r\"Error:\\s*`?([^`\\n]+)`?\",\n",
    "    flags=re.IGNORECASE,\n",
    "    expand=False\n",
    ")"
   ],
   "id": "5f7c171c4e691278",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.head()",
   "id": "6fafa6edb4f63848",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set consistent style for professional look\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "\n",
    "# Define consistent color palette - professional and accessible\n",
    "COLORS = {\n",
    "    'primary': '#1E40AF',      # Deep blue\n",
    "    'secondary': '#F59E0B',    # Amber\n",
    "    'success': '#10B981',      # Emerald\n",
    "    'danger': '#EF4444',       # Red\n",
    "    'purple': '#8B5CF6',       # Purple\n",
    "    'pink': '#EC4899',         # Pink\n",
    "    'cyan': '#06B6D4',         # Cyan\n",
    "    'gray': '#6B7280'          # Gray\n",
    "}\n",
    "\n",
    "# ============================================\n",
    "# LOAD YOUR DATA HERE\n",
    "# ============================================\n",
    "# DATA STRUCTURE ASSUMPTIONS:\n",
    "# error_data: timestamp, error_class, component_type, is_deepset_user, organization_type, organization_name\n",
    "# activity_data: timestamp, is_deepset_user, organization_type, organization_name (general activity indicator)\n",
    "\n",
    "# Replace with your actual data:\n",
    "error_data = df.copy()      # Your error events\n",
    "activity_data = pd.read_csv(\"../../../../data/processed/created_updated_deployed_events.csv\")   # Your general activity events\n",
    "# Ensure both datasets have consistent timestamp column\n",
    "error_data['timestamp'] = pd.to_datetime(error_data['event_timestamp'])\n",
    "activity_data['timestamp'] = pd.to_datetime(activity_data['event_timestamp'])\n",
    "\n",
    "# ============================================\n",
    "# ACTIVITY-ADJUSTED ERROR ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def calculate_activity_adjusted_metrics(error_df, activity_df, group_by_cols):\n",
    "    \"\"\"\n",
    "    Calculate activity-adjusted error metrics by grouping both datasets\n",
    "    Returns errors per 1000 activity events for normalization\n",
    "    Only use this for segments that can have different activity levels (time, orgs, user types)\n",
    "    \"\"\"\n",
    "    error_counts = error_df.groupby(group_by_cols).size().reset_index(name='error_count')\n",
    "    activity_counts = activity_df.groupby(group_by_cols).size().reset_index(name='activity_count')\n",
    "\n",
    "    # Merge to get both counts for each group\n",
    "    merged = pd.merge(activity_counts, error_counts, on=group_by_cols, how='left')\n",
    "    merged['error_count'] = merged['error_count'].fillna(0)\n",
    "\n",
    "    # Calculate errors per 1000 activity events for easier interpretation\n",
    "    merged['errors_per_1k_activity'] = (merged['error_count'] / merged['activity_count']) * 1000\n",
    "    merged['activity_share'] = (merged['activity_count'] / merged['activity_count'].sum()) * 100\n",
    "\n",
    "    return merged\n",
    "\n",
    "# ============================================\n",
    "# CALCULATE KEY METRICS\n",
    "# ============================================\n",
    "\n",
    "total_errors = len(error_data)\n",
    "total_activity = len(activity_data)\n",
    "overall_error_intensity = (total_errors / total_activity) * 1000  # errors per 1000 activities\n",
    "\n",
    "date_range_start = min(error_data['timestamp'].min(), activity_data['timestamp'].min()).strftime('%B %d, %Y')\n",
    "date_range_end = max(error_data['timestamp'].max(), activity_data['timestamp'].max()).strftime('%B %d, %Y')\n",
    "\n",
    "# Weekly aggregation with activity adjustment\n",
    "error_data['week'] = error_data['timestamp'].dt.to_period('W').dt.to_timestamp()\n",
    "activity_data['week'] = activity_data['timestamp'].dt.to_period('W').dt.to_timestamp()\n",
    "\n",
    "weekly_metrics = calculate_activity_adjusted_metrics(error_data, activity_data, ['week'])\n",
    "weekly_metrics = weekly_metrics.sort_values('week')\n",
    "avg_weekly_error_intensity = weekly_metrics['errors_per_1k_activity'].mean()\n",
    "\n",
    "# Activity-adjusted metrics by different dimensions\n",
    "org_metrics = calculate_activity_adjusted_metrics(error_data, activity_data, ['organization_name'])\n",
    "org_metrics = org_metrics.sort_values('error_count', ascending=False)\n",
    "\n",
    "# Error distribution by error-specific dimensions (no activity adjustment needed)\n",
    "error_class_counts = error_data['error_class'].value_counts()\n",
    "error_class_distribution = pd.DataFrame({\n",
    "    'error_class': error_class_counts.index,\n",
    "    'error_count': error_class_counts.values,\n",
    "    'error_share': (error_class_counts.values / error_class_counts.sum()) * 100\n",
    "})\n",
    "\n",
    "component_counts = error_data['component_type'].value_counts()\n",
    "component_distribution = pd.DataFrame({\n",
    "    'component_type': component_counts.index,\n",
    "    'error_count': component_counts.values,\n",
    "    'error_share': (component_counts.values / component_counts.sum()) * 100\n",
    "})\n",
    "\n",
    "# User segmentation with activity adjustment\n",
    "internal_errors = error_data['is_deepset_user'].sum()\n",
    "internal_activity = activity_data['is_deepset_user'].sum()\n",
    "external_errors = len(error_data) - internal_errors\n",
    "external_activity = len(activity_data) - internal_activity\n",
    "\n",
    "internal_intensity = (internal_errors / internal_activity) * 1000 if internal_activity > 0 else 0\n",
    "external_intensity = (external_errors / external_activity) * 1000 if external_activity > 0 else 0\n",
    "\n",
    "# Enterprise vs Free activity-adjusted metrics\n",
    "enterprise_errors = (error_data['organization_type'] == 'FULL_DEEPSET_CLOUD').sum()\n",
    "enterprise_activity = (activity_data['organization_type'] == 'FULL_DEEPSET_CLOUD').sum()\n",
    "free_errors = (error_data['organization_type'] == 'DEEPSET_STUDIO_WITH_LIMITS').sum()\n",
    "free_activity = (activity_data['organization_type'] == 'DEEPSET_STUDIO_WITH_LIMITS').sum()\n",
    "\n",
    "enterprise_intensity = (enterprise_errors / enterprise_activity) * 1000 if enterprise_activity > 0 else 0\n",
    "free_intensity = (free_errors / free_activity) * 1000 if free_activity > 0 else 0\n",
    "\n",
    "# External Enterprise vs External Free activity-adjusted metrics\n",
    "external_enterprise_errors = ((error_data['is_deepset_user'] == False) &\n",
    "                             (error_data['organization_type'] == 'FULL_DEEPSET_CLOUD')).sum()\n",
    "external_enterprise_activity = ((activity_data['is_deepset_user'] == False) &\n",
    "                               (activity_data['organization_type'] == 'FULL_DEEPSET_CLOUD')).sum()\n",
    "external_free_errors = ((error_data['is_deepset_user'] == False) &\n",
    "                       (error_data['organization_type'] == 'DEEPSET_STUDIO_WITH_LIMITS')).sum()\n",
    "external_free_activity = ((activity_data['is_deepset_user'] == False) &\n",
    "                         (activity_data['organization_type'] == 'DEEPSET_STUDIO_WITH_LIMITS')).sum()\n",
    "\n",
    "external_enterprise_intensity = (external_enterprise_errors / external_enterprise_activity) * 1000 if external_enterprise_activity > 0 else 0\n",
    "external_free_intensity = (external_free_errors / external_free_activity) * 1000 if external_free_activity > 0 else 0\n",
    "\n",
    "# ============================================\n",
    "# PLOT 1: KEY METRICS SUMMARY\n",
    "# ============================================\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), facecolor='white')\n",
    "fig.suptitle('Activity-Adjusted Error Analysis - Key Metrics', fontsize=18, fontweight='bold', y=0.98)\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define metrics\n",
    "metrics = [\n",
    "    {'value': f'{overall_error_intensity:.1f}', 'label': 'Errors per 1K Activity', 'sublabel': f'{total_errors:,} errors / {total_activity:,} activities'},\n",
    "    {'value': f'{avg_weekly_error_intensity:.1f}', 'label': 'Avg Weekly Intensity', 'sublabel': 'errors per 1K activities/week'},\n",
    "    {'value': f'{error_class_distribution.iloc[0][\"error_share\"]:.1f}%',\n",
    "     'label': 'Top Error Class Share', 'sublabel': error_class_distribution.iloc[0]['error_class'].replace('_', ' ').title()},\n",
    "    {'value': f'{component_distribution.iloc[0][\"error_share\"]:.1f}%',\n",
    "     'label': 'Top Component Share', 'sublabel': component_distribution.iloc[0]['component_type']},\n",
    "    {'value': f'{external_intensity:.1f}', 'label': 'External User Intensity', 'sublabel': f'{external_errors:,} errors / {external_activity:,} activities'},\n",
    "    {'value': f'{enterprise_intensity:.1f}', 'label': 'Enterprise Intensity', 'sublabel': f'{enterprise_errors:,} errors / {enterprise_activity:,} activities'}\n",
    "]\n",
    "\n",
    "# Create metric cards\n",
    "for ax, metric, color in zip(axes, metrics, [COLORS['primary'], COLORS['secondary'],\n",
    "                                             COLORS['danger'], COLORS['pink'],\n",
    "                                             COLORS['success'], COLORS['cyan']]):\n",
    "    ax.text(0.5, 0.5, metric['value'], ha='center', va='center',\n",
    "            fontsize=32, fontweight='bold', color=color, transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.15, metric['label'], ha='center', va='center',\n",
    "            fontsize=14, color=COLORS['gray'], transform=ax.transAxes)\n",
    "    ax.text(0.5, 0.85, metric['sublabel'], ha='center', va='center',\n",
    "            fontsize=11, color='#9CA3AF', transform=ax.transAxes)\n",
    "\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add subtle border\n",
    "    for spine in ['top', 'right', 'bottom', 'left']:\n",
    "        ax.spines[spine].set_visible(True)\n",
    "        ax.spines[spine].set_color('#E5E7EB')\n",
    "        ax.spines[spine].set_linewidth(1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('activity_adjusted_summary.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 2: WEEKLY ERROR INTENSITY TREND\n",
    "# ============================================\n",
    "fig, ax1 = plt.subplots(figsize=(14, 8), facecolor='white')\n",
    "\n",
    "# Plot error intensity (primary y-axis)\n",
    "color1 = COLORS['primary']\n",
    "ax1.set_xlabel('Week', fontsize=13)\n",
    "ax1.set_ylabel('Errors per 1K Activities', color=color1, fontsize=13)\n",
    "line1 = ax1.plot(weekly_metrics['week'], weekly_metrics['errors_per_1k_activity'],\n",
    "                color=color1, linewidth=3, marker='o', markersize=6,\n",
    "                label='Error Intensity')\n",
    "ax1.tick_params(axis='y', labelcolor=color1)\n",
    "ax1.grid(True, alpha=0.3, linestyle=':')\n",
    "\n",
    "# Add rolling average\n",
    "weekly_metrics['intensity_rolling'] = weekly_metrics['errors_per_1k_activity'].rolling(window=3, center=True, min_periods=1).mean()\n",
    "ax1.plot(weekly_metrics['week'], weekly_metrics['intensity_rolling'],\n",
    "         color=color1, linewidth=2, linestyle='--', alpha=0.7,\n",
    "         label='3-week moving avg')\n",
    "\n",
    "# Add average line\n",
    "ax1.axhline(y=avg_weekly_error_intensity, color=color1, linestyle=':', alpha=0.7, linewidth=2)\n",
    "avg_text_y = avg_weekly_error_intensity + weekly_metrics['errors_per_1k_activity'].std()*0.1\n",
    "ax1.text(weekly_metrics['week'].iloc[0], avg_text_y,\n",
    "         f'Avg: {avg_weekly_error_intensity:.1f}', fontsize=11, color=color1,\n",
    "         bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Create secondary y-axis for activity volume\n",
    "ax2 = ax1.twinx()\n",
    "color2 = COLORS['secondary']\n",
    "ax2.set_ylabel('Activity Volume', color=color2, fontsize=13)\n",
    "bars = ax2.bar(weekly_metrics['week'], weekly_metrics['activity_count'],\n",
    "               alpha=0.3, color=color2, label='Total Activities', width=5)\n",
    "ax2.tick_params(axis='y', labelcolor=color2)\n",
    "\n",
    "# Combine legends\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='upper left',\n",
    "           frameon=True, fancybox=True, shadow=True)\n",
    "\n",
    "plt.title('Weekly Error Intensity Trend (Activity-Adjusted)', fontsize=16, fontweight='bold', pad=20)\n",
    "\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('weekly_error_intensity_trend.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 3: ERROR CLASS DISTRIBUTION\n",
    "# ============================================\n",
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "\n",
    "top_error_classes = error_class_distribution.head(8)\n",
    "colors = [COLORS['danger'], COLORS['secondary'], COLORS['purple'], COLORS['cyan'],\n",
    "          COLORS['success'], COLORS['pink'], COLORS['primary'], COLORS['gray']]\n",
    "\n",
    "# Error share (percentage of all errors)\n",
    "bars = plt.barh(range(8), top_error_classes['error_share'], color=colors, alpha=0.8, height=0.7)\n",
    "plt.yticks(range(8), [err.replace('_', ' ').title() for err in top_error_classes['error_class']], fontsize=12)\n",
    "plt.xlabel('Share of Total Errors (%)', fontsize=13)\n",
    "plt.title('Top 8 Error Classes Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3, axis='x', linestyle=':')\n",
    "\n",
    "for i, (bar, share, count) in enumerate(zip(bars, top_error_classes['error_share'],\n",
    "                                           top_error_classes['error_count'])):\n",
    "    plt.text(share + top_error_classes['error_share'].max()*0.02,\n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{share:.1f}% ({count:.0f})', va='center', fontsize=11,\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('error_class_distribution.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 4: COMPONENT DISTRIBUTION\n",
    "# ============================================\n",
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "\n",
    "top_components = component_distribution.head(8)\n",
    "colors = [COLORS['pink'], COLORS['purple'], COLORS['secondary'], COLORS['cyan'],\n",
    "          COLORS['success'], COLORS['danger'], COLORS['primary'], COLORS['gray']]\n",
    "\n",
    "# Component error share\n",
    "bars = plt.barh(range(8), top_components['error_share'], color=colors, alpha=0.8, height=0.7)\n",
    "plt.yticks(range(8), top_components['component_type'], fontsize=12)\n",
    "plt.xlabel('Share of Total Errors (%)', fontsize=13)\n",
    "plt.title('Top 8 Component Types Distribution', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3, axis='x', linestyle=':')\n",
    "\n",
    "for i, (bar, share, count) in enumerate(zip(bars, top_components['error_share'],\n",
    "                                           top_components['error_count'])):\n",
    "    plt.text(share + top_components['error_share'].max()*0.02,\n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{share:.1f}% ({count:.0f})', va='center', fontsize=11,\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('component_error_distribution.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 5: ORGANIZATION ANALYSIS\n",
    "# ============================================\n",
    "plt.figure(figsize=(12, 8), facecolor='white')\n",
    "\n",
    "top_orgs = org_metrics.head(8)\n",
    "\n",
    "# Organization error intensity\n",
    "bars = plt.barh(range(8), top_orgs['errors_per_1k_activity'], color=COLORS['primary'], alpha=0.8, height=0.7)\n",
    "for i, bar in enumerate(bars):\n",
    "    bar.set_alpha(0.9 - i*0.1)\n",
    "\n",
    "plt.yticks(range(8), top_orgs['organization_name'], fontsize=12)\n",
    "plt.xlabel('Errors per 1K Activities', fontsize=13)\n",
    "plt.title('Top 8 Organizations by Error Intensity', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.grid(True, alpha=0.3, axis='x', linestyle=':')\n",
    "\n",
    "for i, (bar, intensity, errors, activities) in enumerate(zip(bars, top_orgs['errors_per_1k_activity'],\n",
    "                                                            top_orgs['error_count'], top_orgs['activity_count'])):\n",
    "    plt.text(intensity + top_orgs['errors_per_1k_activity'].max()*0.02,\n",
    "             bar.get_y() + bar.get_height()/2,\n",
    "             f'{intensity:.1f} ({errors:.0f}/{activities:.0f})', va='center', fontsize=10,\n",
    "             bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('organization_intensity_analysis.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# ============================================\n",
    "# PLOT 6: USER SEGMENT COMPARISON\n",
    "# ============================================\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10), facecolor='white')\n",
    "\n",
    "# Internal vs External Error Intensity\n",
    "categories1 = ['Internal\\n(Deepset)', 'External\\n(Customers)']\n",
    "intensities1 = [internal_intensity, external_intensity]\n",
    "activity_counts1 = [internal_activity, external_activity]\n",
    "colors1 = [COLORS['primary'], COLORS['secondary']]\n",
    "\n",
    "bars1 = ax1.bar(categories1, intensities1, color=colors1, alpha=0.8, width=0.6)\n",
    "for bar, intensity, activities in zip(bars1, intensities1, activity_counts1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + max(intensities1)*0.02,\n",
    "            f'{intensity:.1f}\\n({activities:,} activities)', ha='center', va='bottom', fontsize=11,\n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "\n",
    "ax1.set_title('Error Intensity: Internal vs External', fontsize=12, fontweight='bold', pad=15)\n",
    "ax1.set_ylabel('Errors per 1K Activities', fontsize=11)\n",
    "ax1.grid(True, alpha=0.3, axis='y', linestyle=':')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "# External Enterprise vs External Free Error Intensity\n",
    "categories2 = ['External\\nEnterprise', 'External\\nFree']\n",
    "intensities2 = [external_enterprise_intensity, external_free_intensity]\n",
    "activity_counts2 = [external_enterprise_activity, external_free_activity]\n",
    "colors2 = [COLORS['success'], COLORS['cyan']]\n",
    "\n",
    "bars2 = ax2.bar(categories2, intensities2, color=colors2, alpha=0.8, width=0.6)\n",
    "for bar, intensity, activities in zip(bars2, intensities2, activity_counts2):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + max(intensities2)*0.02,\n",
    "            f'{intensity:.1f}\\n({activities:,} activities)', ha='center', va='bottom', fontsize=11,\n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "\n",
    "ax2.set_title('Error Intensity: External Enterprise vs Free', fontsize=12, fontweight='bold', pad=15)\n",
    "ax2.set_ylabel('Errors per 1K Activities', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3, axis='y', linestyle=':')\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "# Activity Distribution - Internal vs External\n",
    "bars3 = ax3.bar(categories1, activity_counts1, color=colors1, alpha=0.8, width=0.6)\n",
    "for bar, count in zip(bars3, activity_counts1):\n",
    "    height = bar.get_height()\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2., height + max(activity_counts1)*0.02,\n",
    "            f'{count:,}', ha='center', va='bottom', fontsize=11,\n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "\n",
    "ax3.set_title('Activity Volume: Internal vs External', fontsize=12, fontweight='bold', pad=15)\n",
    "ax3.set_ylabel('Total Activities', fontsize=11)\n",
    "ax3.grid(True, alpha=0.3, axis='y', linestyle=':')\n",
    "ax3.spines['top'].set_visible(False)\n",
    "ax3.spines['right'].set_visible(False)\n",
    "\n",
    "# Activity Distribution - External Enterprise vs External Free\n",
    "bars4 = ax4.bar(categories2, activity_counts2, color=colors2, alpha=0.8, width=0.6)\n",
    "for bar, count in zip(bars4, activity_counts2):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + max(activity_counts2)*0.02,\n",
    "            f'{count:,}', ha='center', va='bottom', fontsize=11,\n",
    "            bbox=dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.9))\n",
    "\n",
    "ax4.set_title('Activity Volume: External Enterprise vs Free', fontsize=12, fontweight='bold', pad=15)\n",
    "ax4.set_ylabel('Total Activities', fontsize=11)\n",
    "ax4.grid(True, alpha=0.3, axis='y', linestyle=':')\n",
    "ax4.spines['top'].set_visible(False)\n",
    "ax4.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('user_segment_intensity_comparison.png', dpi=300, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ],
   "id": "7ca4a6f32ece17e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ============================================\n",
    "# SEGMENT ANALYSIS FUNCTIONS\n",
    "# ============================================\n",
    "\n",
    "def analyze_error_distribution_by_segment(df, segment_col, segment_values, segment_labels, error_type_col, top_n=10):\n",
    "    \"\"\"\n",
    "    Analyze error type distribution across user segments\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    for segment_val, segment_label in zip(segment_values, segment_labels):\n",
    "        if segment_col == 'user_type':\n",
    "            # Special handling for internal vs external\n",
    "            if segment_val == 'internal':\n",
    "                segment_df = df[df['is_deepset_user'] == True]\n",
    "            else:\n",
    "                segment_df = df[df['is_deepset_user'] == False]\n",
    "        else:\n",
    "            segment_df = df[df[segment_col] == segment_val]\n",
    "\n",
    "        # Get error type distribution\n",
    "        error_counts = segment_df[error_type_col].value_counts().head(top_n)\n",
    "        total_errors = len(segment_df)\n",
    "\n",
    "        results[segment_label] = {\n",
    "            'counts': error_counts,\n",
    "            'percentages': (error_counts / total_errors * 100),\n",
    "            'total_errors': total_errors\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def create_comparison_plot(results, title, error_type_name, segment_labels, colors, filename):\n",
    "    \"\"\"\n",
    "    Create side-by-side comparison plots for error distributions (percentages only)\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, len(segment_labels), figsize=(6*len(segment_labels), 6), facecolor='white')\n",
    "    fig.suptitle(title, fontsize=16, fontweight='bold', y=0.95)\n",
    "\n",
    "    # Handle single subplot case\n",
    "    if len(segment_labels) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Percentages within each segment\n",
    "    for i, (segment_label, color) in enumerate(zip(segment_labels, colors)):\n",
    "        ax = axes[i]\n",
    "        data = results[segment_label]['percentages']\n",
    "        counts_data = results[segment_label]['counts']\n",
    "\n",
    "        bars = ax.barh(range(len(data)), data.values, color=color, alpha=0.8, height=0.7)\n",
    "        ax.set_yticks(range(len(data)))\n",
    "        ax.set_yticklabels([str(x).replace('_', ' ').title() if isinstance(x, str) else str(x)\n",
    "                           for x in data.index], fontsize=10)\n",
    "        ax.set_xlabel('Percentage of Errors (%)', fontsize=12)\n",
    "        ax.set_title(f'{segment_label}\\n({results[segment_label][\"total_errors\"]:,} total errors)',\n",
    "                    fontsize=12, fontweight='bold', pad=15)\n",
    "        ax.grid(True, alpha=0.3, axis='x', linestyle=':')\n",
    "\n",
    "        # Add percentage and absolute count labels\n",
    "        for bar, pct, error_type in zip(bars, data.values, data.index):\n",
    "            count = counts_data[error_type]\n",
    "            ax.text(pct + data.max()*0.01, bar.get_y() + bar.get_height()/2,\n",
    "                   f'{pct:.1f}% ({count:,})', va='center', fontsize=9,\n",
    "                   bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8))\n",
    "\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['left'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    plt.show()\n",
    "\n",
    "# ============================================\n",
    "# ANALYSIS 1: INTERNAL VS EXTERNAL USERS\n",
    "# ============================================\n",
    "print(\"=\"*80)\n",
    "print(\"ERROR DISTRIBUTION ANALYSIS BY USER SEGMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Error Classes: Internal vs External\n",
    "print(\"\\n1. ERROR CLASSES: INTERNAL vs EXTERNAL USERS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "error_class_internal_external = analyze_error_distribution_by_segment(\n",
    "    error_data, 'user_type', ['internal', 'external'],\n",
    "    ['Internal (Deepset)', 'External (Customers)'], 'error_class', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    error_class_internal_external,\n",
    "    'Error Class Distribution: Internal vs External Users',\n",
    "    'Error Class',\n",
    "    ['Internal (Deepset)', 'External (Customers)'],\n",
    "    [COLORS['primary'], COLORS['secondary']],\n",
    "    'error_classes_internal_vs_external.png'\n",
    ")\n",
    "\n",
    "component_internal_external = analyze_error_distribution_by_segment(\n",
    "    error_data, 'user_type', ['internal', 'external'],\n",
    "    ['Internal (Deepset)', 'External (Customers)'], 'component_type', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    component_internal_external,\n",
    "    'Component Type Distribution: Internal vs External Users',\n",
    "    'Component Type',\n",
    "    ['Internal (Deepset)', 'External (Customers)'],\n",
    "    [COLORS['primary'], COLORS['secondary']],\n",
    "    'component_types_internal_vs_external.png'\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ANALYSIS 2: ENTERPRISE VS FREE USERS\n",
    "# ============================================\n",
    "print(f\"\\n\\n3. ERROR CLASSES: ENTERPRISE vs FREE USERS\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "error_class_enterprise_free = analyze_error_distribution_by_segment(\n",
    "    error_data, 'organization_type',\n",
    "    ['FULL_DEEPSET_CLOUD', 'DEEPSET_STUDIO_WITH_LIMITS'],\n",
    "    ['Enterprise', 'Free'], 'error_class', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    error_class_enterprise_free,\n",
    "    'Error Class Distribution: Enterprise vs Free Users',\n",
    "    'Error Class',\n",
    "    ['Enterprise', 'Free'],\n",
    "    [COLORS['success'], COLORS['cyan']],\n",
    "    'error_classes_enterprise_vs_free.png'\n",
    ")\n",
    "\n",
    "\n",
    "component_enterprise_free = analyze_error_distribution_by_segment(\n",
    "    error_data, 'organization_type',\n",
    "    ['FULL_DEEPSET_CLOUD', 'DEEPSET_STUDIO_WITH_LIMITS'],\n",
    "    ['Enterprise', 'Free'], 'component_type', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    component_enterprise_free,\n",
    "    'Component Type Distribution: Enterprise vs Free Users',\n",
    "    'Component Type',\n",
    "    ['Enterprise', 'Free'],\n",
    "    [COLORS['success'], COLORS['cyan']],\n",
    "    'component_types_enterprise_vs_free.png'\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# ANALYSIS 3: EXTERNAL ENTERPRISE vs EXTERNAL FREE\n",
    "# ============================================\n",
    "print(f\"\\n\\n5. ERROR CLASSES: EXTERNAL ENTERPRISE vs EXTERNAL FREE\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Filter for external users only\n",
    "external_users = error_data[error_data['is_deepset_user'] == False]\n",
    "\n",
    "error_class_external_segments = analyze_error_distribution_by_segment(\n",
    "    external_users, 'organization_type',\n",
    "    ['FULL_DEEPSET_CLOUD', 'DEEPSET_STUDIO_WITH_LIMITS'],\n",
    "    ['External Enterprise', 'External Free'], 'error_class', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    error_class_external_segments,\n",
    "    'Error Class Distribution: External Enterprise vs External Free Users',\n",
    "    'Error Class',\n",
    "    ['External Enterprise', 'External Free'],\n",
    "    [COLORS['purple'], COLORS['pink']],\n",
    "    'error_classes_external_enterprise_vs_free.png'\n",
    ")\n",
    "\n",
    "component_external_segments = analyze_error_distribution_by_segment(\n",
    "    external_users, 'organization_type',\n",
    "    ['FULL_DEEPSET_CLOUD', 'DEEPSET_STUDIO_WITH_LIMITS'],\n",
    "    ['External Enterprise', 'External Free'], 'component_type', top_n=10\n",
    ")\n",
    "\n",
    "create_comparison_plot(\n",
    "    component_external_segments,\n",
    "    'Component Type Distribution: External Enterprise vs External Free Users',\n",
    "    'Component Type',\n",
    "    ['External Enterprise', 'External Free'],\n",
    "    [COLORS['purple'], COLORS['pink']],\n",
    "    'component_types_external_enterprise_vs_free.png'\n",
    ")\n"
   ],
   "id": "88038fcd25d25346",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
