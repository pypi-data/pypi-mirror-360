{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd88942c",
   "metadata": {},
   "source": [
    "# Multiprocessing Pipelines\n",
    "\n",
    "Processing astronomical images using multiple CPU cores can significantly accelerate data reduction, especially when working with large datasets. However, this approach requires careful consideration of how large files are accessed and shared between processes.\n",
    "\n",
    "## Concurrent Access to Large Files\n",
    "\n",
    "When calibrating each image in a separate process, it is inefficient to repeatedly pass large master calibration files (typically three, each as large as a science image) between processes. Instead, these files can be stored on disk and accessed concurrently by each process. The following example demonstrates how to do this, starting with the creation of master calibration files as shown in the [calibration tutorial](calibration.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01942382",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from dateutil import parser\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from datetime import timedelta\n",
    "from eloy import calibration\n",
    "\n",
    "\n",
    "def load_calibration_files():\n",
    "\n",
    "    files = glob(\"./photometry_raw_data/**/*.fit*\")\n",
    "    files_meta = defaultdict(dict)\n",
    "    observations = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for file in files:\n",
    "        header = fits.getheader(file)\n",
    "        file_date = parser.parse(header[\"DATE-OBS\"])\n",
    "        # because some observations are taken over midnight\n",
    "        file_date = file_date - timedelta(hours=10)\n",
    "        files_meta[file][\"date\"] = file_date\n",
    "        files_meta[file][\"type\"] = Path(file).parent.stem\n",
    "        observations[file_date.date()][files_meta[file][\"type\"]] += 1\n",
    "\n",
    "    # only picking up the science images\n",
    "    lights = list(filter(lambda f: files_meta[f][\"type\"] == \"ScienceImages\", files))\n",
    "    # sorting them by date\n",
    "    lights = sorted(lights, key=lambda f: files_meta[f][\"date\"])\n",
    "    # selecting the first one\n",
    "    file = lights[0]\n",
    "\n",
    "    def filter_files(files, file_type):\n",
    "        return list(filter(lambda f: files_meta[f][\"type\"] == file_type, files))\n",
    "\n",
    "    biases = filter_files(files, \"Bias\")\n",
    "    darks = filter_files(files, \"Darks\")\n",
    "    flats = filter_files(files, \"Flats\")\n",
    "\n",
    "    bias = calibration.master_bias(files=biases)\n",
    "    dark = calibration.master_dark(files=darks, bias=bias)\n",
    "    flat = calibration.master_flat(files=flats, bias=bias, dark=dark)\n",
    "\n",
    "    return bias, dark, flat, lights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7392ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eloy import utils\n",
    "\n",
    "bias, dark, flat, lights = load_calibration_files()\n",
    "\n",
    "master_files = {\n",
    "    \"bias\": bias,\n",
    "    \"dark\": dark,\n",
    "    \"flat\": flat,\n",
    "}\n",
    "\n",
    "shared_data = utils.share_data(master_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8784796b",
   "metadata": {},
   "source": [
    "This approach allows shared access to large numpy arrays saved on disk. For more information, see the documentation on [numpy memory-mapped arrays](https://numpy.org/doc/stable/reference/generated/numpy.memmap.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a34bbda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "memmap([[1286.5, 1287. , 1304. , ..., 1281. , 1281.5, 1278. ],\n",
       "        [1291.5, 1288.5, 1304. , ..., 1284.5, 1285.5, 1280.5],\n",
       "        [1292. , 1295. , 1296. , ..., 1288.5, 1284. , 1287. ],\n",
       "        ...,\n",
       "        [1287.5, 1289. , 1288.5, ..., 1281. , 1278.5, 1284. ],\n",
       "        [1289.5, 1291. , 1298. , ..., 1278. , 1278.5, 1273.5],\n",
       "        [1283.5, 1296. , 1293.5, ..., 1278. , 1280. , 1279.5]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_data[\"bias\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d591d55",
   "metadata": {},
   "source": [
    "## Example: Multiprocessing Pipeline\n",
    "\n",
    "```{important}\n",
    "This example will not work inside a Jupyter notebook, as explained in the [multiprocessing module documentation](https://docs.python.org/3/library/multiprocessing.html#using-a-pool-of-workers).\n",
    "```\n",
    "\n",
    "Below is an example of how a multiprocessing pipeline might be implemented in a standalone Python script:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971c60e0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Make sure to call the load_calibration_files function and import the necessary modules.\n",
    "\n",
    "def process_image(index_file, shared_data=None):\n",
    "    i, file = index_file\n",
    "    image = fits.getdata(file)\n",
    "    header = fits.getheader(file)\n",
    "\n",
    "    # Apply the master calibration\n",
    "    calibrated_image = calibration.calibrate(\n",
    "        image,\n",
    "        exposure=header[\"EXPTIME\"],\n",
    "        bias=shared_data[\"bias\"],\n",
    "        dark=shared_data[\"dark\"],\n",
    "        flat=shared_data[\"flat\"],\n",
    "    )\n",
    "\n",
    "    return i, calibrated_image\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    import multiprocessing as mp\n",
    "    from tqdm import tqdm\n",
    "    from functools import partial\n",
    "    from eloy import utils\n",
    "\n",
    "    bias, dark, flat, lights = load_calibration_files()\n",
    "\n",
    "    master_files = {\n",
    "        \"bias\": bias,\n",
    "        \"dark\": dark,\n",
    "        \"flat\": flat,\n",
    "    }\n",
    "\n",
    "    shared_data = utils.share_data(master_files)\n",
    "    indexes_images = list(enumerate(lights))\n",
    "    calibrated_images = {}\n",
    "\n",
    "    with mp.Pool() as pool:\n",
    "        for i, calibrated_image in tqdm(\n",
    "            pool.imap(partial(process_image, shared_data=shared_data), indexes_images),\n",
    "            total=len(indexes_images),\n",
    "        ):\n",
    "            calibrated_images[i] = calibrated_image\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eloy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
