import pandas as pd
from _typeshed import Incomplete
from typing import Iterable
from virtualitics_sdk.app.step import Step as Step, StepType as StepType
from virtualitics_sdk.assets.asset import AssetType as AssetType
from virtualitics_sdk.assets.language_processor import LanguageProcessor as LanguageProcessor
from virtualitics_sdk.elements import Column as Column, Dashboard as Dashboard, DateTimeRange as DateTimeRange, Image as Image, InfographData as InfographData, InfographDataType as InfographDataType, Infographic as Infographic, Row as Row, Table as Table
from virtualitics_sdk.nlp import EventExtractor as EventExtractor, NerSummarization as NerSummarization
from virtualitics_sdk.nlp.common import build_default_page as build_default_page, get_assets_info as get_assets_info
from virtualitics_sdk.nlp.data_upload import DataUpload as DataUpload
from virtualitics_sdk.nlp.feature_analytics import FeatureExploration as FeatureExploration
from virtualitics_sdk.nlp.pipeline_config import PipelineConfigurationStep as PipelineConfigurationStep
from virtualitics_sdk.page import Card as Card, Page as Page, Section as Section
from virtualitics_sdk.store.store_interface import StoreInterface as StoreInterface
from virtualitics_sdk.utils.viz_utils import create_bar_plot as create_bar_plot, create_histogram_plot as create_histogram_plot

def empty_docs_infographic(nlp_stats: pd.DataFrame) -> InfographData: ...
def doc_len_infographic(nlp_stats: pd.DataFrame) -> tuple[InfographData, InfographData]: ...
def sent_len_infographic(nlp_stats: pd.DataFrame) -> tuple[InfographData, InfographData]: ...
def events_entities_infographics(nlp_stats: pd.DataFrame) -> list[InfographData]: ...
def mean_sents_info(nlp_stats: pd.DataFrame, threshold: float = 2.5) -> InfographData: ...
def mean_unique_words(nlp_stats: pd.DataFrame) -> InfographData: ...
def mean_dependency_tree_depth(nlp_stats: pd.DataFrame) -> InfographData: ...
def unique_ents_features_in_corpus(ents_table: pd.DataFrame): ...
def unique_events_features_in_corpus(events_table: pd.DataFrame): ...
def generate_pos_summary_df(nlp_stats_df: pd.DataFrame): ...
def create_average_dep_depth_hist(nlp_stats_df: pd.DataFrame): ...

class DateTimeFiltering(Step):
    dt_range: str
    logger: Incomplete
    pipeline_config_step: Incomplete
    data_upload_step: Incomplete
    def __init__(self, pipeline_config_step: PipelineConfigurationStep, data_upload_step: DataUpload) -> None: ...
    @staticmethod
    def produce_plot_image(x, y, img_title: str = '', img_descr: str = ''): ...
    @staticmethod
    def cast_column(df_column: pd.Series, date_format: str) -> pd.Series: ...
    def get_dependencies(self, store_interface: StoreInterface): ...
    def run(self, flow_metadata: dict): ...

class DataDiagnostic(Step):
    main_section: str
    default_narrative: str
    logger: Incomplete
    advanced_dash: Incomplete
    data_upload_step: Incomplete
    pipeline_config_step: Incomplete
    dt_filtering_step: Incomplete
    sample_percentage: Incomplete
    num_samples: Incomplete
    downsample_data: Incomplete
    def __init__(self, data_upload_step: DataUpload, pipeline_config_step: PipelineConfigurationStep, data_filtering_step: DateTimeFiltering, advanced_dash: bool = False, downsample_data: bool = False, num_samples: int = 10000, sample_percentage: float = 0.5) -> None: ...
    def merge_narrative_features(self, input_df: pd.DataFrame, cols: Iterable[str], drop: bool = False): ...
    @staticmethod
    def filter_by_date(pandas_df: pd.DataFrame, dt_col: str, range_vals: dict): ...
    def get_dependencies(self, store_interface: StoreInterface): ...
    def run(self, flow_metadata): ...
    def build_advanced_dashboard(self, nlp_stats_df: pd.DataFrame, store_interface: StoreInterface, nlp_module: LanguageProcessor, current_page: Page): ...
    def build_simple_dashboard(self, nlp_stats_df: pd.DataFrame, store_interface: StoreInterface, nlp_module: LanguageProcessor, current_page: Page): ...
