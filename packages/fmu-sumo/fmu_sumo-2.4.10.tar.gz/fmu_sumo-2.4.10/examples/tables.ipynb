{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from fmu.sumo.explorer import AggregatedTable, Explorer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# These examples use Seaborn for plotting. Seaborn does not automatically install with\n",
    "# fmu-sumo. If your environment does not have Seaborn installed, uncomment line below.\n",
    "\n",
    "# !pip install seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo = Explorer(\"dev\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get case by name (name is not guaranteed to be unique)\n",
    "case = sumo.cases.filter(uuid=\"5e6bd69f-eaa2-49b7-b323-62a84d533051\")[0]\n",
    "case.name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding info about tables connected to case\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sumo a big group of data are stored as tables. Any data that does not have spacial references will have to be in this format.<br>\n",
    "This means that this is the solution for datatypes such as inplace volumes, and summary data from reservoir simulators. <br>\n",
    "Even data that has spacial reference might be stored as a table. So to be general one can say that as long as the data is in a table like format,<br> like in an excel or oocalc spreadsheet/pandas dataframe/arrow table or something similar you can upload it to sumo as a table. <br>\n",
    "\n",
    "When it comes to metadata there is a very logical triplet for surfaces/polygons/points, these are name/tagname/content <br>\n",
    "This is very influenced by how these are stored in rms, where they refer to name of horizon/representation/and content type.<br>\n",
    "For example for a surface the name could be BCU (Base Cretaceous unconformity), the representation could be time or depth, and the content could be a <br>2D grid or point sets. \n",
    "\n",
    "For tables this is a bit more unclear, so one will for example find tables that have an empty tag name. <br>\n",
    "Whatever there is of a convention here for now can be described as:<br>\n",
    "\n",
    "**inplace volumes coming out of rms**<br>\n",
    "name: name of grid in rms <br>\n",
    "tagname: vol <br>\n",
    "content: volumes<br>\n",
    "\n",
    "**tables from eclipse** (results extracted with package ecl2df)<br>\n",
    "name: name of datafile (but no -<realization number>)<br>\n",
    "tagname: datatype as according to ecl2df <br>\n",
    "content: summary data will get timeseries, but for now the rest will get property <br>\n",
    "There is a suggestion (issue in the fmu-dataio repo) that basically the content will be same as the tagname, meaning rft will be content rft<br>\n",
    "pvt will be pvt etc. But here there are inconsistencies, e.g. relperm data is called satfunc in ecl2df, and it seems more logical to use relperm, <br>\n",
    "or relativepermeability for this type. Here it would be good with input from the domain experts.\n",
    " for name the convention adopted is that for data coming out of <br>\n",
    "\n",
    "**Any other table**<br>\n",
    "Here there is really anarchy, so it is up to the end user to define this themselves when exporting with fmu-dataio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tables = case.tables\n",
    "print(f\"Table names: {tables.names}\")\n",
    "print(f\"Table tags: {tables.tagnames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching one table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most tables are stored during the running of an fmu run. So you will in that case have one version per realization (i.e per file path realization-n/iter-m) <br>\n",
    "This means that it will be a slow process to get to results from one ensemble. <br>\n",
    "Below is an example of how to fetch one table. General syntax: <br>\n",
    "``table_collection = case.tables.filter(realization=<realization number>, ensemble=<ensemble name>,``<br>\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;``name=<table name>, tagname=<name of tag>)``<br>\n",
    "Any of the input arguements are optional, so you could end up with more than one resulting table, and in theory even if you have <br>\n",
    "used all arguements you could end up with several (long story, please ask). But you can check how many tables you have with using <br>\n",
    "``len(table_collection)``<br>\n",
    "To get to one table you can then access them using indexing as you would with a list in python: <br>\n",
    "``table = table_collection[0]``<br>\n",
    "If you want to access the actual object, you can access this with the methods to_pandas or to_arrow, and you also have access to the <br>\n",
    "metadata via indexing as you would do a dictionary. The entire metadata can be access with using the attribute _metadata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter using the key\n",
    "one_table = tables.filter(\n",
    "    realization=0, ensemble=\"iter-0\", name=\"DROGON\", tagname=\"compdat\"\n",
    ")[0]\n",
    "\n",
    "# Give back the name and tag\n",
    "print(f\"Found table {one_table.name}-{one_table.tagname}\")\n",
    "\n",
    "# fetching the actual table as a Pandas dataframe\n",
    "print(one_table.name)\n",
    "print(one_table.to_pandas().head())\n",
    "\n",
    "# If you know the metadata fields you can access the data directly on the object with square brackets\n",
    "print(one_table[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is slow to aggregate the tables yourself, and that the tables then would become very large Sumo comes with a service that aggregates the tables, and then splits them up by column. We refer to these objects as aggregated tables even though they are both aggregated and split up. These come in different types, but the most general is the collection, where you get all realizations stacked on top of each other,<br> but you also have access to statistical aggregations such as mean, min,max, std, p10, and p90 <br>\n",
    "\n",
    "Below is described how one uses these."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with aggregated tables\n",
    "There are two ways of getting to aggregated tables\n",
    "1. The filtering way\n",
    "2. Through the AggregatedTable class (Which is using filtering under the hood)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The filtering way\n",
    "\n",
    "General syntax:<br>\n",
    "``selection = case.tables.filter(name=<NAME OF TABLE>, tagname=<NAME OF TAG>, column=<COLUMN NAME>, aggregation=<aggregation type>)``\n",
    "\n",
    "All these are optional as explained above, but you have to have the aggregation argument to get to an aggregated object. <br>\n",
    "And if you leave out some of them you will end up with a collection of them, not just one"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filtering to get to all aggregated tables with name of data file, for the drogon case it is called DROGON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_tables = tables.filter(\n",
    "    name=\"DROGON\", ensemble=\"iter-0\", aggregation=\"collection\"\n",
    ")\n",
    "sim_tables.tagnames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rft_tables = sim_tables.filter(tagname=\"rft\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rft table object now contains all the aggregated tables relating to the rft tag. <br>\n",
    "The different object names you can access via the columns attribute, sort of similar to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rft_tables.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get to one spesific table you use the filtering option column=, <br> and fetch the element just like in a list<br>\n",
    "Which gives access to one object, but this can be accessed both as pandas dataframe and pyarrow table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pressure = rft_tables.filter(column=\"PRESSURE\")[0]\n",
    "frame = pressure.to_pandas()\n",
    "print(\n",
    "    f\"The following columns are in the pressure object {frame.columns.to_list()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After this it is easy to make a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = frame.WELL.unique()\n",
    "dates = frame.DATE.unique()\n",
    "fig, plots = plt.subplots(len(dates), len(names))\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    for j, well in enumerate(names):\n",
    "        data = frame.loc[\n",
    "            (date == frame.DATE) & (well == frame.WELL)\n",
    "        ].sort_values(by=\"DEPTH\")\n",
    "        ax = plots[i, j]\n",
    "        if data.empty:\n",
    "            ax = plots[i, j]  # get current axes\n",
    "            ax.get_xaxis().set_visible(False)  # hide x-axis\n",
    "            ax.get_yaxis().set_visible(False)  # hide y-axis\n",
    "            ax.axis(\"off\")\n",
    "        else:\n",
    "            data[[\"DEPTH\", \"PRESSURE\"]].plot(ax=ax, x=\"PRESSURE\", y=\"DEPTH\")\n",
    "            ax.get_legend().remove()\n",
    "            if i == 0:\n",
    "                ax.set_title(well)\n",
    "\n",
    "            ax.invert_yaxis()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For even more user friendly access to summary data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use the class Aggregated Table \n",
    "\n",
    "``COLLECTION = AggregatedTable(case, <NAME OF DATAFILE>, <DATATYPE>)``\n",
    "\n",
    "Here ``<DATATYPE>`` can be of collection, index, mean, min, max, p10 or p90\n",
    "\n",
    "This class gives you the aggregated tables that share name and tagname for one ensemble as one object, <br> \n",
    "so you don't need to know that what you are dealing with is a collection of objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID = AggregatedTable(case, \"DROGON\", \"grid\", \"iter-0\")\n",
    "GRID[\"PORO\"].to_pandas().plot(kind=\"hist\", y=\"PORO\")\n",
    "GRID[\"PERMX\"].to_pandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EQUIL = AggregatedTable(case, \"DROGON\", \"equil\", \"iter-0\")\n",
    "CONTACT_TYPE = \"OWC\"\n",
    "sns.boxplot(\n",
    "    pd.pivot_table(\n",
    "        EQUIL[CONTACT_TYPE].to_pandas(),\n",
    "        index=\"REAL\",\n",
    "        columns=\"EQLNUM\",\n",
    "        values=CONTACT_TYPE,\n",
    "    ).values\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELPERM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELPERM = AggregatedTable(case, \"DROGON\", \"satfunc\", \"iter-0\")\n",
    "\n",
    "KRW = (\n",
    "    pd.concat((RELPERM[\"KRW\"].to_pandas(), RELPERM[\"SW\"].to_pandas()), axis=1)\n",
    "    .T.drop_duplicates()\n",
    "    .T\n",
    ")\n",
    "print(KRW.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(\n",
    "    KRW.loc[(KRW.KEYWORD == \"SWOF\")],\n",
    "    x=\"SW\",\n",
    "    y=\"KRW\",\n",
    "    hue=\"SATNUM\",\n",
    "    style=\"REAL\",\n",
    ")\n",
    "ax.legend(loc=\"right\", ncols=6, bbox_to_anchor=(2.1, 0.5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = AggregatedTable(case, \"DROGON\", \"summary\", \"iter-0\")\n",
    "VECTOR_NAME = \"FOIP\"\n",
    "ax = (\n",
    "    pd.pivot_table(\n",
    "        summary[VECTOR_NAME].to_pandas(),\n",
    "        index=\"DATE\",\n",
    "        columns=\"REAL\",\n",
    "        values=VECTOR_NAME,\n",
    "    )\n",
    "    .dropna(axis=0)\n",
    "    .plot()\n",
    ")\n",
    "ax.get_legend().remove()\n",
    "ax.set_label(VECTOR_NAME)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compdat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPDAT = AggregatedTable(case, \"DROGON\", \"compdat\", ensemble=\"iter-0\")\n",
    "COMPDAT[\"KH\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wellcompletions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS = AggregatedTable(case, \"DROGON\", \"wellcompletiondata\", \"iter-0\")\n",
    "KH = COMPLETIONS[\"KH\"].to_pandas()\n",
    "KH.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KH[\"ZONE_NR\"] = KH[\"ZONE\"].replace(\n",
    "    {\n",
    "        value: key\n",
    "        for key, value in dict(enumerate(KH[\"ZONE\"].unique().tolist())).items()\n",
    "    }\n",
    ")\n",
    "MEAN_STD = pd.pivot_table(\n",
    "    KH,\n",
    "    index=[\"ZONE_NR\", \"ZONE\"],\n",
    "    columns=\"WELL\",\n",
    "    values=\"KH\",\n",
    "    aggfunc=[\"mean\", \"std\"],\n",
    ")\n",
    "# KH.head()\n",
    "MEAN_STD[(\"mean\",)][\"A1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(KH, x=\"WELL\", y=\"ZONE\", hue=\"KH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIPREPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORTS = AggregatedTable(case, \"DROGON\", \"fipreports\", \"iter-0\")\n",
    "print(REPORTS.columns)\n",
    "REPORT_NAME = \"STOIIP_OIL\"\n",
    "STOIIP = REPORTS[REPORT_NAME].to_pandas().dropna(subset=REPORT_NAME, axis=0)\n",
    "STOIIP.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faults\n",
    "Seems to be something wrong with it, will need to have a look\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAULTS = AggregatedTable(case, \"DROGON\", \"faults\", \"iter-0\")\n",
    "print(FAULTS.columns)\n",
    "COMPLETE = pd.concat(\n",
    "    (FAULTS[\"I\"].to_pandas(), FAULTS[\"J\"].to_pandas(), FAULTS[\"K\"].to_pandas())\n",
    ")\n",
    "COMPLETE.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The table index \n",
    "\n",
    "Throughout the examples of the aggregated tables you have probably noticed that the aggregated tables comes with additonal columns apart from the <br>\n",
    "specific one that you have asked for. E.g. fetching an aggregated table for FOPT from summary will include the DATE column, and if you ask from PORO <br> from grid you will get these additional elements: [\"GLOBAL_INDEX\", \"I\", \"J\", \"K\"]. This is enables you to only download one object and you straight out of the box have all you need for plotting or analysis. These could be revised though, and here we want input from the users.\n",
    " E.g. for now satfunc (which is relperm) does not include SW, should that be included? These are the definitions as of now, <br>\n",
    " please give feedback on this!!\n",
    "\n",
    "DEFINITIONS = {<br>\n",
    "&emsp;    \"inplace_volumes\": [\"ZONE\", \"REGION\", \"FACIES\", \"LICENCE\"], <br>\n",
    "&emsp;    \"wellpicks\": [\"WELL\", \"HORIZON\"], <br>\n",
    "&emsp;    \"summary\": [\"DATE\"], <br>\n",
    "&emsp;    \"equil\": [\"EQLNUM\"], <br>\n",
    "&emsp;    \"compdat\": [\"WELL\", \"DATE\", \"DIR\"], <br>\n",
    "&emsp;    \"faults\": [\"NAME\", \"FACE\"], <br>\n",
    "&emsp;    \"fipreports\": [\"DATE\", \"FIPNAME\", \"REGION\"], <br>\n",
    "&emsp;    \"grid\": [\"GLOBAL_INDEX\", \"I\", \"J\", \"K\"], <br>\n",
    "&emsp;    \"pillars\": [\"PILLAR\"], <br>\n",
    "&emsp;    \"pvt\": [\"PVTNUM\", \"KEYWORD\"], <br>\n",
    "&emsp;    \"rft\": [\"WELL\", \"DATE\", \"DEPTH\"], <br>\n",
    "&emsp;    \"satfunc\": [\"SATNUM\", \"KEYWORD\"], <br>\n",
    "&emsp;    \"wellcompletiondata\": [\"WELL\", \"DATE\", \"ZONE\"], <br>\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
