{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Wiener-Hammerstein system\n",
    "\n",
    "See http://arxiv.org/pdf/1708.06543 for more information on the dataset.\n",
    "\n",
    "Note that running this file multiple times, or on different machines, with the same parameters may yield different results due to the non-deterministic nature of GPU parallel execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nonlinear_benchmarks as nlb\n",
    "import numpy as np\n",
    "import optimistix as optx\n",
    "\n",
    "import freq_statespace as fss\n",
    "\n",
    "\n",
    "# Load data\n",
    "ParWH_full_train, ParWH_full_test = nlb.ParWH() \n",
    "\n",
    "# Initialize variables\n",
    "N = 16384  # number of samples per period\n",
    "R = 5  # number of random phase multisine realizations\n",
    "P = 2  # number of periods\n",
    "amplitude_level = 4  # must be one of {0, 1, 2, 3, 4}\n",
    "\n",
    "nu, ny = 1, 1  # SISO system\n",
    "\n",
    "fs = 78e3 # [Hz]\n",
    "f_idx = np.arange(1, 4096)  # frequency lines of interest (excludes DC)\n",
    "\n",
    "# Load data\n",
    "ParWH_full_train, ParWH_full_test = nlb.ParWH() \n",
    "ParWH_train = [\n",
    "    data for data in ParWH_full_train\n",
    "    for phase in range(R)\n",
    "    if data.name == f'Est-phase-{phase}-amp-{amplitude_level}'\n",
    "]\n",
    "ParWH_test = [\n",
    "    data for data in ParWH_full_test\n",
    "    if data.name == f'Val-amp-{amplitude_level}'\n",
    "][0]\n",
    "\n",
    "# Preprocess data\n",
    "u_train = np.array([data.u for data in ParWH_train]).reshape(R, nu, N, P)\n",
    "y_train = np.array([data.y for data in ParWH_train]).reshape(R, ny, N, P)\n",
    "u_train = np.transpose(u_train, (2, 1, 0, 3))\n",
    "y_train = np.transpose(y_train, (2, 1, 0, 3))\n",
    "\n",
    "u_test = np.transpose(ParWH_test.u.reshape(1, nu, N, 2), (2, 1, 0, 3))\n",
    "y_test = np.transpose(ParWH_test.y.reshape(1, ny, N, 2), (2, 1, 0, 3))\n",
    "\n",
    "# Create input-output training data object\n",
    "data = fss.create_data_object(u_train, y_train, f_idx, fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Best Linear Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (i) Parametrize using frequency-domain subspace identification method\n",
    "nx = 12  # number of states\n",
    "q = nx + 1  # subspace dimensioning parameter\n",
    "bla_fsid = fss.lin.subspace_id(data, nx, q)\n",
    "\n",
    "# (ii) Frequency-domain iterative optimization starting from FSID BLA\n",
    "solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6)\n",
    "bla_opti = fss.lin.optimize(bla_fsid, data, solver=solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: inference and learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the nonlinear basis function\n",
    "degree = 7\n",
    "nw = 2\n",
    "nz = 2\n",
    "phi = fss.f_static.basis.Polynomial(nz, degree)\n",
    "\n",
    "# As for the solver, we typically prefer a dedicated least-squares solver,\n",
    "# such as the Levenbergâ€“Marquardt (LM) algorithm. However, these solvers tend to have\n",
    "# a high memory footprint, which can quickly become prohibitive for large-scale problems\n",
    "# (like the one at hand). Your machine may not have enough memory to run it.\n",
    "#\n",
    "# This is especially true for our inference and learning approach, which involves:\n",
    "# - fixed-point iterations within the loss function,\n",
    "# - large feature matrices from nonlinear basis expansions,\n",
    "# - multiple FFT operations and reshaping steps,\n",
    "# all of which contribute to a large autodiff trace and memory pressure under LM.\n",
    "#\n",
    "# Fortunately, we can also opt for general-purpose minimizers that are more\n",
    "# memory-efficient, such as BFGS or any first-order optimizer from the Optax library!\n",
    "# These only require the gradient of a scalar loss and avoid tracing through the full\n",
    "# residual or Jacobian.\n",
    "#\n",
    "# Example solver choices:\n",
    "# solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6)\n",
    "# solver = optx.OptaxMinimiser(optax.adam(learning_rate=1e-3), rtol=1e-3, atol=1e-6)\n",
    "# solver = optx.BFGS(rtol=1e-3, atol=1e-6)\n",
    "\n",
    "# Solve the problem\n",
    "solver = optx.BFGS(rtol=1e-3, atol=1e-6)\n",
    "nllfr_init = fss.nonlin.inference_and_learning(\n",
    "    bla_opti, data, phi=phi, nw=nw, lambda_w=1, fixed_point_iters=5, solver=solver\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: full nonlinear optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarding the solver, the same story as above applies. But this optimization step is a\n",
    "# bit less  memory-hungry than inference and learning, so we can afford to use a more \n",
    "# powerful solver.\n",
    "#\n",
    "# Example solver choices:\n",
    "# solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6)\n",
    "# solver = optx.OptaxMinimiser(optax.adam(learning_rate=1e-3), rtol=1e-3, atol=1e-6)\n",
    "# solver = optx.BFGS(rtol=1e-3, atol=1e-6)\n",
    "\n",
    "# Solve the problem\n",
    "solver = optx.LevenbergMarquardt(rtol=1e-3, atol=1e-6)\n",
    "nllfr_opti = fss.nonlin.optimize(nllfr_init, data, solver=solver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "u_test = ParWH_test.u.reshape(N, 2).T.flatten()  # 2 periods in a single vector\n",
    "y_test = ParWH_test.y.reshape(N, 2).T.flatten()  # 2 periods in a single vector\n",
    "\n",
    "# Simulate BLA and NL-LFR models\n",
    "y_test_bla = bla_opti.simulate(u_test)[0]\n",
    "y_test_nllfr = nllfr_opti.simulate(u_test)[0]\n",
    "        \n",
    "# Check performance (we only check the second period)\n",
    "y_test = y_test[N:]\n",
    "e_test_bla = y_test - y_test_bla[N:]\n",
    "e_test_nllfr = y_test - y_test_nllfr[N:]\n",
    "\n",
    "mse_bla = np.mean((e_test_bla)**2)\n",
    "mse_nllfr_lfr = np.mean((e_test_nllfr)**2)\n",
    "norm = np.mean(y_test**2)\n",
    "\n",
    "print(f'NRMSE of BLA model on test data: {100 * np.sqrt(mse_bla / norm):.2f}%')\n",
    "print(f'NRMSE of NL-LFR model on test data: {100 * np.sqrt(mse_nllfr_lfr / norm):.2f}%')\n",
    "\n",
    "# Convert to frequency domain\n",
    "Y_test = np.fft.rfft(y_test, norm='forward')\n",
    "E_test_bla = np.fft.rfft(e_test_bla, norm='forward')\n",
    "E_test_nonlin_lfr = np.fft.rfft(e_test_nllfr, norm='forward')\n",
    "\n",
    "# Compute noise level\n",
    "Y_noise_std = np.sqrt(data.freq.Y_var_noise)\n",
    "Y_noise_std = 1 / N * Y_noise_std * data.norm.y_std  # denormalize\n",
    "\n",
    "t = data.time.t\n",
    "f = data.freq.f[f_idx]\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(9, 4))\n",
    "axs[0].plot(t, y_test, label='system output')\n",
    "axs[0].plot(t, e_test_bla, label='BLA error')\n",
    "axs[0].plot(t, e_test_nllfr, label='NL-LFR error')\n",
    "axs[0].set_title('Multisine - Time Domain')\n",
    "axs[0].set_xlabel('time [s]')\n",
    "axs[0].set_ylabel('output [V]')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(f, 20*np.log10(np.abs(Y_test[f_idx])), label='system output')\n",
    "axs[1].plot(f, 20*np.log10(np.abs(E_test_bla[f_idx])), label='BLA error')\n",
    "axs[1].plot(f, 20*np.log10(np.abs(E_test_nonlin_lfr[f_idx])), label='NL-LFR error')\n",
    "axs[1].plot(f, 20*np.log10(Y_noise_std[f_idx]), 'k', label='noise level')\n",
    "axs[1].set_title('Multisine - Frequency Domain')\n",
    "axs[1].set_xlabel('frequency [Hz]')\n",
    "axs[1].set_ylabel('magnitude [dB]')\n",
    "axs[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
