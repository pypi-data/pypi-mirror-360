# This file should be in the root directory where you run the tests.
# NOTE: This configuration requires an OpenAI API key to be set in your environment
# (e.g., export OPENAI_API_KEY="sk-...")

mcp_servers:
  # This key 'sample_server' is used in the @mcp_eval.task decorator
  sample_server:
    transport: stdio
    command: "python"
    args: ["sample_mcp_server.py"]
    # This server will use the 'openai_llm' provider defined below
    llm: openai_llm

openai:
  # Using a faster, cheaper model is ideal for testing
  model: gpt-3.5-turbo