# A model on OpenRouter
MODEL=google/gemini-2.5-flash-preview

# A local Ollama model
# MODEL=gemma3:27b-it-qat

# GitHub personal access token with repo scope
GITHUB_TOKEN=your_github_token_here

# OpenAI-compatible API configuration
# For OpenRouter (default), use openrouter.ai/api/v1
OPENAI_API_BASE_URL=https://openrouter.ai/api/v1

# Local Ollama OpenAI-compatible server
# OPENAI_API_BASE_URL=http://localhost:11434/v1

# OpenWebUI OpenAI-compatible server
# OPENAI_BASE_URL=http://localhost:8080/api

# API key can be specified via OPENAI_API_KEY (default) or OPENROUTER_API_KEY
# Use --api-key-env-var to specify a different environment variable name

# OPENROUTER_API_KEY=your_openrouter_key_here

# OPENAI_API_KEY=your_api_key_here

# In Docker
# CACHE_DIR=/app/.cache
# Not Docker
# CACHE_DIR=$HOME/.cache/git-fork-recon

# Optional: Override default context length
# CONTEXT_LENGTH=64000
