#!/usr/bin/env python3
"""
Test script to verify dynamic sentiment scoring
"""
import asyncio
import sys
sys.path.append('src')

from premium_futures_mcp.public_client import PublicBinanceClient
from premium_futures_mcp.market_intelligence import MarketIntelligenceService

async def test_dynamic_sentiment():
    """Test dynamic sentiment scoring for different categories"""
    
    # Test tokens from different categories
    test_tokens = [
        ('APEUSDT', 'NFT'),         # Should get high score (NFT performing well)
        ('UNIUSDT', 'DeFi'),        # Should get good score (DeFi performing well)  
        ('AIUSDT', 'AI'),           # Should get lower score (AI underperforming)
        ('DOGEUSDT', 'Meme'),       # Should get moderate score
        ('ETHUSDT', 'Layer-1'),     # Should get moderate score
    ]
    
    async with PublicBinanceClient() as client:
        intelligence = MarketIntelligenceService(client)
        
        # Get ticker data for dynamic calculation
        all_tickers = await client.get_all_tickers()
        
        # Calculate dynamic scores
        print("ğŸ§  DYNAMIC SENTIMENT SCORING TEST")
        print("=" * 60)
        
        print("\nğŸ“Š Calculating dynamic category scores...")
        dynamic_scores = await intelligence._calculate_dynamic_category_scores(all_tickers)
        
        print(f"\nğŸ¯ Category Performance Rankings:")
        sorted_categories = sorted(dynamic_scores.items(), key=lambda x: x[1], reverse=True)
        for i, (category, score) in enumerate(sorted_categories[:15], 1):
            metrics = intelligence.category_metrics_cache.get(category, {})
            active_tokens = metrics.get('active_tokens', 0)
            avg_change = metrics.get('avg_price_change', 0)
            total_volume = metrics.get('total_volume', 0)
            print(f"   {i:2d}. {category:12s}: {score:.2f}/4 ({active_tokens:2d} tokens, {avg_change:+6.2f}%, {total_volume:,.0f} vol)")
        
        print(f"\nğŸ” Individual Token Sentiment Analysis:")
        print("-" * 60)
        
        for symbol, expected_category in test_tokens:
            try:
                # Test the sentiment scoring
                sentiment_score, actual_category = await intelligence._calculate_sentiment_score(symbol)
                category_dynamic_score = dynamic_scores.get(actual_category, 1.0)
                
                print(f"\nğŸ“ˆ {symbol}")
                print(f"   Expected Category: {expected_category}")
                print(f"   Actual Category:   {actual_category}")
                print(f"   Category Score:    {category_dynamic_score:.2f}/4 (dynamic)")
                print(f"   Token Score:       {sentiment_score}/4")
                
                # Compare with old hardcoded score
                old_hardcoded = intelligence.narrative_scores.get(actual_category, 1)
                print(f"   Old Hardcoded:     {old_hardcoded}/4")
                
                if category_dynamic_score != old_hardcoded:
                    difference = category_dynamic_score - old_hardcoded
                    direction = "ğŸ“ˆ UPGRADE" if difference > 0 else "ğŸ“‰ DOWNGRADE"
                    print(f"   ğŸ“Š Change:         {direction} ({difference:+.2f} points)")
                else:
                    print(f"   ğŸ“Š Change:         No change")
                    
            except Exception as e:
                print(f"âŒ Error testing {symbol}: {e}")
        
        print(f"\nğŸ’¡ INSIGHTS:")
        print("   â€¢ Dynamic scoring reflects real market performance")
        print("   â€¢ Categories with strong performance get higher sentiment scores")
        print("   â€¢ This removes bias from hardcoded category rankings")
        print("   â€¢ Sentiment scores now update based on actual market data")

if __name__ == "__main__":
    asyncio.run(test_dynamic_sentiment())
