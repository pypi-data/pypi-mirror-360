# Copyright (c) 2024 Advanced Micro Devices, Inc.

---
attributes:
    # domain to use for new ops
    domains: com.ryzenai
    xclbins: ""
    op_namespaces: "hybrid"
    # set to "" or remove to use BF16 weights
    # is_bfp16: "weights"
    npu_jit: true
    # flag to enable logits prune
    prune_logits: false
# define the passes to run. These passes are defined in passes/ and are executed
# in order
# NOTE: any new passes that you add here may need to be added to the
# hybrid_llm.gitignore file
passes:
    - fastgelu_to_gelu
    # - initializers_to_bfloat16
    - normalize_matmulnbits
    - hybrid_llm_ssmlp
    - hybrid_llm_gqa
    - hybrid_llm_gqo:
        attributes:
            cast_kv_cache: false
    - hybrid_llm_kv_cache_to_bf16
    - hybrid_llm_matmulnbits
    - hybrid_llm_gqa_rotary_dim
    # convert any new ops
    - initializers_to_float16
    # this must be enabled for now for renaming the op_type
    - hybrid_llm_add_npu_weights_only
    - simplify_casts
    # - hybrid_llm_add_cast_attributes
    - hybrid_llm_add_empty_cast_attributes
    - hybrid_llm_prune_logits
    - simplify_matmulnbits
inherit_passes_after: !include [cleanup.yaml]
postprocess:
    - hybrid_llm_jit
