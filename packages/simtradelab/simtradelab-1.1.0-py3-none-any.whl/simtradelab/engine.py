# -*- coding: utf-8 -*-
"""
å›æµ‹å¼•æ“æ¨¡å—
"""
import importlib.util
import os
import types
from datetime import datetime
from typing import Union, List, Optional

import numpy as np
import pandas as pd

from . import financials, market_data, trading, utils
from .context import Context, Portfolio
from .logger import log
from .data_sources import DataSourceFactory, DataSourceManager, CSVDataSource
from .config import load_config
from .performance_optimizer import (
    get_global_cache, ConcurrentDataLoader, VectorizedCalculator, MemoryOptimizer
)
from .exceptions import DataLoadError, EngineError


class BacktestEngine:
    """
    å›æµ‹å¼•æ“ï¼Œè´Ÿè´£åŠ è½½ç­–ç•¥ã€æ¨¡æ‹Ÿäº¤æ˜“å¹¶è¿è¡Œå›æµ‹ã€‚
    """

    def __init__(self, strategy_file, data_path=None, start_date=None, end_date=None,
                 initial_cash=1000000, frequency='1d', data_source=None,
                 securities=None, config_path=None):
        """
        åˆå§‹åŒ–å›æµ‹å¼•æ“

        Args:
            strategy_file: ç­–ç•¥æ–‡ä»¶è·¯å¾„
            data_path: CSVæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆå‘åå…¼å®¹ï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            initial_cash: åˆå§‹èµ„é‡‘
            frequency: äº¤æ˜“é¢‘ç‡
            data_source: æ•°æ®æºç±»å‹æˆ–æ•°æ®æºå¯¹è±¡
            securities: è‚¡ç¥¨åˆ—è¡¨ï¼ˆç”¨äºåœ¨çº¿æ•°æ®æºï¼‰
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.strategy_file = strategy_file
        self.data_path = data_path
        self.start_date = pd.to_datetime(start_date) if start_date else None
        self.end_date = pd.to_datetime(end_date) if end_date else None
        self.initial_cash = initial_cash
        self.frequency = frequency
        self.securities = securities or []

        # åŠ è½½é…ç½®
        self.config = load_config(config_path)

        # åˆå§‹åŒ–æ•°æ®æº
        self.data_source_manager = self._init_data_source(data_source)

        # åˆå§‹åŒ–å…¶ä»–ç»„ä»¶
        self.portfolio = Portfolio(initial_cash)
        self.context = Context(self.portfolio)
        self.commission_ratio = 0.0003  # é»˜è®¤ä½£é‡‘
        self.min_commission = 5      # é»˜è®¤æœ€ä½ä½£é‡‘
        self.slippage = 0.001  # é»˜è®¤æ»‘ç‚¹
        self.data = self._load_data()
        self.current_data = {}
        self.portfolio_history = []
        self.strategy = self._load_strategy()

    def _init_data_source(self, data_source):
        """åˆå§‹åŒ–æ•°æ®æºç®¡ç†å™¨"""
        if data_source is None:
            # å‘åå…¼å®¹ï¼šå¦‚æœæŒ‡å®šäº†data_pathï¼Œä½¿ç”¨CSVæ•°æ®æº
            if self.data_path:
                primary_source = CSVDataSource(data_path=self.data_path)
                log.info("ä½¿ç”¨CSVæ•°æ®æºï¼ˆå‘åå…¼å®¹æ¨¡å¼ï¼‰")
            else:
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æ•°æ®æº
                default_source_name = self.config.get_default_source()
                primary_source = self._create_data_source(default_source_name)
                log.info(f"ä½¿ç”¨é»˜è®¤æ•°æ®æº: {default_source_name}")
        elif isinstance(data_source, str):
            # æ ¹æ®å­—ç¬¦ä¸²åˆ›å»ºæ•°æ®æº
            primary_source = self._create_data_source(data_source)
            log.info(f"ä½¿ç”¨æŒ‡å®šæ•°æ®æº: {data_source}")
        else:
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„æ•°æ®æºå¯¹è±¡
            primary_source = data_source
            log.info(f"ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®æº: {type(data_source).__name__}")

        # åˆ›å»ºæ•°æ®æºç®¡ç†å™¨ï¼ˆæš‚æ—¶ä¸æ·»åŠ å¤‡ç”¨æ•°æ®æºï¼‰
        return DataSourceManager(primary_source)

    def _create_data_source(self, source_name):
        """æ ¹æ®åç§°åˆ›å»ºæ•°æ®æº"""
        source_config = self.config.get_source_config(source_name)

        if source_name == 'csv':
            data_path = source_config.get('data_path', self.data_path or './data/sample_data.csv')
            return DataSourceFactory.create('csv', data_path=data_path)
        elif source_name == 'tushare':
            token = self.config.get_tushare_token()
            if not token:
                raise ValueError("Tushare tokenæœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡TUSHARE_TOKENæˆ–åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®")
            cache_dir = source_config.get('cache_dir', './cache/tushare')
            cache_enabled = source_config.get('cache_enabled', True)
            return DataSourceFactory.create('tushare', token=token,
                                          cache_dir=cache_dir, cache_enabled=cache_enabled)
        elif source_name == 'akshare':
            cache_dir = source_config.get('cache_dir', './cache/akshare')
            cache_enabled = source_config.get('cache_enabled', True)
            return DataSourceFactory.create('akshare',
                                          cache_dir=cache_dir, cache_enabled=cache_enabled)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹: {source_name}")

    def _load_strategy(self):
        """
        åŠ¨æ€åŠ è½½æŒ‡å®šçš„ç­–ç•¥æ–‡ä»¶ï¼Œå¹¶æ³¨å…¥APIå’Œ'g'å¯¹è±¡ã€‚
        """
        spec = importlib.util.spec_from_file_location("strategy", self.strategy_file)
        strategy_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(strategy_module)

        if not hasattr(strategy_module, 'g'):
            strategy_module.g = types.SimpleNamespace()

        strategy_module.log = log

        from . import compatibility, performance

        # æ³¨å…¥éœ€è¦engineå‚æ•°çš„APIå‡½æ•°
        api_modules = [financials, market_data, trading, utils]
        for module in api_modules:
            for func_name in dir(module):
                if not func_name.startswith("__"):
                    api_func = getattr(module, func_name)
                    # åªæ³¨å…¥å‡½æ•°ï¼Œæ’é™¤ç±»ã€æ¨¡å—å’Œå…¶ä»–å¯¹è±¡
                    if callable(api_func) and hasattr(api_func, '__call__') and not isinstance(api_func, type):
                        # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„åŒ…è£…å‡½æ•°ï¼Œç¡®ä¿è¿”å›å€¼ç±»å‹æ­£ç¡®
                        def create_wrapper(func, engine, name):
                            def wrapper(*args, **kwargs):
                                try:
                                    result = func(engine, *args, **kwargs)
                                    # å¯¹äº get_research_pathï¼Œç¡®ä¿è¿”å›å­—ç¬¦ä¸²
                                    if name == 'get_research_path' and not isinstance(result, str):
                                        log.warning(f"get_research_path è¿”å›äº†éå­—ç¬¦ä¸²ç±»å‹: {type(result)}, ä½¿ç”¨é»˜è®¤è·¯å¾„")
                                        return './'
                                    return result
                                except Exception as e:
                                    log.warning(f"APIå‡½æ•° {name} è°ƒç”¨å¤±è´¥: {e}")
                                    # ä¸ºå…³é”®å‡½æ•°æä¾›é»˜è®¤è¿”å›å€¼
                                    if name == 'get_research_path':
                                        return './'
                                    raise
                            return wrapper
                        setattr(strategy_module, func_name, create_wrapper(api_func, self, func_name))

        # æ³¨å…¥ä¸éœ€è¦engineå‚æ•°çš„å‡½æ•°ï¼ˆå…¼å®¹æ€§å’Œæ€§èƒ½æ¨¡å—ï¼‰
        standalone_modules = [compatibility, performance]
        for module in standalone_modules:
            for func_name in dir(module):
                if not func_name.startswith("__") and not func_name.startswith("_"):
                    api_func = getattr(module, func_name)
                    if callable(api_func):
                        setattr(strategy_module, func_name, api_func)

        # è®¾ç½®å½“å‰å¼•æ“åˆ°æ€§èƒ½æ¨¡å—
        performance._set_current_engine(self)

        return strategy_module

    def _load_data(self):
        """
        ä½¿ç”¨æ•°æ®æºç®¡ç†å™¨åŠ è½½æ•°æ®ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        """
        try:
            # ç”Ÿæˆç¼“å­˜é”®
            cache_key_params = {
                'securities': tuple(sorted(self.securities)) if self.securities else (),
                'start_date': self.start_date.strftime('%Y-%m-%d') if self.start_date else None,
                'end_date': self.end_date.strftime('%Y-%m-%d') if self.end_date else None,
                'frequency': self.frequency,
                'data_source': str(type(self.data_source_manager.primary_source).__name__)
            }
            
            # å°è¯•ä»ç¼“å­˜è·å–æ•°æ®
            cache = get_global_cache()
            cached_data = cache.get(**cache_key_params)
            if cached_data is not None:
                log.info("ä»ç¼“å­˜åŠ è½½æ•°æ®æˆåŠŸ")
                return MemoryOptimizer.reduce_memory_usage(cached_data)
            
            # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œå°è¯•ä»æ•°æ®æºè·å–å¯ç”¨çš„æ—¥æœŸèŒƒå›´
            if self.start_date is None or self.end_date is None:
                log.warning("æœªæŒ‡å®šæ—¥æœŸèŒƒå›´ï¼Œå°†å°è¯•åŠ è½½æ‰€æœ‰å¯ç”¨æ•°æ®")
                if self.start_date is None:
                    self.start_date = pd.to_datetime('2023-01-01')
                if self.end_date is None:
                    self.end_date = pd.to_datetime('2023-12-31')

            # ç¡®å®šè¦è·å–æ•°æ®çš„è‚¡ç¥¨åˆ—è¡¨
            securities = self.securities
            if not securities:
                securities = self.data_source_manager.get_stock_list()
                if not securities:
                    raise DataLoadError("æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œè¯·åœ¨åˆå§‹åŒ–æ—¶æŒ‡å®šsecuritieså‚æ•°")
                # é™åˆ¶è‚¡ç¥¨æ•°é‡ä»¥é¿å…è¿‡å¤šçš„APIè°ƒç”¨
                securities = securities[:10]
                log.info(f"è‡ªåŠ¨é€‰æ‹©è‚¡ç¥¨åˆ—è¡¨: {securities}")

            # ä½¿ç”¨å¹¶å‘åŠ è½½å™¨åŠ è½½æ•°æ®
            if len(securities) > 1:
                log.info(f"ä½¿ç”¨å¹¶å‘æ–¹å¼åŠ è½½ {len(securities)} åªè‚¡ç¥¨æ•°æ®")
                concurrent_loader = ConcurrentDataLoader(max_workers=min(4, len(securities)))
                data_dict = concurrent_loader.load_multiple_securities(
                    self.data_source_manager,
                    securities,
                    self.start_date.strftime('%Y-%m-%d'),
                    self.end_date.strftime('%Y-%m-%d'),
                    self.frequency
                )
            else:
                # å•åªè‚¡ç¥¨ç›´æ¥åŠ è½½
                data_dict = self.data_source_manager.get_history(
                    securities=securities,
                    start_date=self.start_date.strftime('%Y-%m-%d'),
                    end_date=self.end_date.strftime('%Y-%m-%d'),
                    frequency=self.frequency
                )

            if not data_dict:
                raise DataLoadError("æœªèƒ½åŠ è½½åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®")

            # å†…å­˜ä¼˜åŒ–
            optimized_data = MemoryOptimizer.reduce_memory_usage(data_dict)
            
            # ç¼“å­˜æ•°æ®
            cache.set(data_dict, **cache_key_params)
            
            log.info(f"æˆåŠŸåŠ è½½ {len(optimized_data)} åªè‚¡ç¥¨çš„æ•°æ®")
            return optimized_data

        except DataLoadError:
            raise
        except Exception as e:
            log.error(f"åŠ è½½æ•°æ®å¤±è´¥: {e}")
            raise DataLoadError(f"æ•°æ®åŠ è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}") from e


    def _is_daily_data(self, df):
        """
        åˆ¤æ–­æ•°æ®æ˜¯å¦ä¸ºæ—¥çº¿æ•°æ®ã€‚
        """
        if df.empty:
            return True
        time_diff = df.index[1] - df.index[0] if len(df) > 1 else pd.Timedelta(days=1)
        return time_diff >= pd.Timedelta(days=1)

    def _generate_minute_data(self, daily_df):
        """
        ä»æ—¥çº¿æ•°æ®ç”Ÿæˆåˆ†é’Ÿçº§æ•°æ®ã€‚
        """
        freq_map = {'1m': 1, '5m': 5, '15m': 15, '30m': 30}
        minute_interval = freq_map.get(self.frequency, 1)
        periods_per_day = 240 // minute_interval

        minute_data_list = []
        for security, security_data in daily_df.groupby('security'):
            for idx, row in security_data.iterrows():
                day_start = idx.replace(hour=9, minute=30)
                minute_times = pd.date_range(start=day_start, periods=periods_per_day, freq=f'{minute_interval}min')
                daily_range = row['high'] - row['low']
                daily_volume = row['volume']

                for i, minute_time in enumerate(minute_times):
                    progress = i / periods_per_day
                    np.random.seed(int(minute_time.timestamp()) % 10000)
                    noise = np.random.normal(0, daily_range * 0.01)
                    minute_close = max(row['low'], min(row['high'], row['low'] + daily_range * progress + noise))
                    minute_open = minute_close * (1 + np.random.normal(0, 0.001))
                    minute_high = max(minute_open, minute_close, minute_close * (1 + abs(np.random.normal(0, 0.002))))
                    minute_low = min(minute_open, minute_close, minute_close * (1 - abs(np.random.normal(0, 0.002))))
                    minute_volume = daily_volume / periods_per_day

                    minute_data_list.append({
                        'datetime': minute_time, 'open': minute_open, 'high': minute_high,
                        'low': minute_low, 'close': minute_close, 'volume': minute_volume,
                        'security': security
                    })

        if not minute_data_list:
            return daily_df
        
        minute_df = pd.DataFrame(minute_data_list)
        minute_df.set_index('datetime', inplace=True)
        return minute_df

    def _update_portfolio_value(self, current_prices):
        """
        æ ¹æ®å½“å‰ä»·æ ¼æ›´æ–°æŠ•èµ„ç»„åˆçš„æ€»ä»·å€¼ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
        """
        try:
            # å‘é‡åŒ–è®¡ç®—æŒä»“ä»·å€¼
            if not self.portfolio.positions:
                self.portfolio.total_value = self.portfolio.cash
                return
                
            # ä½¿ç”¨ numpy æ•°ç»„è¿›è¡Œå‘é‡åŒ–è®¡ç®—
            securities = list(self.portfolio.positions.keys())
            amounts = np.array([pos.amount for pos in self.portfolio.positions.values()])
            prices = np.array([current_prices.get(sec, 0) for sec in securities])
            
            # å‘é‡åŒ–è®¡ç®—æ€»æŒä»“ä»·å€¼
            total_position_value = np.sum(amounts * prices)
            self.portfolio.total_value = self.portfolio.cash + total_position_value
            
        except Exception as e:
            log.warning(f"æ›´æ–°æŠ•èµ„ç»„åˆä»·å€¼æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            # å›é€€åˆ°åŸå§‹æ–¹æ³•
            # å›é€€åˆ°æ›´å®‰å…¨çš„æ–¹æ³•
            total_value = self.portfolio.cash
            for security, position in self.portfolio.positions.items():
                price = current_prices.get(security, 0)
                try:
                    # å°è¯•è¿›è¡Œè®¡ç®—ï¼Œå¦‚æœæŒä»“æ•°é‡æ— æ•ˆåˆ™è·³è¿‡
                    if isinstance(position.amount, (int, float)):
                        total_value += position.amount * price
                except TypeError:
                    log.warning(f"è·³è¿‡æ— æ•ˆçš„æŒä»“æ•°æ®: {security}")
            self.portfolio.total_value = total_value

    def run(self):
        """
        è¿è¡Œå›æµ‹ã€‚
        """
        start_time_str = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        strategy_name = os.path.basename(self.strategy_file).replace('.py', '')
        print(f"{start_time_str} å¼€å§‹è¿è¡Œå›æµ‹, ç­–ç•¥åç§°: {strategy_name}, é¢‘ç‡: {self.frequency}")

        if hasattr(self.strategy, 'initialize'):
            self.strategy.initialize(self.context)

        if not self.data:
            log.warning("æ²¡æœ‰å¯ç”¨çš„æ•°æ®")
            return

        first_security = list(self.data.keys())[0]
        trading_times = self.data[first_security].index
        trading_times = trading_times[(trading_times >= self.start_date) & (trading_times <= self.end_date)]

        if self.frequency == '1d':
            self._run_daily_backtest(trading_times)
        else:
            self._run_minute_backtest(trading_times)

        log.current_dt = None
        log.info("ç­–ç•¥å›æµ‹ç»“æŸ")

        # ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š
        generated_files = self._generate_performance_report()
        return generated_files

    def _run_daily_backtest(self, trading_days):
        """
        è¿è¡Œæ—¥çº¿å›æµ‹ã€‚
        """
        previous_day = None
        for day in trading_days:
            self.context.current_dt = day
            self.context.previous_date = previous_day.date() if previous_day is not None else day.date()
            log.current_dt = day.replace(hour=9, minute=30)

            # æ›´æ–°äº¤æ˜“æ—¥å¼€å§‹æ•°æ®
            self.context.portfolio.update_daily_start()

            # é‡ç½®å½“æ—¥è®¢å•å’Œæˆäº¤æ•°æ®
            self.context.blotter.reset_daily_data()

            self.current_data = {sec: df.loc[day] for sec, df in self.data.items() if day in df.index}
            self._update_position_prices()
            self._execute_trading_session()

            current_prices = {sec: data['close'] for sec, data in self.current_data.items()}
            self._update_portfolio_value(current_prices)
            self.portfolio_history.append({
                'datetime': day, 'total_value': self.portfolio.total_value, 'cash': self.portfolio.cash
            })
            previous_day = day

    def _run_minute_backtest(self, trading_times):
        """
        è¿è¡Œåˆ†é’Ÿçº§å›æµ‹ã€‚
        """
        current_day = None
        previous_time = None
        for current_time in trading_times:
            self.context.current_dt = current_time
            self.context.previous_date = previous_time.date() if previous_time is not None else current_time.date()
            log.current_dt = current_time
            self.current_data = {sec: df.loc[current_time] for sec, df in self.data.items() if current_time in df.index}
            self._update_position_prices()

            if current_day is None or current_time.date() != current_day:
                current_day = current_time.date()
                if hasattr(self.strategy, 'before_trading_start'):
                    self.strategy.before_trading_start(self.context, self.current_data)

            if hasattr(self.strategy, 'handle_data'):
                self.strategy.handle_data(self.context, self.current_data)

            if current_time.hour == 15 and current_time.minute == 0 and hasattr(self.strategy, 'after_trading_end'):
                self.strategy.after_trading_end(self.context, self.current_data)

            current_prices = {sec: data['close'] for sec, data in self.current_data.items()}
            self._update_portfolio_value(current_prices)

            if current_time.minute == 0 or (current_time.hour == 15 and current_time.minute == 0):
                self.portfolio_history.append({
                    'datetime': current_time, 'total_value': self.portfolio.total_value, 'cash': self.portfolio.cash
                })
            previous_time = current_time

    def _update_position_prices(self):
        """
        æ›´æ–°æŒä»“æœ€æ–°ä»·æ ¼ã€‚
        """
        for stock, pos in self.context.portfolio.positions.items():
            if stock in self.current_data:
                pos.last_sale_price = self.current_data[stock]['close']

    def _execute_trading_session(self):
        """
        æ‰§è¡Œæ—¥çº¿äº¤æ˜“ä¼šè¯ã€‚
        """
        if hasattr(self.strategy, 'before_trading_start'):
            self.strategy.before_trading_start(self.context, self.current_data)

        if hasattr(self.strategy, 'handle_data'):
            self.strategy.handle_data(self.context, self.current_data)

        if hasattr(self.strategy, 'after_trading_end'):
            log.current_dt = self.context.current_dt.replace(hour=15, minute=30)
            self.strategy.after_trading_end(self.context, self.current_data)

    def _generate_performance_report(self):
        """ç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š"""
        from .performance import print_performance_report
        from .report_generator import ReportGenerator
        from .utils import get_benchmark_returns

        # è·å–åŸºå‡†æ”¶ç›Šç‡ï¼ˆå¦‚æœè®¾ç½®äº†åŸºå‡†ï¼‰
        benchmark_returns = None
        if hasattr(self, 'benchmark') and self.benchmark:
            benchmark_returns = get_benchmark_returns(self, self.start_date, self.end_date)

        # æ‰“å°æ€§èƒ½æŠ¥å‘Š
        print_performance_report(self, benchmark_returns)

        # ç”Ÿæˆå¤šæ ¼å¼æŠ¥å‘Šæ–‡ä»¶
        report_generator = ReportGenerator(self)
        generated_files = []

        # ç”Ÿæˆç»¼åˆæ–‡æœ¬æŠ¥å‘Š
        txt_file = report_generator.generate_comprehensive_report(
            benchmark_returns=benchmark_returns,
            include_strategy_code=True,
            include_trade_details=True
        )
        if txt_file:
            generated_files.append(txt_file)

        # ç”ŸæˆJSONæŠ¥å‘Šï¼ˆç”¨äºç¨‹åºåŒ–åˆ†æï¼‰
        json_file = report_generator.generate_json_report(benchmark_returns)
        if json_file:
            generated_files.append(json_file)

        # ç”ŸæˆCSVæŠ¥å‘Šï¼ˆæŠ•èµ„ç»„åˆå†å²ï¼‰
        csv_file = report_generator.generate_csv_report()
        if csv_file:
            generated_files.append(csv_file)

        # ç”Ÿæˆç®€æ´æ‘˜è¦æŠ¥å‘Š
        summary_file = report_generator.generate_summary_report(benchmark_returns)
        if summary_file:
            generated_files.append(summary_file)


        # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        if generated_files:
            print(f"\nğŸ“„ æŠ¥å‘Šæ–‡ä»¶å·²ç”Ÿæˆ:")
            for file_path in generated_files:
                file_type = self._get_file_type_emoji(file_path)
                print(f"   {file_type} {os.path.basename(file_path)}")
            print(f"   ğŸ“ æŠ¥å‘Šç›®å½•: {os.path.dirname(generated_files[0])}")

        return generated_files

    def _get_file_type_emoji(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶ç±»å‹è¿”å›å¯¹åº”çš„emoji"""
        if file_path.endswith('.txt'):
            if 'summary' in file_path:
                return 'ğŸ“‹'
            else:
                return 'ğŸ“'
        elif file_path.endswith('.json'):
            return 'ğŸ“Š'
        elif file_path.endswith('.csv'):
            return 'ğŸ“ˆ'
        else:
            return 'ğŸ“„'