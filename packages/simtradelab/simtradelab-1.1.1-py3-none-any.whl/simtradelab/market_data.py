# -*- coding: utf-8 -*-
"""
å¸‚åœºæ•°æ®æ¥å£æ¨¡å—

=======================
PTrade å®Œå…¨å…¼å®¹æ•°æ®æ¥å£
=======================

æä¾›ä¸ PTrade å®Œå…¨ä¸€è‡´çš„å¸‚åœºæ•°æ®è·å–æ¥å£ï¼Œæ”¯æŒï¼š

ğŸ“Š **åŸºç¡€è¡Œæƒ…æ•°æ®**
- get_history(): å†å²æ•°æ®è·å–ï¼Œä¸PTradeå‚æ•°å®Œå…¨ä¸€è‡´
- get_price(): å®æ—¶/å†å²ä»·æ ¼æŸ¥è¯¢
- get_current_data(): å½“å‰å¸‚åœºæ•°æ®å¿«ç…§

ğŸ“ˆ **æŠ€æœ¯æŒ‡æ ‡è®¡ç®—**
- get_MACD(), get_KDJ(), get_RSI(), get_CCI(): æŠ€æœ¯æŒ‡æ ‡
- get_technical_indicators(): æ‰¹é‡æŠ€æœ¯æŒ‡æ ‡è®¡ç®—

ğŸ” **é«˜çº§å¸‚åœºæ•°æ®**
- get_snapshot(): è‚¡ç¥¨å¿«ç…§æ•°æ®ï¼ŒåŒ…å«ä¹°å–äº”æ¡£
- get_individual_entrust(): é€ç¬”å§”æ‰˜æ•°æ®
- get_individual_transaction(): é€ç¬”æˆäº¤æ•°æ®
- get_gear_price(): æ¡£ä½è¡Œæƒ…ä»·æ ¼

ğŸ“‹ **å¸‚åœºç»Ÿè®¡æ•°æ®**
- get_volume_ratio(): é‡æ¯”è®¡ç®—
- get_turnover_rate(): æ¢æ‰‹ç‡
- get_pe_ratio(): å¸‚ç›ˆç‡
- get_pb_ratio(): å¸‚å‡€ç‡
- get_sort_msg(): æ¿å—è¡Œä¸šæ’å

ğŸ• **äº¤æ˜“æ—¥å†**
- get_previous_trading_date(): ä¸Šä¸€äº¤æ˜“æ—¥
- get_next_trading_date(): ä¸‹ä¸€äº¤æ˜“æ—¥

PTrade å…¼å®¹æ€§è¯´æ˜:
- æ‰€æœ‰å‡½æ•°å‚æ•°ä¸PTradeå®Œå…¨ä¸€è‡´
- è¿”å›æ•°æ®æ ¼å¼ä¸PTradeä¿æŒç»Ÿä¸€
- æ”¯æŒPTradeçš„æ‰€æœ‰æ•°æ®é¢‘ç‡å’Œå­—æ®µ
- é”™è¯¯å¤„ç†æ–¹å¼ä¸PTradeç›¸åŒ

æ•°æ®æºæ”¯æŒ:
- CSVæ–‡ä»¶æ•°æ®ï¼ˆæœ¬åœ°å›æµ‹ï¼‰
- Tushareæ•°æ®æºï¼ˆåœ¨çº¿æ•°æ®ï¼‰
- AkShareæ•°æ®æºï¼ˆå…è´¹æ•°æ®ï¼‰
- å¯æ‰©å±•å…¶ä»–æ•°æ®æº
"""
from typing import Union, List, Optional, Dict, Any
import hashlib
import pandas as pd
import numpy as np
from .logger import log

def get_history(
    engine: 'BacktestEngine',
    count: int,
    frequency: str = '1d',
    field: Union[str, List[str]] = ['open','high','low','close','volume','money','price'],
    security_list: Optional[List[str]] = None,
    fq: Optional[str] = None,
    include: bool = False,
    fill: str = 'nan',
    is_dict: bool = False,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> Union[pd.DataFrame, Dict[str, Dict[str, np.ndarray]]]:
    """
    è·å–å†å²æ•°æ®

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        count: Kçº¿æ•°é‡ï¼Œå¤§äº0ï¼Œè¿”å›æŒ‡å®šæ•°é‡çš„Kçº¿è¡Œæƒ…
        frequency: Kçº¿å‘¨æœŸï¼Œæ”¯æŒ1åˆ†é’Ÿçº¿(1m)ã€5åˆ†é’Ÿçº¿(5m)ã€15åˆ†é’Ÿçº¿(15m)ã€30åˆ†é’Ÿçº¿(30m)ã€
                  60åˆ†é’Ÿçº¿(60m)ã€120åˆ†é’Ÿçº¿(120m)ã€æ—¥çº¿(1d)ã€å‘¨çº¿(1w/weekly)ã€
                  æœˆçº¿(mo/monthly)ã€å­£åº¦çº¿(1q/quarter)å’Œå¹´çº¿(1y/yearly)é¢‘ç‡çš„æ•°æ®ï¼Œé»˜è®¤ä¸º'1d'
        field: æŒ‡æ˜æ•°æ®ç»“æœé›†ä¸­æ‰€æ”¯æŒè¾“å‡ºçš„è¡Œæƒ…å­—æ®µï¼Œé»˜è®¤ä¸º['open','high','low','close','volume','money','price']
               æ”¯æŒå­—æ®µï¼šopen, high, low, close, volume, money, price, preclose, high_limit, low_limit, unlimited
        security_list: è¦è·å–æ•°æ®çš„è‚¡ç¥¨åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºåœ¨ä¸Šä¸‹æ–‡ä¸­çš„universeä¸­é€‰ä¸­çš„æ‰€æœ‰è‚¡ç¥¨
        fq: æ•°æ®å¤æƒé€‰é¡¹ï¼Œæ”¯æŒpre-å‰å¤æƒï¼Œpost-åå¤æƒï¼Œdypre-åŠ¨æ€å‰å¤æƒï¼ŒNone-ä¸å¤æƒï¼Œé»˜è®¤ä¸ºNone
        include: æ˜¯å¦åŒ…å«å½“å‰å‘¨æœŸï¼ŒTrueâ€“åŒ…å«ï¼ŒFalse-ä¸åŒ…å«ï¼Œé»˜è®¤ä¸ºFalse
        fill: è¡Œæƒ…è·å–ä¸åˆ°æŸä¸€æ—¶åˆ»çš„åˆ†é’Ÿæ•°æ®æ—¶ï¼Œæ˜¯å¦ç”¨ä¸Šä¸€åˆ†é’Ÿçš„æ•°æ®è¿›è¡Œå¡«å……è¯¥æ—¶åˆ»æ•°æ®ï¼Œ
              'pre'â€“ç”¨ä¸Šä¸€åˆ†é’Ÿæ•°æ®å¡«å……ï¼Œ'nan'â€“NaNè¿›è¡Œå¡«å……ï¼Œé»˜è®¤ä¸º'nan'
        is_dict: è¿”å›æ˜¯å¦æ˜¯å­—å…¸(dict)æ ¼å¼{str: array()}ï¼ŒTrueâ€“æ˜¯ï¼ŒFalse-ä¸æ˜¯ï¼Œé»˜è®¤ä¸ºFalse
        start_date: å¼€å§‹æ—¥æœŸ (æ‰©å±•å‚æ•°)
        end_date: ç»“æŸæ—¥æœŸ (æ‰©å±•å‚æ•°)
        
    Returns:
        DataFrame æˆ–å­—å…¸æ ¼å¼çš„å†å²æ•°æ®
    """
    if security_list is None:
        security_list = list(engine.data.keys())

    if isinstance(field, str):
        field = [field]

    frequency_mapping = {
        '1d': 'D', 'daily': 'D', '1m': 'T', 'minute': 'T', '5m': '5T', '5min': '5T',
        '15m': '15T', '15min': '15T', '30m': '30T', '30min': '30T', '1h': 'H',
        'hour': 'H', '1w': 'W', 'week': 'W', '1M': 'M', 'month': 'M'
    }
    pandas_freq = frequency_mapping.get(frequency, 'D')

    extended_fields = {
        'pre_close', 'change', 'pct_change', 'amplitude',
        'turnover_rate', 'amount', 'vwap', 'high_limit', 'low_limit'
    }

    if is_dict:
        result = {}
        for sec in security_list:
            if sec not in engine.data:
                result[sec] = {col: np.array([]) for col in field}
                continue

            hist_df = engine.data[sec].copy()

            if hasattr(engine, 'context') and engine.context.current_dt:
                valid_hist = hist_df[hist_df.index <= engine.context.current_dt] if include else hist_df[hist_df.index < engine.context.current_dt]
            else:
                valid_hist = hist_df

            if start_date:
                valid_hist = valid_hist[valid_hist.index >= pd.to_datetime(start_date)]
            if end_date:
                valid_hist = valid_hist[valid_hist.index <= pd.to_datetime(end_date)]

            if pandas_freq != 'D' and not valid_hist.empty:
                if pandas_freq in ['T', '5T', '15T', '30T', 'H']:
                    expanded_data = []
                    for _, row in valid_hist.iterrows():
                        periods_per_day = 240 if pandas_freq == 'T' else 48 if pandas_freq == '5T' else 16 if pandas_freq == '15T' else 8 if pandas_freq == '30T' else 4
                        day_start = _.replace(hour=9, minute=30)
                        time_range = pd.date_range(start=day_start, periods=periods_per_day, freq=pandas_freq)
                        daily_range = row['high'] - row['low']
                        for i, _ in enumerate(time_range):
                            progress = i / periods_per_day
                            noise = np.random.normal(0, daily_range * 0.01)
                            minute_close = max(row['low'], min(row['high'], row['low'] + daily_range * progress + noise))
                            expanded_data.append({
                                'open': minute_close * (1 + np.random.normal(0, 0.001)),
                                'high': minute_close * (1 + abs(np.random.normal(0, 0.002))),
                                'low': minute_close * (1 - abs(np.random.normal(0, 0.002))),
                                'close': minute_close,
                                'volume': row['volume'] / periods_per_day
                            })
                    if expanded_data:
                        valid_hist = pd.DataFrame(expanded_data)
                        valid_hist.index = pd.date_range(start=valid_hist.index[0].replace(hour=9, minute=30), periods=len(expanded_data), freq=pandas_freq)
                elif pandas_freq in ['W', 'M']:
                    valid_hist = valid_hist.resample(pandas_freq).agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'}).dropna()

            if count and len(valid_hist) > count:
                valid_hist = valid_hist.tail(count)

            if valid_hist.empty:
                result[sec] = {col: np.array([]) for col in field}
                continue

            for ext_field in field:
                if ext_field in extended_fields:
                    pre_close = valid_hist['close'].shift(1)
                    if ext_field == 'pre_close':
                        valid_hist['pre_close'] = pre_close
                    elif ext_field == 'change':
                        valid_hist['change'] = valid_hist['close'] - pre_close
                    elif ext_field == 'pct_change':
                        valid_hist['pct_change'] = (valid_hist['close'] / pre_close - 1) * 100
                    elif ext_field == 'amplitude':
                        valid_hist['amplitude'] = ((valid_hist['high'] - valid_hist['low']) / pre_close) * 100
                    elif ext_field == 'turnover_rate':
                        hash_factor = int(hashlib.md5(sec.encode()).hexdigest()[:8], 16) / 0xffffffff
                        valid_hist['turnover_rate'] = 2.5 + 5.0 * hash_factor
                    elif ext_field == 'amount':
                        valid_hist['amount'] = valid_hist['volume'] * valid_hist['close'] / 10000
                    elif ext_field == 'vwap':
                        valid_hist['vwap'] = (valid_hist['high'] + valid_hist['low'] + valid_hist['close'] * 2) / 4
                    elif ext_field == 'high_limit':
                        valid_hist['high_limit'] = pre_close * 1.1
                    elif ext_field == 'low_limit':
                        valid_hist['low_limit'] = pre_close * 0.9

            result[sec] = {col: valid_hist[col].to_numpy() if col in valid_hist.columns else np.array([]) for col in field}
        return result

    result_df = pd.DataFrame()
    for sec in security_list:
        if sec not in engine.data:
            continue
        hist_df = engine.data[sec].copy()
        if hasattr(engine, 'context') and engine.context.current_dt:
            valid_hist = hist_df[hist_df.index <= engine.context.current_dt] if include else hist_df[hist_df.index < engine.context.current_dt]
        else:
            valid_hist = hist_df
        if start_date:
            valid_hist = valid_hist[valid_hist.index >= pd.to_datetime(start_date)]
        if end_date:
            valid_hist = valid_hist[valid_hist.index <= pd.to_datetime(end_date)]
        if count and len(valid_hist) > count:
            valid_hist = valid_hist.tail(count)
        if valid_hist.empty:
            continue
        for f in field:
            if f in valid_hist.columns:
                result_df[(f, sec)] = valid_hist[f]
            else:
                log.warning(f"å­—æ®µ '{f}' ä¸å­˜åœ¨")
    
    # ç¡®ä¿å³ä½¿ç»“æœä¸ºç©ºä¹Ÿè¿”å›æ˜ç¡®çš„DataFrameè€Œä¸æ˜¯å®¹æ˜“è¢«è¯¯ç”¨çš„ç©ºDataFrame
    if result_df.empty:
        # è¿”å›å¸¦æœ‰æ˜ç¡®åˆ—ç»“æ„çš„ç©ºDataFrameï¼Œé¿å…å¸ƒå°”å€¼æ··æ·†
        columns = [(f, sec) for f in field for sec in security_list if sec in engine.data]
        result_df = pd.DataFrame(columns=columns)
    
    return result_df

def get_price(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    start_date: Optional[str] = None, 
    end_date: Optional[str] = None, 
    frequency: str = '1d', 
    fields: Optional[Union[str, List[str]]] = None, 
    count: Optional[int] = None
) -> pd.DataFrame:
    """
    è·å–ä»·æ ¼æ•°æ®
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        frequency: æ•°æ®é¢‘ç‡
        fields: å­—æ®µåæˆ–å­—æ®µåˆ—è¡¨
        count: æ•°æ®æ¡æ•°
        
    Returns:
        ä»·æ ¼æ•°æ®DataFrame
    """
    count = count or 1
    securities = [security] if isinstance(security, str) else security
    fields = ['close'] if fields is None else ([fields] if isinstance(fields, str) else fields)

    all_supported_fields = {
        'open', 'high', 'low', 'close', 'volume', 'pre_close', 'change', 'pct_change',
        'amplitude', 'turnover_rate', 'vwap', 'amount', 'high_limit', 'low_limit'
    }

    result_data = {}
    for sec in securities:
        if sec not in engine.data:
            log.warning(f"è‚¡ç¥¨ {sec} çš„æ•°æ®ä¸å­˜åœ¨")
            continue

        hist_df = engine.data[sec]
        current_dt = engine.context.current_dt if hasattr(engine, 'context') else None
        valid_hist = hist_df[hist_df.index < current_dt] if current_dt else hist_df

        if valid_hist.empty:
            log.warning(f"è‚¡ç¥¨ {sec} æ²¡æœ‰æœ‰æ•ˆçš„å†å²æ•°æ®")
            continue

        recent_data = valid_hist.tail(count)
        result_data[sec] = {}
        for field in fields:
            if field in recent_data.columns:
                result_data[sec][field] = recent_data[field].tolist()
            elif field in all_supported_fields:
                calculated_values = []
                for _, row in recent_data.iterrows():
                    pre_close = row['close'] * 0.98
                    if field == 'pre_close':
                        calculated_values.append(pre_close)
                    elif field == 'change':
                        calculated_values.append(row['close'] - pre_close)
                    elif field == 'pct_change':
                        calculated_values.append(((row['close'] - pre_close) / pre_close) * 100)
                    elif field == 'amplitude':
                        calculated_values.append(((row['high'] - row['low']) / pre_close) * 100)
                    elif field == 'turnover_rate':
                        hash_factor = int(hashlib.md5(sec.encode()).hexdigest()[:8], 16) / 0xffffffff
                        calculated_values.append(2.5 + 5.0 * hash_factor)
                    elif field == 'vwap':
                        calculated_values.append((row['high'] + row['low'] + row['close'] * 2) / 4)
                    elif field == 'amount':
                        calculated_values.append(row['volume'] * row['close'] / 10000)
                    elif field == 'high_limit':
                        calculated_values.append(pre_close * 1.1)
                    elif field == 'low_limit':
                        calculated_values.append(pre_close * 0.9)
                result_data[sec][field] = calculated_values
            else:
                log.warning(f"ä¸æ”¯æŒçš„å­—æ®µ: {field}")
                result_data[sec][field] = [None] * count

    if not result_data:
        # å¯¹äºå•ä¸ªè‚¡ç¥¨è¯·æ±‚closeä»·æ ¼çš„æƒ…å†µï¼Œè¿”å›Noneè€Œä¸æ˜¯ç©ºDataFrameï¼Œé¿å…å¸ƒå°”å€¼é”™è¯¯
        if isinstance(security, str) and len(fields) == 1 and fields[0] == 'close':
            return None
        return pd.DataFrame()

    sample_data = engine.data[securities[0]]
    current_dt = engine.context.current_dt if hasattr(engine, 'context') else None
    valid_hist = sample_data[sample_data.index < current_dt] if current_dt else sample_data
    time_index = valid_hist.tail(count).index

    result_df = pd.DataFrame()
    for field in fields:
        for sec in securities:
            if sec in result_data and field in result_data[sec] and len(result_data[sec][field]) == len(time_index):
                result_df[(field, sec)] = pd.Series(result_data[sec][field], index=time_index)

    if len(fields) == 1:
        result_df.columns = [col[1] for col in result_df.columns]

    # ç‰¹æ®Šå¤„ç†ï¼šå•ä¸ªè‚¡ç¥¨çš„å•ä¸ªå­—æ®µï¼ˆé€šå¸¸æ˜¯closeä»·æ ¼ï¼‰ï¼Œè¿”å›æ•°å€¼è€Œä¸æ˜¯DataFrame
    if isinstance(security, str) and len(fields) == 1 and not result_df.empty:
        if fields[0] == 'close':
            # è¿”å›æœ€æ–°çš„closeä»·æ ¼ä½œä¸ºæ•°å€¼
            return float(result_df.iloc[-1, 0])

    return result_df

def get_current_data(
    engine: 'BacktestEngine', 
    security: Optional[Union[str, List[str]]] = None
) -> Dict[str, Dict[str, float]]:
    """
    è·å–å½“å‰å®æ—¶å¸‚åœºæ•°æ®
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼ŒNoneè¡¨ç¤ºæ‰€æœ‰è‚¡ç¥¨
        
    Returns:
        å½“å‰å¸‚åœºæ•°æ®å­—å…¸
    """
    securities = list(engine.data.keys()) if security is None else ([security] if isinstance(security, str) else security)
    current_data = {}
    for sec in securities:
        if sec not in engine.data:
            log.warning(f"è‚¡ç¥¨ {sec} çš„æ•°æ®ä¸å­˜åœ¨")
            continue

        hist_df = engine.data[sec]
        current_dt = engine.context.current_dt if hasattr(engine, 'context') else None
        valid_hist = hist_df[hist_df.index <= current_dt] if current_dt else hist_df

        if valid_hist.empty:
            continue

        latest_data = valid_hist.iloc[-1]
        hash_factor = int(hashlib.md5(sec.encode()).hexdigest()[:8], 16) / 0xffffffff
        current_price = latest_data['close']
        spread = current_price * 0.001

        current_data[sec] = {
            'open': latest_data['open'], 'high': latest_data['high'], 'low': latest_data['low'],
            'close': current_price, 'volume': latest_data['volume'],
            'bid1': current_price - spread, 'bid2': current_price - spread * 2, 'bid3': current_price - spread * 3,
            'bid4': current_price - spread * 4, 'bid5': current_price - spread * 5,
            'ask1': current_price + spread, 'ask2': current_price + spread * 2, 'ask3': current_price + spread * 3,
            'ask4': current_price + spread * 4, 'ask5': current_price + spread * 5,
            'bid1_volume': int(1000 + 5000 * hash_factor), 'bid2_volume': int(800 + 4000 * hash_factor),
            'bid3_volume': int(600 + 3000 * hash_factor), 'bid4_volume': int(400 + 2000 * hash_factor),
            'bid5_volume': int(200 + 1000 * hash_factor), 'ask1_volume': int(1200 + 5500 * hash_factor),
            'ask2_volume': int(900 + 4500 * hash_factor), 'ask3_volume': int(700 + 3500 * hash_factor),
            'ask4_volume': int(500 + 2500 * hash_factor), 'ask5_volume': int(300 + 1500 * hash_factor),
            'pre_close': current_price * 0.98, 'change': current_price * 0.02, 'pct_change': 2.04,
            'amount': np.float64(latest_data['volume']) * np.float64(current_price) / 10000,
            'turnover_rate': 2.5 + 5.0 * hash_factor,
            'high_limit': current_price * 0.98 * 1.1, 'low_limit': current_price * 0.98 * 0.9,
            'amplitude': ((latest_data['high'] - latest_data['low']) / (current_price * 0.98)) * 100,
            'vwap': (latest_data['high'] + latest_data['low'] + current_price * 2) / 4,
        }
    return current_data

def get_market_snapshot(
    engine: 'BacktestEngine', 
    security: Optional[Union[str, List[str]]] = None, 
    fields: Optional[Union[str, List[str]]] = None
) -> pd.DataFrame:
    """
    è·å–å¸‚åœºå¿«ç…§æ•°æ®
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        fields: å­—æ®µåæˆ–å­—æ®µåˆ—è¡¨
        
    Returns:
        å¸‚åœºå¿«ç…§æ•°æ®DataFrame
    """
    current_data = get_current_data(engine, security)
    if not current_data:
        return pd.DataFrame()

    all_fields = [
        'open', 'high', 'low', 'close', 'volume', 'amount', 'pre_close', 'change', 'pct_change',
        'amplitude', 'turnover_rate', 'bid1', 'bid2', 'bid3', 'bid4', 'bid5', 'ask1', 'ask2', 'ask3',
        'ask4', 'ask5', 'bid1_volume', 'bid2_volume', 'bid3_volume', 'bid4_volume', 'bid5_volume',
        'ask1_volume', 'ask2_volume', 'ask3_volume', 'ask4_volume', 'ask5_volume', 'high_limit',
        'low_limit', 'vwap'
    ]
    fields = ['open', 'high', 'low', 'close', 'volume', 'change', 'pct_change'] if fields is None else ([fields] if isinstance(fields, str) else fields)

    data_dict = {field: [current_data[sec].get(field) for sec in current_data] for field in fields}
    return pd.DataFrame(data_dict, index=list(current_data.keys()))

def get_technical_indicators(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    indicators: Union[str, List[str]], 
    period: int = 20, 
    **kwargs: Any
) -> pd.DataFrame:
    """
    è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨ä»£ç åˆ—è¡¨
        indicators: æŒ‡æ ‡åæˆ–æŒ‡æ ‡åˆ—è¡¨
        period: è®¡ç®—å‘¨æœŸ
        **kwargs: å…¶ä»–å‚æ•°
        
    Returns:
        æŠ€æœ¯æŒ‡æ ‡æ•°æ®DataFrame
    """
    securities = [security] if isinstance(security, str) else security
    indicators = [indicators] if isinstance(indicators, str) else indicators
    result_data = {}

    for sec in securities:
        if sec not in engine.data:
            log.warning(f"è‚¡ç¥¨ {sec} çš„æ•°æ®ä¸å­˜åœ¨")
            continue

        hist_df = engine.data[sec]
        current_dt = engine.context.current_dt if hasattr(engine, 'context') else None
        valid_hist = hist_df[hist_df.index <= current_dt] if current_dt else hist_df

        if len(valid_hist) < period:
            log.warning(f"è‚¡ç¥¨ {sec} çš„å†å²æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {period} æ¡æ•°æ®")
            continue

        result_data[sec] = {}
        close_prices = valid_hist['close'].values
        high_prices = valid_hist['high'].values
        low_prices = valid_hist['low'].values

        for indicator in indicators:
            try:
                if indicator.upper() == 'MA':
                    result_data[sec][f'MA{period}'] = pd.Series(close_prices).rolling(window=period).mean().tolist()
                elif indicator.upper() == 'EMA':
                    result_data[sec][f'EMA{period}'] = pd.Series(close_prices).ewm(span=period, adjust=False).mean().tolist()
                elif indicator.upper() == 'MACD':
                    fast_period = kwargs.get('fast_period', 12)
                    slow_period = kwargs.get('slow_period', 26)
                    signal_period = kwargs.get('signal_period', 9)
                    ema_fast = pd.Series(close_prices).ewm(span=fast_period, adjust=False).mean()
                    ema_slow = pd.Series(close_prices).ewm(span=slow_period, adjust=False).mean()
                    dif = ema_fast - ema_slow
                    dea = dif.ewm(span=signal_period, adjust=False).mean()
                    result_data[sec]['MACD_DIF'] = dif.tolist()
                    result_data[sec]['MACD_DEA'] = dea.tolist()
                    result_data[sec]['MACD_HIST'] = ((dif - dea) * 2).tolist()
                elif indicator.upper() == 'RSI':
                    delta = pd.Series(close_prices).diff()
                    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()
                    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()
                    rs = gain / loss
                    result_data[sec][f'RSI{period}'] = (100 - (100 / (1 + rs))).tolist()
                elif indicator.upper() == 'BOLL':
                    std_multiplier = kwargs.get('std_multiplier', 2)
                    ma = pd.Series(close_prices).rolling(window=period).mean()
                    std = pd.Series(close_prices).rolling(window=period).std()
                    result_data[sec]['BOLL_UPPER'] = (ma + std_multiplier * std).tolist()
                    result_data[sec]['BOLL_MIDDLE'] = ma.tolist()
                    result_data[sec]['BOLL_LOWER'] = (ma - std_multiplier * std).tolist()
                elif indicator.upper() == 'KDJ':
                    k_period = kwargs.get('k_period', 9)
                    low_min = pd.Series(low_prices).rolling(window=k_period).min()
                    high_max = pd.Series(high_prices).rolling(window=k_period).max()
                    rsv = (pd.Series(close_prices) - low_min) / (high_max - low_min) * 100
                    k_values = rsv.ewm(com=2, adjust=False).mean()
                    d_values = k_values.ewm(com=2, adjust=False).mean()
                    j_values = 3 * k_values - 2 * d_values
                    result_data[sec]['KDJ_K'] = k_values.tolist()
                    result_data[sec]['KDJ_D'] = d_values.tolist()
                    result_data[sec]['KDJ_J'] = j_values.tolist()
                elif indicator.upper() == 'CCI':
                    # CCI (Commodity Channel Index) é¡ºåŠ¿æŒ‡æ ‡
                    cci_period = kwargs.get('cci_period', period)
                    typical_price = (pd.Series(high_prices) + pd.Series(low_prices) + pd.Series(close_prices)) / 3
                    sma_tp = typical_price.rolling(window=cci_period).mean()
                    # è®¡ç®—å¹³å‡ç»å¯¹åå·® (MAD)
                    def calculate_mad(x):
                        return (x - x.mean()).abs().mean()
                    mad = typical_price.rolling(window=cci_period).apply(calculate_mad, raw=False)
                    cci = (typical_price - sma_tp) / (0.015 * mad)
                    result_data[sec][f'CCI{cci_period}'] = cci.tolist()
            except Exception as e:
                log.warning(f"è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ {indicator} æ—¶å‡ºé”™: {e}")

    if not result_data:
        return pd.DataFrame()

    sample_data = engine.data[securities[0]]
    current_dt = engine.context.current_dt if hasattr(engine, 'context') else None
    valid_hist = sample_data[sample_data.index <= current_dt] if current_dt else sample_data
    time_index = valid_hist.index

    result_df = pd.DataFrame()
    for sec in result_data:
        for indicator_name, values in result_data[sec].items():
            if len(values) == len(time_index):
                result_df[(indicator_name, sec)] = pd.Series(values, index=time_index)

    return result_df


# ==================== ç‹¬ç«‹æŠ€æœ¯æŒ‡æ ‡å‡½æ•°æ¥å£ ====================
# ç¬¦åˆptradeAPIæ ‡å‡†çš„ç‹¬ç«‹æŠ€æœ¯æŒ‡æ ‡å‡½æ•°

def get_MACD(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    fast_period: int = 12, 
    slow_period: int = 26, 
    signal_period: int = 9
) -> pd.DataFrame:
    """
    è®¡ç®—MACDæŒ‡æ ‡ (å¼‚åŒç§»åŠ¨å¹³å‡çº¿)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå•ä¸ªè‚¡ç¥¨æˆ–è‚¡ç¥¨åˆ—è¡¨
        fast_period: å¿«çº¿å‘¨æœŸï¼Œé»˜è®¤12
        slow_period: æ…¢çº¿å‘¨æœŸï¼Œé»˜è®¤26
        signal_period: ä¿¡å·çº¿å‘¨æœŸï¼Œé»˜è®¤9

    Returns:
        åŒ…å«MACD_DIF, MACD_DEA, MACD_HISTçš„æ•°æ®æ¡†
    """
    return get_technical_indicators(
        engine, security, 'MACD',
        fast_period=fast_period,
        slow_period=slow_period,
        signal_period=signal_period
    )


def get_KDJ(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    k_period: int = 9
) -> pd.DataFrame:
    """
    è®¡ç®—KDJæŒ‡æ ‡ (éšæœºæŒ‡æ ‡)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå•ä¸ªè‚¡ç¥¨æˆ–è‚¡ç¥¨åˆ—è¡¨
        k_period: Kå€¼è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤9

    Returns:
        åŒ…å«KDJ_K, KDJ_D, KDJ_Jçš„æ•°æ®æ¡†
    """
    return get_technical_indicators(
        engine, security, 'KDJ',
        k_period=k_period
    )


def get_RSI(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    period: int = 14
) -> pd.DataFrame:
    """
    è®¡ç®—RSIæŒ‡æ ‡ (ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå•ä¸ªè‚¡ç¥¨æˆ–è‚¡ç¥¨åˆ—è¡¨
        period: è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤14

    Returns:
        åŒ…å«RSIå€¼çš„æ•°æ®æ¡†
    """
    return get_technical_indicators(
        engine, security, 'RSI',
        period=period
    )


def get_CCI(
    engine: 'BacktestEngine', 
    security: Union[str, List[str]], 
    period: int = 20
) -> pd.DataFrame:
    """
    è®¡ç®—CCIæŒ‡æ ‡ (é¡ºåŠ¿æŒ‡æ ‡)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå•ä¸ªè‚¡ç¥¨æˆ–è‚¡ç¥¨åˆ—è¡¨
        period: è®¡ç®—å‘¨æœŸï¼Œé»˜è®¤20

    Returns:
        åŒ…å«CCIå€¼çš„æ•°æ®æ¡†
    """
    return get_technical_indicators(
        engine, security, 'CCI',
        cci_period=period
    )


# ==================== å¸‚åœºä¿¡æ¯API ====================

def get_market_list(engine: 'BacktestEngine') -> List[str]:
    """
    è·å–å¸‚åœºåˆ—è¡¨
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        
    Returns:
        å¸‚åœºä»£ç åˆ—è¡¨
    """
    # æ ¹æ®è‚¡ç¥¨ä»£ç åç¼€åˆ¤æ–­å¸‚åœº
    markets = set()
    
    if not engine.data:
        return []
    
    for security in engine.data.keys():
        if '.' in security:
            market = security.split('.')[-1]
            markets.add(market)
        else:
            # é»˜è®¤å¸‚åœº
            markets.add('SZ')  # æ·±åœ³
    
    market_list = list(markets)
    log.info(f"è·å–å¸‚åœºåˆ—è¡¨: {market_list}")
    return market_list


def get_cash(engine: 'BacktestEngine') -> float:
    """
    è·å–å½“å‰ç°é‡‘
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        
    Returns:
        å½“å‰ç°é‡‘é‡‘é¢
    """
    if hasattr(engine, 'context') and engine.context:
        return engine.context.portfolio.cash
    return 0.0


def get_total_value(engine: 'BacktestEngine') -> float:
    """
    è·å–æ€»èµ„äº§
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        
    Returns:
        æ€»èµ„äº§é‡‘é¢
    """
    if hasattr(engine, 'context') and engine.context:
        return engine.context.portfolio.total_value
    return 0.0


def get_datetime(engine: 'BacktestEngine') -> str:
    """
    è·å–å½“å‰æ—¶é—´
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        
    Returns:
        å½“å‰æ—¶é—´å­—ç¬¦ä¸²
    """
    if hasattr(engine, 'context') and engine.context and engine.context.current_dt:
        return engine.context.current_dt.strftime('%Y-%m-%d %H:%M:%S')
    return ""


def get_previous_trading_date(engine: 'BacktestEngine', date: str = None) -> str:
    """
    è·å–ä¸Šä¸€äº¤æ˜“æ—¥
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        date: åŸºå‡†æ—¥æœŸï¼ŒNoneè¡¨ç¤ºå½“å‰æ—¥æœŸ
        
    Returns:
        ä¸Šä¸€äº¤æ˜“æ—¥å­—ç¬¦ä¸²
    """
    from .utils import get_trading_day
    import pandas as pd
    
    previous_date = get_trading_day(engine, date, offset=-1)
    if previous_date:
        return previous_date.strftime('%Y-%m-%d')
    return ""


def get_next_trading_date(engine: 'BacktestEngine', date: str = None) -> str:
    """
    è·å–ä¸‹ä¸€äº¤æ˜“æ—¥
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        date: åŸºå‡†æ—¥æœŸï¼ŒNoneè¡¨ç¤ºå½“å‰æ—¥æœŸ
        
    Returns:
        ä¸‹ä¸€äº¤æ˜“æ—¥å­—ç¬¦ä¸²
    """
    from .utils import get_trading_day
    import pandas as pd
    
    next_date = get_trading_day(engine, date, offset=1)
    if next_date:
        return next_date.strftime('%Y-%m-%d')
    return ""


# =================================================================
# é«˜çº§å¸‚åœºæ•°æ®API - ä»utils.pyè¿ç§»è€Œæ¥ï¼Œä¿æŒPTradeå…¼å®¹æ€§
# =================================================================

def get_snapshot(engine: 'BacktestEngine', stock: str) -> Dict[str, Any]:
    """
    è·å–è‚¡ç¥¨å¿«ç…§æ•°æ® (PTradeå…¼å®¹)
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stock: è‚¡ç¥¨ä»£ç 
        
    Returns:
        dict: å¿«ç…§æ•°æ®
    """
    if stock in engine.data:
        latest_data = engine.data[stock].iloc[-1]
        snapshot = {
            'code': stock,
            'open': latest_data['open'],
            'high': latest_data['high'],
            'low': latest_data['low'],
            'close': latest_data['close'],
            'volume': latest_data['volume'],
            'turnover': latest_data['close'] * latest_data['volume'],
            'bid1': latest_data['close'] * 0.999,
            'ask1': latest_data['close'] * 1.001,
            'bid1_volume': 10000,
            'ask1_volume': 10000
        }
    else:
        snapshot = {'code': stock, 'error': 'No data available'}
    
    log.info(f"è·å–è‚¡ç¥¨å¿«ç…§: {stock}")
    return snapshot


def get_volume_ratio(engine: 'BacktestEngine', stock: str) -> float:
    """
    è·å–è‚¡ç¥¨é‡æ¯” (PTradeå…¼å®¹)
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stock: è‚¡ç¥¨ä»£ç 
        
    Returns:
        float: é‡æ¯”
    """
    if stock in engine.data and len(engine.data[stock]) >= 5:
        recent_volume = engine.data[stock]['volume'].iloc[-1]
        avg_volume = engine.data[stock]['volume'].iloc[-5:].mean()
        volume_ratio = recent_volume / avg_volume if avg_volume > 0 else 1.0
    else:
        volume_ratio = 1.0
    
    log.info(f"è·å–é‡æ¯”: {stock} -> {volume_ratio:.2f}")
    return volume_ratio


def get_turnover_rate(engine: 'BacktestEngine', stock: str) -> float:
    """
    è·å–è‚¡ç¥¨æ¢æ‰‹ç‡ (PTradeå…¼å®¹)
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stock: è‚¡ç¥¨ä»£ç 
        
    Returns:
        float: æ¢æ‰‹ç‡(%)
    """
    import random
    # æ¨¡æ‹Ÿæ¢æ‰‹ç‡è®¡ç®—ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ•°æ®æºè·å–ï¼‰
    turnover_rate = random.uniform(0.5, 5.0)  # 0.5%-5%
    log.info(f"è·å–æ¢æ‰‹ç‡: {stock} -> {turnover_rate:.2f}%")
    return turnover_rate


def get_pe_ratio(engine: 'BacktestEngine', stock: str) -> float:
    """
    è·å–è‚¡ç¥¨å¸‚ç›ˆç‡ (PTradeå…¼å®¹)
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stock: è‚¡ç¥¨ä»£ç 
        
    Returns:
        float: å¸‚ç›ˆç‡
    """
    import random
    # æ¨¡æ‹Ÿå¸‚ç›ˆç‡ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ•°æ®æºè·å–ï¼‰
    pe_ratio = random.uniform(10, 50)
    log.info(f"è·å–å¸‚ç›ˆç‡: {stock} -> {pe_ratio:.2f}")
    return pe_ratio


def get_pb_ratio(engine: 'BacktestEngine', stock: str) -> float:
    """
    è·å–è‚¡ç¥¨å¸‚å‡€ç‡ (PTradeå…¼å®¹)
    
    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stock: è‚¡ç¥¨ä»£ç 
        
    Returns:
        float: å¸‚å‡€ç‡
    """
    import random
    # æ¨¡æ‹Ÿå¸‚å‡€ç‡ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­åº”è¯¥ä»æ•°æ®æºè·å–ï¼‰
    pb_ratio = random.uniform(0.5, 8.0)
    log.info(f"è·å–å¸‚å‡€ç‡: {stock} -> {pb_ratio:.2f}")
    return pb_ratio


def get_individual_entrust(engine: 'BacktestEngine', stocks: Union[str, List[str]], 
                          start_time: str = None, end_time: str = None) -> Dict[str, pd.DataFrame]:
    """
    è·å–é€ç¬”å§”æ‰˜è¡Œæƒ… (PTradeå…¼å®¹)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stocks: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨åˆ—è¡¨
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´

    Returns:
        dict: é€ç¬”å§”æ‰˜æ•°æ®ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    from datetime import datetime, timedelta
    
    if isinstance(stocks, str):
        stocks = [stocks]

    result = {}

    for stock in stocks:
        # æ¨¡æ‹Ÿé€ç¬”å§”æ‰˜æ•°æ®
        current_time = datetime.now()
        time_range = pd.date_range(
            start=current_time - timedelta(minutes=30),
            end=current_time,
            freq='10s'  # æ¯10ç§’ä¸€æ¡è®°å½•
        )

        n_records = len(time_range)

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        base_price = 10.0  # åŸºç¡€ä»·æ ¼
        entrust_data = pd.DataFrame({
            'business_time': [int(t.timestamp() * 1000) for t in time_range],  # æ¯«ç§’æ—¶é—´æˆ³
            'hq_px': np.round(base_price + np.random.normal(0, 0.1, n_records), 2),  # å§”æ‰˜ä»·æ ¼
            'business_amount': np.random.randint(100, 10000, n_records),  # å§”æ‰˜é‡
            'order_no': [f"ORD{i:06d}" for i in range(n_records)],  # å§”æ‰˜ç¼–å·
            'business_direction': np.random.choice([0, 1], n_records),  # 0-å–ï¼Œ1-ä¹°
            'trans_kind': np.random.choice([1, 2, 3], n_records)  # 1-å¸‚ä»·ï¼Œ2-é™ä»·ï¼Œ3-æœ¬æ–¹æœ€ä¼˜
        })

        result[stock] = entrust_data

    log.info(f"è·å–é€ç¬”å§”æ‰˜æ•°æ®: {len(stocks)}åªè‚¡ç¥¨")
    return result


def get_individual_transaction(engine: 'BacktestEngine', stocks: Union[str, List[str]], 
                             start_time: str = None, end_time: str = None) -> Dict[str, pd.DataFrame]:
    """
    è·å–é€ç¬”æˆäº¤è¡Œæƒ… (PTradeå…¼å®¹)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        stocks: è‚¡ç¥¨ä»£ç æˆ–è‚¡ç¥¨åˆ—è¡¨
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´

    Returns:
        dict: é€ç¬”æˆäº¤æ•°æ®ï¼Œkeyä¸ºè‚¡ç¥¨ä»£ç ï¼Œvalueä¸ºDataFrame
    """
    from datetime import datetime, timedelta
    
    if isinstance(stocks, str):
        stocks = [stocks]

    result = {}

    for stock in stocks:
        # æ¨¡æ‹Ÿé€ç¬”æˆäº¤æ•°æ®
        current_time = datetime.now()
        time_range = pd.date_range(
            start=current_time - timedelta(minutes=30),
            end=current_time,
            freq='15s'  # æ¯15ç§’ä¸€æ¡è®°å½•
        )

        n_records = len(time_range)

        # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
        base_price = 10.0  # åŸºç¡€ä»·æ ¼
        transaction_data = pd.DataFrame({
            'business_time': [int(t.timestamp() * 1000) for t in time_range],  # æ¯«ç§’æ—¶é—´æˆ³
            'hq_px': np.round(base_price + np.random.normal(0, 0.05, n_records), 2),  # æˆäº¤ä»·æ ¼
            'business_amount': np.random.randint(100, 5000, n_records),  # æˆäº¤é‡
            'trade_index': [f"TRD{i:06d}" for i in range(n_records)],  # æˆäº¤ç¼–å·
            'business_direction': np.random.choice([0, 1], n_records),  # 0-å–ï¼Œ1-ä¹°
            'buy_no': [f"BUY{i:06d}" for i in range(n_records)],  # å«ä¹°æ–¹ç¼–å·
            'sell_no': [f"SELL{i:06d}" for i in range(n_records)],  # å«å–æ–¹ç¼–å·
            'trans_flag': np.random.choice([0, 1], n_records, p=[0.95, 0.05]),  # 0-æ™®é€šï¼Œ1-æ’¤å•
            'trans_identify_am': np.random.choice([0, 1], n_records, p=[0.9, 0.1]),  # 0-ç›˜ä¸­ï¼Œ1-ç›˜å
            'channel_num': np.random.randint(1, 10, n_records)  # æˆäº¤é€šé“ä¿¡æ¯
        })

        result[stock] = transaction_data

    log.info(f"è·å–é€ç¬”æˆäº¤æ•°æ®: {len(stocks)}åªè‚¡ç¥¨")
    return result


def get_gear_price(engine: 'BacktestEngine', security: str) -> Dict[str, Any]:
    """
    è·å–æŒ‡å®šä»£ç çš„æ¡£ä½è¡Œæƒ…ä»·æ ¼ (PTradeå…¼å®¹)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        security: è‚¡ç¥¨ä»£ç 

    Returns:
        dict: æ¡£ä½è¡Œæƒ…æ•°æ®
    """
    import random
    from datetime import datetime
    
    # æ¨¡æ‹Ÿæ¡£ä½è¡Œæƒ…æ•°æ®
    base_price = 10.0

    # ç”Ÿæˆä¹°å–äº”æ¡£æ•°æ®
    bid_prices = []
    ask_prices = []

    for i in range(5):
        bid_price = round(base_price - (i + 1) * 0.01, 2)
        ask_price = round(base_price + (i + 1) * 0.01, 2)
        bid_prices.append(bid_price)
        ask_prices.append(ask_price)

    gear_data = {
        'security': security,
        'timestamp': int(datetime.now().timestamp() * 1000),
        'bid_prices': bid_prices,  # ä¹°ä¸€åˆ°ä¹°äº”ä»·æ ¼
        'bid_volumes': [random.randint(100, 10000) for _ in range(5)],  # ä¹°ä¸€åˆ°ä¹°äº”é‡
        'ask_prices': ask_prices,  # å–ä¸€åˆ°å–äº”ä»·æ ¼
        'ask_volumes': [random.randint(100, 10000) for _ in range(5)],  # å–ä¸€åˆ°å–äº”é‡
        'last_price': base_price,  # æœ€æ–°ä»·
        'total_bid_volume': sum([random.randint(100, 10000) for _ in range(5)]),  # å§”ä¹°æ€»é‡
        'total_ask_volume': sum([random.randint(100, 10000) for _ in range(5)]),  # å§”å–æ€»é‡
    }

    log.info(f"è·å–æ¡£ä½è¡Œæƒ…: {security}")
    return gear_data


def get_sort_msg(engine: 'BacktestEngine', market_type: str = 'sector', 
                 sort_field: str = 'pct_change', ascending: bool = False, count: int = 20) -> List[Dict[str, Any]]:
    """
    è·å–æ¿å—ã€è¡Œä¸šçš„æ¶¨å¹…æ’å (PTradeå…¼å®¹)

    Args:
        engine: å›æµ‹å¼•æ“å®ä¾‹
        market_type: å¸‚åœºç±»å‹ ('sector'-æ¿å—, 'industry'-è¡Œä¸š)
        sort_field: æ’åºå­—æ®µ ('pct_change'-æ¶¨è·Œå¹…, 'volume'-æˆäº¤é‡, 'amount'-æˆäº¤é¢)
        ascending: æ˜¯å¦å‡åºæ’åˆ—
        count: è¿”å›æ•°é‡

    Returns:
        list: æ’åæ•°æ®åˆ—è¡¨
    """
    import random
    
    # æ¨¡æ‹Ÿæ¿å—/è¡Œä¸šæ•°æ®
    if market_type == 'sector':
        sectors = [
            'é“¶è¡Œæ¿å—', 'è¯åˆ¸æ¿å—', 'ä¿é™©æ¿å—', 'åœ°äº§æ¿å—', 'é’¢é“æ¿å—',
            'ç…¤ç‚­æ¿å—', 'æœ‰è‰²æ¿å—', 'çŸ³æ²¹æ¿å—', 'ç”µåŠ›æ¿å—', 'æ±½è½¦æ¿å—',
            'å®¶ç”µæ¿å—', 'é£Ÿå“æ¿å—', 'åŒ»è¯æ¿å—', 'ç§‘æŠ€æ¿å—', 'å†›å·¥æ¿å—'
        ]
        data_source = sectors
    else:  # industry
        industries = [
            'é“¶è¡Œä¸š', 'è¯åˆ¸ä¸š', 'ä¿é™©ä¸š', 'æˆ¿åœ°äº§ä¸š', 'é’¢é“ä¸š',
            'ç…¤ç‚­ä¸š', 'æœ‰è‰²é‡‘å±', 'çŸ³æ²¹åŒ–å·¥', 'ç”µåŠ›è¡Œä¸š', 'æ±½è½¦åˆ¶é€ ',
            'å®¶ç”¨ç”µå™¨', 'é£Ÿå“é¥®æ–™', 'åŒ»è¯ç”Ÿç‰©', 'è®¡ç®—æœº', 'å›½é˜²å†›å·¥'
        ]
        data_source = industries

    # ç”Ÿæˆæ¨¡æ‹Ÿæ’åæ•°æ®
    sort_data = []
    for i, name in enumerate(data_source[:count]):
        item = {
            'name': name,
            'code': f"{market_type.upper()}{i:03d}",
            'pct_change': round(random.uniform(-5.0, 8.0), 2),  # æ¶¨è·Œå¹… -5% åˆ° 8%
            'volume': random.randint(1000000, 100000000),  # æˆäº¤é‡
            'amount': random.randint(100000000, 10000000000),  # æˆäº¤é¢
            'up_count': random.randint(0, 50),  # ä¸Šæ¶¨å®¶æ•°
            'down_count': random.randint(0, 50),  # ä¸‹è·Œå®¶æ•°
            'flat_count': random.randint(0, 10),  # å¹³ç›˜å®¶æ•°
        }
        sort_data.append(item)

    # æŒ‰æŒ‡å®šå­—æ®µæ’åº
    sort_data.sort(key=lambda x: x[sort_field], reverse=not ascending)

    log.info(f"è·å–{market_type}æ’åæ•°æ®: {len(sort_data)}ä¸ª")
    return sort_data
