# ğŸ“‹ æ•°æ®æ ¼å¼è¿ç§»æŒ‡å—

## æ¦‚è¿°

å¦‚æœæ‚¨ä¹‹å‰ä½¿ç”¨çš„æ˜¯å®½æ ¼å¼ï¼ˆWide Formatï¼‰æ•°æ®ï¼Œæœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿè¿ç§»åˆ°SimTradeLab v2.0+è¦æ±‚çš„é•¿æ ¼å¼ï¼ˆLong Formatï¼‰æ•°æ®ã€‚

## ğŸ”„ æ ¼å¼å¯¹æ¯”

### æ—§æ ¼å¼ï¼ˆå®½æ ¼å¼ï¼‰âŒ
```csv
datetime,STOCK_A_open,STOCK_A_high,STOCK_A_low,STOCK_A_close,STOCK_A_volume,STOCK_B_open,STOCK_B_high,STOCK_B_low,STOCK_B_close,STOCK_B_volume
2023-01-01,100.00,102.50,99.50,101.20,1500000,50.00,51.25,49.75,50.60,800000
2023-01-02,101.20,103.80,100.90,102.50,1600000,50.60,51.90,50.45,51.25,850000
```

### æ–°æ ¼å¼ï¼ˆé•¿æ ¼å¼ï¼‰âœ…
```csv
date,open,high,low,close,volume,security
2023-01-01,100.00,102.50,99.50,101.20,1500000,STOCK_A
2023-01-02,101.20,103.80,100.90,102.50,1600000,STOCK_A
2023-01-01,50.00,51.25,49.75,50.60,800000,STOCK_B
2023-01-02,50.60,51.90,50.45,51.25,850000,STOCK_B
```

## ğŸ› ï¸ è‡ªåŠ¨è½¬æ¢å·¥å…·

### Pythonè½¬æ¢è„šæœ¬

åˆ›å»º `convert_data_format.py` æ–‡ä»¶ï¼š

```python
import pandas as pd
import re
from pathlib import Path

def convert_wide_to_long(input_file, output_file=None):
    """
    å°†å®½æ ¼å¼æ•°æ®è½¬æ¢ä¸ºé•¿æ ¼å¼
    
    Args:
        input_file: è¾“å…¥çš„å®½æ ¼å¼CSVæ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºçš„é•¿æ ¼å¼CSVæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    # è¯»å–å®½æ ¼å¼æ•°æ®
    df = pd.read_csv(input_file)
    
    # è‡ªåŠ¨æ£€æµ‹æ—¥æœŸåˆ—
    date_col = None
    for col in ['date', 'datetime', 'Date', 'DateTime']:
        if col in df.columns:
            date_col = col
            break
    
    if date_col is None:
        raise ValueError("æœªæ‰¾åˆ°æ—¥æœŸåˆ—ï¼Œè¯·ç¡®ä¿æ•°æ®åŒ…å« 'date' æˆ– 'datetime' åˆ—")
    
    # æå–è‚¡ç¥¨ä»£ç 
    stock_pattern = r'^([A-Z_]+[A-Z0-9_]*)_(open|high|low|close|volume)$'
    stocks = set()
    
    for col in df.columns:
        if col != date_col:
            match = re.match(stock_pattern, col, re.IGNORECASE)
            if match:
                stocks.add(match.group(1))
    
    if not stocks:
        raise ValueError("æœªæ‰¾åˆ°ç¬¦åˆæ ¼å¼çš„è‚¡ç¥¨æ•°æ®åˆ—")
    
    print(f"æ£€æµ‹åˆ° {len(stocks)} åªè‚¡ç¥¨: {', '.join(sorted(stocks))}")
    
    # è½¬æ¢ä¸ºé•¿æ ¼å¼
    long_data = []
    
    for stock in stocks:
        # æ„å»ºåˆ—å
        open_col = f"{stock}_open"
        high_col = f"{stock}_high"
        low_col = f"{stock}_low"
        close_col = f"{stock}_close"
        volume_col = f"{stock}_volume"
        
        # æ£€æŸ¥æ‰€æœ‰å¿…éœ€åˆ—æ˜¯å¦å­˜åœ¨
        required_cols = [open_col, high_col, low_col, close_col, volume_col]
        missing_cols = [col for col in required_cols if col not in df.columns]
        
        if missing_cols:
            print(f"è­¦å‘Š: è‚¡ç¥¨ {stock} ç¼ºå°‘åˆ—: {missing_cols}ï¼Œè·³è¿‡")
            continue
        
        # æå–è¯¥è‚¡ç¥¨çš„æ•°æ®
        stock_data = pd.DataFrame({
            'date': df[date_col],
            'open': df[open_col],
            'high': df[high_col],
            'low': df[low_col],
            'close': df[close_col],
            'volume': df[volume_col],
            'security': stock
        })
        
        # è¿‡æ»¤æ‰åŒ…å«NaNçš„è¡Œ
        stock_data = stock_data.dropna()
        
        if not stock_data.empty:
            long_data.append(stock_data)
            print(f"âœ… æˆåŠŸè½¬æ¢è‚¡ç¥¨ {stock}: {len(stock_data)} æ¡è®°å½•")
        else:
            print(f"âš ï¸  è‚¡ç¥¨ {stock} æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
    
    if not long_data:
        raise ValueError("æ²¡æœ‰æˆåŠŸè½¬æ¢ä»»ä½•è‚¡ç¥¨æ•°æ®")
    
    # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨æ•°æ®
    result_df = pd.concat(long_data, ignore_index=True)
    
    # æŒ‰æ—¥æœŸå’Œè‚¡ç¥¨ä»£ç æ’åº
    result_df = result_df.sort_values(['date', 'security']).reset_index(drop=True)
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
    if output_file is None:
        input_path = Path(input_file)
        output_file = input_path.parent / f"{input_path.stem}_long_format{input_path.suffix}"
    
    # ä¿å­˜ç»“æœ
    result_df.to_csv(output_file, index=False)
    
    print(f"\nğŸ‰ è½¬æ¢å®Œæˆ!")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_file}")
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(result_df)}")
    print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {result_df['security'].nunique()}")
    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {result_df['date'].min()} åˆ° {result_df['date'].max()}")
    
    return result_df

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # è½¬æ¢å•ä¸ªæ–‡ä»¶
    convert_wide_to_long("data/old_format_data.csv", "data/new_format_data.csv")
    
    # æ‰¹é‡è½¬æ¢
    import glob
    
    for file in glob.glob("data/*_wide.csv"):
        try:
            convert_wide_to_long(file)
            print(f"âœ… æˆåŠŸè½¬æ¢: {file}")
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {file} - {e}")
```

### ä½¿ç”¨æ–¹æ³•

1. **å•æ–‡ä»¶è½¬æ¢**ï¼š
```bash
python convert_data_format.py
```

2. **è‡ªå®šä¹‰è½¬æ¢**ï¼š
```python
from convert_data_format import convert_wide_to_long

# è½¬æ¢æŒ‡å®šæ–‡ä»¶
convert_wide_to_long("my_old_data.csv", "my_new_data.csv")
```

## âœ… éªŒè¯è½¬æ¢ç»“æœ

è½¬æ¢å®Œæˆåï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç éªŒè¯æ•°æ®æ ¼å¼ï¼š

```python
import pandas as pd

def validate_long_format(file_path):
    """éªŒè¯é•¿æ ¼å¼æ•°æ®æ˜¯å¦æ­£ç¡®"""
    df = pd.read_csv(file_path)
    
    # æ£€æŸ¥å¿…éœ€åˆ—
    required_cols = ['date', 'open', 'high', 'low', 'close', 'volume', 'security']
    missing_cols = [col for col in required_cols if col not in df.columns]
    
    if missing_cols:
        print(f"âŒ ç¼ºå°‘å¿…éœ€åˆ—: {missing_cols}")
        return False
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    numeric_cols = ['open', 'high', 'low', 'close', 'volume']
    for col in numeric_cols:
        if not pd.api.types.is_numeric_dtype(df[col]):
            print(f"âŒ åˆ— {col} ä¸æ˜¯æ•°å€¼ç±»å‹")
            return False
    
    # æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§
    invalid_rows = df[
        (df['high'] < df['open']) | 
        (df['high'] < df['close']) | 
        (df['low'] > df['open']) | 
        (df['low'] > df['close'])
    ]
    
    if not invalid_rows.empty:
        print(f"âŒ å‘ç° {len(invalid_rows)} è¡Œæ•°æ®é€»è¾‘ä¸ä¸€è‡´")
        return False
    
    print("âœ… æ•°æ®æ ¼å¼éªŒè¯é€šè¿‡!")
    print(f"ğŸ“Š æ€»è®°å½•æ•°: {len(df)}")
    print(f"ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {df['security'].nunique()}")
    print(f"ğŸ“… æ—¥æœŸèŒƒå›´: {df['date'].min()} åˆ° {df['date'].max()}")
    
    return True

# éªŒè¯è½¬æ¢åçš„æ•°æ®
validate_long_format("data/new_format_data.csv")
```

## ğŸš¨ å¸¸è§é—®é¢˜

### Q1: è½¬æ¢åæ•°æ®é‡å˜å¤§äº†ï¼Ÿ
**A**: è¿™æ˜¯æ­£å¸¸çš„ã€‚é•¿æ ¼å¼ä¼šä¸ºæ¯åªè‚¡ç¥¨çš„æ¯ä¸ªæ—¥æœŸåˆ›å»ºå•ç‹¬çš„è¡Œï¼Œæ‰€ä»¥æ€»è¡Œæ•°ä¼šå¢åŠ ã€‚

### Q2: æŸäº›è‚¡ç¥¨æ•°æ®ä¸¢å¤±äº†ï¼Ÿ
**A**: æ£€æŸ¥åŸå§‹æ•°æ®ä¸­æ˜¯å¦æœ‰ç¼ºå¤±å€¼æˆ–åˆ—åä¸è§„èŒƒã€‚è½¬æ¢å·¥å…·ä¼šè‡ªåŠ¨è·³è¿‡ä¸å®Œæ•´çš„æ•°æ®ã€‚

### Q3: æ—¥æœŸæ ¼å¼ä¸å¯¹ï¼Ÿ
**A**: ç¡®ä¿åŸå§‹æ•°æ®çš„æ—¥æœŸåˆ—æ ¼å¼ä¸º YYYY-MM-DD æˆ– YYYY-MM-DD HH:MM:SSã€‚

### Q4: å¦‚ä½•å¤„ç†åˆ†é’Ÿçº§æ•°æ®ï¼Ÿ
**A**: åˆ†é’Ÿçº§æ•°æ®è½¬æ¢æ–¹æ³•ç›¸åŒï¼Œåªéœ€ç¡®ä¿æ—¥æœŸåˆ—åŒ…å«æ—¶é—´ä¿¡æ¯ã€‚

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æ•°æ®æ ¼å¼è§„èŒƒ](DATA_FORMAT.md)
- [APIå‚è€ƒæ–‡æ¡£](API_REFERENCE.md)
- [ç­–ç•¥å¼€å‘æŒ‡å—](STRATEGY_GUIDE.md)
