Metadata-Version: 2.4
Name: llamate
Version: 0.1.7
Summary: A memory-augmented framework for LLMs
Author: Andy Thompson
Author-email: Andy Thompson <andyt338@gmail.com>
License: MIT
Project-URL: Homepage, https://github.com/andyt338/llamate
Project-URL: Bug Tracker, https://github.com/andyt338/llamate/issues
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: openai>=1.0.0
Requires-Dist: faiss-cpu
Requires-Dist: numpy
Requires-Dist: python-dotenv
Requires-Dist: psycopg2-binary
Provides-Extra: dev
Requires-Dist: pytest; extra == "dev"
Dynamic: author
Dynamic: license-file
Dynamic: requires-python

# ðŸ¦™ Llamate

Llamate is a memory-augmented agent framework for Large Language Models (LLMs) that provides persistent, retrievable memory for AI conversations.

## What is Llamate?

Llamate solves a fundamental limitation of current LLMs: their inability to remember past conversations beyond a single context window. It creates a vector database of memories that can be semantically searched and retrieved during conversations, allowing LLMs to maintain continuity and context over extended interactions.

## How It Works

1. **Memory Storage**: Llamate stores important pieces of conversation as vector embeddings in a database (either FAISS or PostgreSQL).
2. **Semantic Retrieval**: When new queries come in, Llamate searches for semantically relevant past memories.
3. **Memory Filtering**: The system automatically filters out the current query from search results to prevent echo effects.
4. **Context Enhancement**: Retrieved memories are injected into the conversation context, allowing the LLM to access and utilize past information.
5. **User Identification**: Each user gets a unique memory space, ensuring personalized conversation history.

## Key Features

- **Multiple Backend Support**: Works with FAISS (file-based) or PostgreSQL (with pgvector)
- **Persistence**: Memories remain available between sessions and application restarts
- **Simple API**: Easy-to-use Python interface that works with any LLM
- **CLI Interface**: Command-line tool for quick testing and interaction
- **Production Ready**: Designed for both development and production environments


## Quick Start

Follow these steps to set up, use, and view data in Llamate with PostgreSQL:

### 1. Install Llamate

```bash
pip install llamate
```

### 2. OpenAI API Requirements

Llamate requires access to the following OpenAI models in your account:

- `text-embedding-3-large` - Used for vector embeddings
- `gpt-4` - Recommended for high-quality responses

Make sure these models are enabled in your OpenAI account and set your API key:

### 3. Start PostgreSQL Container

```bash
docker run --name llamate-postgres -e POSTGRES_USER=llamate -e POSTGRES_PASSWORD=llamate -e POSTGRES_DB=llamate -p 5432:5432 -d ankane/pgvector
```

### 4. Initialize Llamate

```bash
llamate --init
# Select 'postgres' as your vector store backend
# Enter connection string: postgresql://llamate:llamate@localhost:5432/llamate
```

### 5. Test Llamate locally

```python
from llamate import MemoryAgent, get_vectorstore_from_env

# Set user ID
user_id = "test_user"

# Initialize components
vectorstore = get_vectorstore_from_env(user_id=user_id)
agent = MemoryAgent(user_id=user_id, vectorstore=vectorstore)

# Add memories
agent.chat("The capital of France is Paris.")
agent.chat("The Eiffel Tower is 324 meters tall.")
agent.chat("Python is a programming language created by Guido van Rossum.")

# Test retrieval
response = agent.chat("Tell me about Paris.")
print("Response:", response)
```

### 6. View Data in PostgreSQL

Connect to the database:

```bash
docker exec -it llamate-postgres psql -U llamate -d llamate
```

List tables to find your memory table (it will use your user_id):

```sql
\dt
```

View table structure:

```sql
\d memory_test_user
```

Display memory records (omitting the large vector field):

```sql
SELECT id, text FROM memory_test_user;
```

Count records:

```sql
SELECT COUNT(*) FROM memory_test_user;
```

Query specific memories (using text search):

```sql
SELECT id, text FROM memory_test_user WHERE text LIKE '%Paris%';
```

Delete test memories (if needed):

```sql
DELETE FROM memory_test_user WHERE text LIKE '%test%';
```

Exit the PostgreSQL shell:

```sql
\q
```

## Features

- Persistent memory for AI using vector embeddings
- Multiple vector store backends (FAISS and PostgreSQL)
- Easy integration into existing applications
- Simple CLI for testing and demonstration
