Metadata-Version: 2.4
Name: promptliy
Version: 1.0.1
Summary: Promptliy SDK for accessing Promptliy API
Author-email: Promptliy Inc <support@promptliy.ai>
Project-URL: Homepage, https://promptliy.ai
Keywords: promptliy,prompts,api,client,sdk,ai,python
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: requests>=2.25.0
Provides-Extra: cache
Requires-Dist: cachetools>=5.3.0; extra == "cache"
Dynamic: license-file

# promptliy-client

A lightweight Python SDK to fetch and format AI prompts from [Promptliy.ai](https://promptliy.ai) using your project API key.

---

## Installation

```bash
pip install promptliy
```

> Optional (recommended for caching in long-running environments like servers):
```bash
pip install cachetools
```

---

## What is Promptliy?

[Promptliy](https://promptliy.ai) helps teams manage, version, and collaborate on production-ready AI prompts with live context, variables, version history, and client libraries for devs.

---

## Usage

### 1. Initialize the client

```python
from promptliy import PromptliyClient

promptliy_client = PromptliyClient(project_key="pl_sk_abc123yourkey")
```

### 2. Fetch and format a prompt

```python
prompt = promptliy_client.get_prompt("welcome-message")
formatted = prompt.format("welcome-message",{
    "name": "John",
    "company": "Promptliy"
})

print(formatted)
# Output: "Hello John, welcome to Promptliy!"
```

### 3. Shortcut usage

```python
output = promptliy_client.format("onboarding-email", {
    "name": "Ava",
    "product": "Promptliy"
})
```

---

## Example: Use with LLMs

### OpenAI (ChatGPT, GPT-4)

```python
from openai import OpenAI
client = OpenAI(api_key="sk-...")

prompt_text = promptliy_client.format("chat-prompt", { "topic": "AI" })

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt_text}]
)

print(response.choices[0].message.content)
```

### Claude (Anthropic)

```python
from anthropic import Anthropic

anthropic = Anthropic(api_key="your-anthropic-key")

prompt_text = promptliy_client.format("claude-prompt", { "question": "What is PromptOps?" })

response = anthropic.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=500,
    messages=[{"role": "user", "content": prompt_text}]
)

print(response.content)
```

### Google Gemini

```python
import google.generativeai as genai

genai.configure(api_key="your-gemini-api-key")

prompt_text = promptliy_client.format("gemini-prompt", { "question": "What is PromptOps?" })

response = genai.GenerativeModel("gemini-1.5-pro").generate_content(prompt_text)
print(response.text)
```

---

## Features

- Smart in-memory caching (via built-in dict or `cachetools`)
- Background refresh loop (auto-syncs every 30 seconds)
- Variable validation with `{{ name }}` support
- Works with all LLM APIs (OpenAI, Claude, Gemini, etc.)

---

## Example Prompt Template

```text
Subject: Welcome, {{ name }}!

Hey {{ name }},

Thanks for joining {{ product }}. We're thrilled to have you on board!
```

---

## Error Handling

```python
# ‚ùå Missing required variable
promptliy_client.format({ "name": "Leo" })
# ‚ûú ValueError: Missing required variables: product
```

---

## License

This SDK is **commercial software** by Promptliy Inc.

By using this package, you agree to the terms in [`LICENSE.txt`](./LICENSE.txt).

- ‚úÖ Free tier use is allowed
- üö´ Production use requires a paid subscription

---

## üì¨ Contact

- üåê [https://promptliy.ai](https://promptliy.ai)
- üìß support@promptliy.ai
