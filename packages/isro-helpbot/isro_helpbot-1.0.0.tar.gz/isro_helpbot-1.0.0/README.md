Here's a professional, clean, and complete `README.md` for your **ISRO HelpBot** project, optimized for both GitHub and PyPI packaging:

---

```markdown
# ğŸš€ ISRO HelpBot

An AI-powered conversational assistant designed for information retrieval from ISRO's knowledge resources using a Knowledge Graph, Natural Language Processing (NLP), and semantic search. Built for the [ISRO Bharatiya Antariksh Hackathon 2025](https://www.isrohack.in/), this project aims to revolutionize access to space-related information.

---

## ğŸ“Œ Features

- ğŸ” **Query Understanding**: Extracts intent and named entities from natural language queries.
- ğŸ§  **Knowledge Graph Builder**: Builds a semantic knowledge graph from `.txt`, `.pdf`, `.docx`, and `.xlsx` documents.
- ğŸŒ **Geospatial Awareness**: Recognizes and links locations (e.g., "Bay of Bengal", "17Â°N") from queries and documents.
- ğŸ’¬ **Frontend Chat UI**: Built using Streamlit with file upload and interactive conversation.
- âš™ï¸ **Backend API**: FastAPI-powered backend to serve query results via RESTful endpoints.
- ğŸ“ˆ **Evaluation Metrics**: Real-time performance metrics to assess accuracy and responsiveness.

---

## ğŸ—‚ï¸ Project Structure

```



```
ISRO HELPBOT/
â”œâ”€â”€ __pycache__/                       # Compiled Python bytecode
â”œâ”€â”€ .vscode/                           # VS Code settings for development
â”‚   â””â”€â”€ settings.json                  # Editor preferences and configurations
â”‚
â”œâ”€â”€ api/                               # FastAPI backend for handling API requests
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ data/                          # API-level data files (temporary or static)
â”‚   â”œâ”€â”€ static/                        # Static assets for FastAPI (CSS, JS, etc.)
â”‚   â”œâ”€â”€ __init__.py                    # Marks directory as a Python package
â”‚   â”œâ”€â”€ main_api.py                    # Uvicorn entrypoint with FastAPI app instance
â”‚   â”œâ”€â”€ query_handler.py               # Logic to handle and respond to queries via API
â”‚   â””â”€â”€ routes.py                      # API endpoint definitions and routing
â”‚
â”œâ”€â”€ app/                               # Supplementary app scripts
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â””â”€â”€ main.py                        # Optional script for centralized app execution
â”‚
â”œâ”€â”€ core/                              # Chat logic and shared application functionality
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â””â”€â”€ chat_engine.py                 # Core engine handling conversations and message flow
â”‚
â”œâ”€â”€ data/                              # Datasets and documents used in KG construction
â”‚   â”œâ”€â”€ clean_text/                    # Cleaned versions of raw text documents
â”‚   â”œâ”€â”€ graph/                         # Serialized Knowledge Graphs
â”‚   â”‚   â””â”€â”€ knowledge_graph.pkl        # Pickled NetworkX graph
â”‚   â”œâ”€â”€ html/                          # Raw HTML files from scraped pages
â”‚   â”œâ”€â”€ mosdac_docs/                   # Original documents (pdf/docx) from MOSDAC
â”‚   â”œâ”€â”€ mosdac_pages/                  # Full saved MOSDAC HTML pages
â”‚   â””â”€â”€ raw_docs/                      # Raw document input before cleaning
â”‚
â”œâ”€â”€ raw_text/                          # Preprocessed plain text documents
â”‚   â”œâ”€â”€ raw_docs                       # Raw text files for reference
â”‚   â””â”€â”€ test.text                      # Sample text used for testing
â”‚
â”œâ”€â”€ evaluation/                        # Evaluation scripts and outputs
â”‚   â”œâ”€â”€ eval_engine.py                 # Script for evaluating intent/entity/response performance
â”‚   â””â”€â”€ results/                       # Output metrics and evaluation results
â”‚       â”œâ”€â”€ intent_results.json        # JSON containing evaluation result details
â”‚       â”œâ”€â”€ false_positives.csv        # Queries where intent classification failed
â”‚       â””â”€â”€ eval_summary.png           # Bar chart visualization of evaluation metrics
â”‚
â”œâ”€â”€ ingestion/                         # Document parsing and scraping modules
â”‚   â”œâ”€â”€ docx_extractor.py              # Parse and extract text from .docx
â”‚   â”œâ”€â”€ dynamic_scraper.py             # Scrape JavaScript-rendered MOSDAC pages
â”‚   â”œâ”€â”€ html_scraper.py                # Parse static HTML files
â”‚   â””â”€â”€ pdf_extractor.py               # Extract content from PDFs
â”‚
â”œâ”€â”€ intent_classifier/                # Intent classification model and routing
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py                    # Package initializer
â”‚   â”œâ”€â”€ intent_predictor.py            # ML model that predicts user intent
â”‚   â””â”€â”€ intent_router.py               # Maps intent labels to downstream task handlers
â”‚
â”œâ”€â”€ isro_helpbot/                      # Core pip-installable CLI module
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py                    # Package initializer
â”‚   â””â”€â”€ cli.py                         # CLI script to launch the bot via terminal
â”‚
â”œâ”€â”€ kg_builder/                        # Knowledge Graph construction modules
â”‚   â”œâ”€â”€ entity_extractor.py            # Extracts named entities from documents/queries
â”‚   â”œâ”€â”€ relationship_mapper.py         # Detects relationships among entities
â”‚   â”œâ”€â”€ response_generator.py          # Forms responses from entities and graph traversal
â”‚   â””â”€â”€ text_preprocessor.py           # Cleans, splits and processes raw text
â”‚
â”œâ”€â”€ lib/                               # External shared libraries (if any)
â”‚
â”œâ”€â”€ model/                             # Models and vector storage
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ embedding_generator.py         # Generates embeddings from textual input
â”‚   â”œâ”€â”€ faiss_store_docs.pkl           # Serialized FAISS-compatible document store
â”‚   â”œâ”€â”€ faiss_store.index              # FAISS binary index for fast semantic retrieval
â”‚   â”œâ”€â”€ kg_reasoner.py                 # Reasoning logic using KG + LLM
â”‚   â”œâ”€â”€ language_model.py              # Wrapper for local or API-based language models
â”‚   â”œâ”€â”€ qa_pipeline.py                 # Complete pipeline from query to answer
â”‚   â””â”€â”€ vector_store.py                # Vector DB abstraction for FAISS, Chroma, etc.
â”‚
â”œâ”€â”€ tests/                             # Unit and integration test scripts
â”‚   â”œâ”€â”€ test_intent_classifier.py      # Tests for intent classification logic
â”‚   â”œâ”€â”€ test_kg.py                     # Tests for KG extraction and structure
â”‚   â””â”€â”€ test_scrapper.py               # Tests for scraping functions
â”‚
â”œâ”€â”€ ui/                                # Streamlit-based frontend
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ components/                    # Streamlit component scripts (widgets, etc.)
â”‚   â”œâ”€â”€ static/                        # Static images, graphs, etc.
â”‚   â”œâ”€â”€ templates/                     # HTML templates (optional for hybrid UI)
â”‚   â”œâ”€â”€ index.html                     # Frontend base page
â”‚   â”œâ”€â”€ __init__.py                    # Marks UI as a package
â”‚   â””â”€â”€ streamlit_app.py               # Streamlit chatbot UI interface
â”‚
â”œâ”€â”€ venv/                              # Python virtual environment (excluded from Git)
â”œâ”€â”€ .env                               # API keys and environment variables
â”œâ”€â”€ .gitignore                         # Exclude rules for Git
â”œâ”€â”€ build_index.py                     # Builds FAISS index for semantic search
â”œâ”€â”€ config.py                          # Centralized configuration file (e.g., paths, thresholds)
â”œâ”€â”€ entrypoints.py                     # Unified entrypoints for CLI/API/Streamlit
â”œâ”€â”€ LICENSE                            # License file (MIT in this case)
â”œâ”€â”€ main.py                            # Optional main runner script
â”œâ”€â”€ MANIFEST.in                        # Include non-Python files during packaging
â”œâ”€â”€ mosdac_crawler.py                  # Crawler script to fetch data from MOSDAC
â”œâ”€â”€ pyproject.toml                     # Modern Python packaging metadata
â”œâ”€â”€ requirements.txt                   # Required dependencies for pip install
â””â”€â”€ setup.py                           # Package installer configuration
```

Let me know if you want this as a downloadable `.md` or `.txt` file or integrated into your `README.md`.

````

---

## âš™ï¸ Installation

```bash
pip install isro-helpbot
````

Or clone and run locally:

```bash
git clone https://github.com/Gaurav9693089415/ISRO-HelpBot.git
cd ISRO-HelpBot
pip install -e .
```

---

## ğŸš€ Usage

### ğŸ“ Launch Chatbot UI

```bash
isro-helpbot
```

This opens the Streamlit interface at `http://localhost:8501/`.

### ğŸ“ Run Backend API

```bash
uvicorn backend.main:app --reload --port 8080
```

---

## ğŸ“Š Evaluation Metrics

Evaluation metrics like accuracy, precision, recall, and response latency are automatically logged and can be viewed in the Streamlit sidebar.

---

## ğŸ“‚ Supported Document Types

* `.txt` â€“ Plain text files
* `.pdf` â€“ Scanned and digital PDFs
* `.docx` â€“ Microsoft Word
* `.xlsx` â€“ Excel Sheets

Uploaded files auto-update the Knowledge Graph.

---

## ğŸ’» Technologies Used

| Category    | Tools/Tech Stack                  |
| ----------- | --------------------------------- |
| NLP         | spaCy, NLTK, SentenceTransformers |
| KG + Search | NetworkX, FAISS, PyVis            |
| UI          | Streamlit                         |
| Backend     | FastAPI, Uvicorn                  |
| Others      | LangChain, OpenAI API, Selenium   |

---

## ğŸ¯ Objectives (As per ISRO Hackathon)

* Convert web portal content into machine-readable knowledge.
* Enable geospatial semantic search.
* Build a dynamic, AI-based helpbot interface.
* Provide API for external access to the system.

---

## ğŸ Final Outcome

An end-to-end, modular AI HelpBot that:

* Parses ISRO content into a Knowledge Graph.
* Understands user questions contextually.
* Answers using accurate and semantically relevant data.
* Offers CLI + UI + REST API + pip packaging.

---

## ğŸ›¡ï¸ License

MIT License. See `LICENSE` file.

---

## ğŸ™Œ Acknowledgement

Special thanks to **ISRO**, **IN-SPACe**, and **AICTE** for organizing the [Bharatiya Antariksh Hackathon 2025](https://www.isrohack.in/).

---

## âœ¨ Future Enhancements

* Voice interaction
* Image-based QnA using satellite maps
* Integration with live ISRO data streams

```

---

Let me know if you'd like me to:
- Add badges (PyPI, License, Build)
- Generate this as a downloadable file
- Translate it into Hindi (for local repo presentation)

Ready to proceed with packaging now?
```
