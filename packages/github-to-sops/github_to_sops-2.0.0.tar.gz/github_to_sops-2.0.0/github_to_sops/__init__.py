#!/usr/bin/env python3
"""
Standalone (no-dependencies beyond Python) script fetches SSH keys of GitHub repository contributors and generates SOPS-compatible SSH key files.
"""

import argparse
import json
import logging
import os
import shlex
import sys
import subprocess
from typing import Any, Dict, Optional, List, Set, TextIO
from urllib import request, error
import re

GITHUB_TO_SOPS_TAG = "https://github.com/tarasglek/github-to-sops"
GITHUB_API_BASE_URL = "api.github.com/repos"
GENERATED_MSG = (
    f"Generated by `{' '.join(sys.argv)}` {GITHUB_TO_SOPS_TAG}"
)

SOPS_TEMPLATE = f"""
creation_rules:
  - key_groups:
      - age:
        - Mark stuff to replace by having a line with {GITHUB_TO_SOPS_TAG} which can be within a comment or not
        - Following lines with same indent get dropped
# EOF
"""

def process_template(template, tag, output_fd):
    """
    1. Takes a template string
    2. Finds line containing the specified tag
    3. Detects whitespace on the tag line and stores that as line_prefix
    4. yields it
    5. Finds first line after the tag with a different prefix
    6. Writes all other lines to the output file descriptor as they are being scanned
    7. Only does it once, e.g., subsequent tag lines will end up with suffix
    8. Yields None if no tag was found
    """
    lines = template.split("\n")
    found_tag = False
    scan_prefix = None
    tag_pattern = re.compile(r"^\s*")  # Precompile the regex pattern

    for line in lines:
        if not found_tag:
            if tag in line:
                found_tag = True
                # Match only the leading whitespace of the line with the tag
                match = tag_pattern.match(line)
                scan_prefix = match.group() if match else ""
                yield scan_prefix
                continue
            output_fd.write(line + "\n")
        else:
            if scan_prefix is not None:
                # Compute the current line's prefix
                current_line_prefix = tag_pattern.match(line).group()
                # Check if the current line's prefix is different from the tag's prefix
                if current_line_prefix == scan_prefix:
                    continue
                scan_prefix = None
            output_fd.write(line + "\n")
    if not found_tag:
        yield None

def is_git_repo(repo_path: str) -> bool:
    """
    Check if the given path is a git repository.
    """
    try:
        subprocess.check_output(["git", "-C", repo_path, "rev-parse", "--is-inside-work-tree"])
        return True
    except subprocess.CalledProcessError:
        return False

def get_api_url_from_git(repo_path: str) -> Optional[str]:
    if not is_git_repo(repo_path):
        logging.warning(
            f"The path '{repo_path}' is not a git repository. Not pulling keys from github."
        )
        return None
    """
    Extract the GitHub API URL from the local git repository using git command.

    :param repo_path: Path to the local git repository.
    :return: GitHub API URL or None if not found.
    """
    try:
        # Get the remote URL of the 'origin' remote repository
        git_url = (
            subprocess.check_output(
                ["git", "-C", repo_path, "remote", "get-url", "origin"],
                stderr=subprocess.PIPE
            )
            .decode()
            .strip()
        )
        logging.info(f"Pulling keys from GitHub repository: {git_url}")

        # Transform the git URL to the GitHub API URL
        if git_url.startswith("https://github.com/"):
            return git_url.replace(
                "https://github.com/", GITHUB_API_BASE_URL + "/", 1
            ).rstrip(".git")
        elif git_url.startswith("git@github.com:"):
            return git_url.replace(
                "git@github.com:", GITHUB_API_BASE_URL + "/", 1
            ).rstrip(".git")
    except Exception as e:
        logging.error(f"Unexpected error: {e}")
    return None


def get_api_url(repo_url: Optional[str], local_repo: Optional[str]) -> str|None:
    """
    Determine the GitHub API URL from either a repository URL or a local repository path.

    :param repo_url: GitHub repository URL.
    :param local_repo: Path to local Git repository.
    :return: GitHub API URL or None if not found.
    """
    api_url = None
    if repo_url:
        api_url = repo_url.rstrip("/").replace("github.com", GITHUB_API_BASE_URL, 1)
    elif local_repo:
        api_url = get_api_url_from_git(local_repo)
    if api_url:
        if not api_url.startswith("https://"):
            api_url = f"https://{api_url}"
        return api_url
    else:
        return None


def github_request(request_url: str, method: str = 'GET', data: Optional[dict] = None) -> request.urlopen:
    """
    Make a request to the GitHub API, supporting both GET and POST requests.
    This injects the GitHub API token environment variable into the request if present.

    :param request_url: URL to make the request to.
    :param method: HTTP method ('GET' or 'POST').
    :param data: Data to be sent in the request body (for POST requests).
    :return: Response from the GitHub API.
    """
    if data is not None:
        data = json.dumps(data).encode()
    req = request.Request(request_url, data=data, method=method)
    github_token = os.getenv("GITHUB_TOKEN")
    if github_token:
        auth_header = f"token {github_token}"
        req.add_header("Authorization", auth_header)
    req.add_header("Content-Type", "application/json")
    return request.urlopen(req)

def fetch_contributors(api_url: str) -> List[str]:
    """
    Fetch the list of collaborators for a GitHub repository using GitHub's GraphQL API.
    If the GraphQL query fails, fallback to the REST API to fetch contributors.

    :param api_url: GitHub API URL for the repository.
    :return: List of collaborator/contributor usernames.
    """
    graphql_url = "https://api.github.com/graphql"
    owner, repo = api_url.split('/')[-2:]
    query = """
    query {
      repository(owner: "%s", name: "%s") {
        collaborators(first: 100) {
          edges {
            node {
              login
            }
          }
        }
      }
    }
    """ % (owner, repo)

    try:
        with github_request(graphql_url, 'POST', {'query': query}) as response:
            data = json.load(response)
            contributors = data['data']['repository']['collaborators']['edges']
            return [contributor['node']['login'] for contributor in contributors]
    except (error.HTTPError, TypeError) as e:
        error_type = "HTTPError" if isinstance(e, error.HTTPError) else "KeyError"
        logging.error(f"{error_type} when querying {graphql_url}: {e}")
        logging.info("Attempting to list users via REST API as a fallback")
        return fetch_contributors_rest(api_url)


def fetch_contributors_rest(api_url: str) -> List[str]:
    """
    Fallback method to fetch the list of contributors for a GitHub repository using the REST API.

    :param api_url: GitHub API URL for the repository.
    :return: List of contributor usernames.
    """
    url = f"{api_url}/contributors"
    try:
        with github_request(url) as response:
            contributors = json.load(response)
            logging.debug(f"{url} returned {json.dumps(contributors, indent=2)}")
            return [contributor["login"] for contributor in contributors]
    except error.HTTPError as e:
        logging.error(f"HTTP Error: {e.code} {e.reason}")
        logging.error(
            "For private repositories and to avoid throttling you must set the GITHUB_TOKEN. Alternatively, consider passing users explicitly via --github-users to avoid auth hassles."
        )
        return None


def fetch_github_ssh_keys(contributors: List[str]) -> Dict[str, Dict[str, List[str]]]:
    """
    Fetch the specified types of SSH keys for a list of GitHub users.
    Store each key type mapping to a list of keys.

    :param contributors: List of GitHub usernames.
    :return: A dictionary mapping usernames to dictionaries of key types and their keys.
    """
    keys_by_user_and_type = {}
    for username in contributors:
        user_keys = keys_by_user_and_type.get(username, {})
        try:
            with github_request(f"https://github.com/{username}.keys") as response:
                lines = response.read().decode().strip().splitlines()
                for line in lines:
                    key_type, key = line.split(" ", 1)  # Split on first space only
                    if key_type not in user_keys:
                        user_keys[key_type] = []
                    user_keys[key_type].append(key)
                keys_by_user_and_type[username] = user_keys
        except error.HTTPError as e:
            print(
                f"HTTP Error: {e.code} {e.reason} for user {username}", file=sys.stderr
            )
            continue
    return keys_by_user_and_type




def comma_separated_list(string: str) -> Set[str]:
    """
    Converts a comma-separated string into a set of strings.

    :param string: A string containing comma-separated values.
    :return: A set containing the individual values as strings.
    """
    return set(string.split(","))


def print_keys(template: str, user_keys: Dict[str, Dict[str, List[str]]],
               accepted_key_types: Set[str], output_format: str,
               output_fd: TextIO) -> None:
    """
    Processes a template and prints SSH keys in a specified format.

    :param template: A string template for processing.
    :param user_keys: A dictionary mapping usernames to dictionaries of key types and their keys.
                      Each key type maps to a list of keys.
    :param accepted_key_types: A set of accepted key types.
    :param output_format: The format in which to output the keys.
    :param output_fd: The file descriptor to write the output to.
    """
    # Assuming process_template is a function you have defined elsewhere
    for line_prefix in process_template(template, GITHUB_TO_SOPS_TAG, output_fd):
        if line_prefix is None:
            line_prefix = ""
        print(f"{line_prefix}# {GENERATED_MSG}", file=output_fd)

        # Sort the users by their username
        sorted_users = sorted(user_keys.keys(), key=lambda username: username.lower())

        for username in sorted_users:
            user_key_types = user_keys[username]
            for key_type in user_key_types:
                if accepted_key_types is not None and key_type not in accepted_key_types:
                    continue
                for key in user_key_types[key_type]:
                    if output_format == "sops":
                        if output_format == "sops":
                            print(f"{line_prefix}- {key_type} {key} # {username}", file=output_fd)
                        else:
                            print(f"{key}", file=output_fd)
                    else:
                        print(f"{key_type} {key} {username}", file=output_fd)


def extract_generation_command(file_path: str) -> Optional[List[str]]:
    """
    Extracts the generation command from the file's 'Generated by' line.
    """
    try:
        with open(file_path, 'r') as f:
            for line in f:
                if 'Generated by' in line and GITHUB_TO_SOPS_TAG in line:
                    # Extract command from backticks: `command`
                    match = re.search(r'`([^`]+)`', line)
                    if match:
                        command_str = match.group(1)
                        # Replace the command name if it was 'refresh-secrets' with 'import-keys'
                        # to ensure we call the right function for generation logic.
                        # This handles the case where a refresh command was used previously.
                        parts = shlex.split(command_str)
                        # Replace 'refresh-secrets' with 'import-keys' to ensure we call the right function.
                        parts = ['import-keys' if part == 'refresh-secrets' else part for part in parts]
                        return parts
    except FileNotFoundError:
        return None
    return None


def refresh_secrets(args):
    """
    Refresh secrets in the repository.

    This function finds all `.sops.yaml` files managed by git and runs `import-keys --inplace-edit` on them.
    It also finds all `*.enc.yaml` files, and for those containing 'sops:', it runs `sops updatekeys -y`.
    """
    import subprocess
    import os
    import logging

    def find_sops_yaml_files():
        """
        Find all .sops.yaml files in the repo that are managed by git.
        """
        logging.info("Finding .sops.yaml files in the repo managed by git.")
        result = subprocess.run(
            ["git", "ls-files", "*.sops.yaml"],
            stdout=subprocess.PIPE,
            text=True,
            check=True
        )
        return result.stdout.splitlines()

    def find_enc_yaml_files():
        """
        Find all *.enc.yaml files in the repo that are managed by git.
        """
        logging.info("Finding *.enc.yaml files in the repo managed by git.")
        result = subprocess.run(
            ["git", "ls-files", "*.enc.yaml"],
            stdout=subprocess.PIPE,
            text=True,
            check=True
        )
        return result.stdout.splitlines()

    def file_contains_sops(file_path):
        """
        Check if the file contains 'sops:' in its content.
        """
        with open(file_path, 'r') as file:
            return 'sops:' in file.read()

    sops_yaml_files = find_sops_yaml_files()
    logging.info(f"Found {len(sops_yaml_files)} .sops.yaml files.")
    for file in sops_yaml_files:
        logging.info(f"Re-running generation command for {file}.")
        old_cmd_args = extract_generation_command(file)
        if not old_cmd_args:
            logging.warning(f"Could not extract generation command from {file}. Skipping.")
            continue

        # Re-run the old command, but ensure it's doing an inplace edit on the current file.
        # Use current executable, arguments from old command, and add --inplace-edit.
        # The last used --inplace-edit will be used by argparse if multiple are present.
        new_cmd = [sys.argv[0]] + old_cmd_args[1:] + ["--inplace-edit", file]

        logging.info(f"Executing: {' '.join(new_cmd)}")
        subprocess.run(
            new_cmd,
            check=True
        )

    enc_yaml_files = find_enc_yaml_files()
    logging.info(f"Found {len(enc_yaml_files)} *.enc.yaml files.")
    for file in enc_yaml_files:
        if file_contains_sops(file):
            logging.info(f"Running sops updatekeys -y on {file}.")
            subprocess.run(
                ["sops", "updatekeys", "-y", file],
                check=True
            )

def generate_keys(args):
    """
    Handles the logic for the 'import-keys' command.

    Fetches SSH keys from GitHub contributors or specified users,
    and then prints them in the specified format (e.g., SOPS, authorized_keys).
    Can also perform in-place edits of SOPS files.
    """
    if args.inplace_edit:
        args.format = "sops"
        input_template = open(args.inplace_edit, "r").read()
        output_fd = open(args.inplace_edit + ".tmp", "w")
    if args.key_types is None:
        args.key_types = set(["ssh-ed25519", "ssh-rsa"])

    api_url = get_api_url(args.github_url, args.local_github_checkout)
    contributors = None
    if args.github_users:
        contributors = args.github_users
    elif api_url:
        contributors = fetch_contributors(api_url)
        if contributors is None:
            logging.error("Failed to fetch contributors from GitHub. Aborting to prevent data loss.")
            sys.exit(1)

    keys = dict()
    if contributors:
        keys = fetch_github_ssh_keys(contributors)

    print_keys(
        template=input_template.strip() if args.inplace_edit and args.format == "sops" else SOPS_TEMPLATE if args.format == "sops" else "",
        user_keys=keys,
        accepted_key_types=args.key_types,
        output_format=args.format,
        output_fd=output_fd if args.inplace_edit else sys.stdout,
    )
    if args.inplace_edit:
        output_fd.close()
        os.rename(args.inplace_edit + ".tmp", args.inplace_edit)

def get_version():
    """
    Get the package version.
    """
    try:
        from importlib.metadata import version
        return version("github_to_sops")
    except Exception:
        return "unknown"

def get_goos(system):
    """
    Returns the GOOS value based on the system.

    :param system: The operating system.
    :return: The GOOS value.
    """
    goos_map = {
        "Linux": "linux",
        "Darwin": "darwin"
    }
    return goos_map.get(system)

def get_goarch(machine):
    """
    Returns the GOARCH value based on the machine.

    :param machine: The machine architecture.
    :return: The GOARCH value.
    """
    goarch_map = {
        "x86_64": "amd64",
        "aarch64": "arm64",
        "arm64": "arm64"
    }
    return goarch_map.get(machine)

def get_sops_download_url(system, machine, version="v3.10.2"):
    """
    Returns the download URL for the sops binary based on the system, machine, and version.

    :param system: The operating system.
    :param machine: The machine architecture.
    :param version: The version of the sops binary.
    :return: The download URL for the sops binary.
    """
    goos = get_goos(system)
    goarch = get_goarch(machine)
    if goos and goarch:
        base_url = f"https://github.com/getsops/sops/releases/download/{version}/sops-{version}"
        return f"{base_url}.{goos}.{goarch}"
    return None

def install(args):
    """
    Handles the logic for the 'install' command.

    Checks if 'sops' is installed, and if not, downloads and installs it
    for supported platforms (Linux, macOS).
    """
    import os
    import platform
    import subprocess
    import tempfile
    import urllib.request
    import shutil

    def is_binary_installed(name):
        """Check if a binary is already installed and executable"""
        return shutil.which(name) is not None

    def download_and_install_sops(system, machine):
        if is_binary_installed("sops"):
            print("sops is already installed, skipping installation")
            return

        download_url = get_sops_download_url(system, machine)
        if download_url is None:
            print("Not supported on your platform", file=sys.stderr)
            sys.exit(1)

        temp_dir = tempfile.gettempdir()
        binary_name = "sops"
        temp_binary_path = os.path.join(temp_dir, binary_name)

        print(f"Downloading sops binary from {download_url} to {temp_binary_path}")
        with urllib.request.urlopen(download_url) as response, open(temp_binary_path, 'wb') as out_file:
            shutil.copyfileobj(response, out_file)
        print("Download completed")

        os.chmod(temp_binary_path, 0o755)
        try:
            print(f"Executing: sudo mv {temp_binary_path} /usr/local/bin/sops")
            subprocess.run(["sudo", "mv", temp_binary_path, "/usr/local/bin/sops"], check=True)
            print("sops binary installed successfully to /usr/local/bin/sops")
        except subprocess.CalledProcessError as e:
            print(f"Failed to move sops binary to /usr/local/bin/sops: {e}", file=sys.stderr)
            sys.exit(1)

    system = platform.system()
    machine = platform.machine()

    download_and_install_sops(system, machine)

def main():
    """
    Main entry point for the script.

    Parses command-line arguments and calls the appropriate function
    based on the specified subcommand (install, refresh-secrets, import-keys).
    """
    # Handle sops subcommand before argparse, otherwise argparse will make it hard to pass arguments to sops

    parser = argparse.ArgumentParser(
        description="Manage GitHub SSH keys and generate SOPS-compatible SSH key files.",
        add_help=False
    )
    parser.add_argument(
        "--version",
        action="version",
        version=f"%(prog)s {get_version()}"
    )
    parser.add_argument(
        "-h", "--help",
        action="help",
        help="Show this help message and exit."
    )
    parser.add_argument(
        "--github-users",
        type=comma_separated_list,
        help="Comma-separated list of GitHub usernames to fetch keys for. This is a global option that can be used with import-keys and refresh-secrets.",
    )
    subparsers = parser.add_subparsers(dest="command")

    install_parser = subparsers.add_parser(
        "install",
        help="Install sops binary for supported platforms (Linux and Mac)."
    )
    
    install_parser.add_argument(
        "-v",
        "--verbose",
        help="Turn on debug logging to see HTTP requests and other internal Python stuff.",
        action="store_true",
    )

    refresh_secrets_parser = subparsers.add_parser(
        "refresh-secrets",
        help="Find all .sops.yaml files in the repo that are managed by git and run `import-keys --inplace-edit .sops.yaml` on them. Can be combined with --github-users."
    )
    refresh_secrets_parser.add_argument(
        "-v",
        "--verbose",
        help="Turn on debug logging to see HTTP requests and other internal Python stuff.",
        action="store_true",
    )

    import_keys_parser = subparsers.add_parser(
        "import-keys",
        help="Import SSH keys of GitHub repository contributors or specified github users and output that info into a useful format like sops or ssh authorized_keys",
        epilog=f"""Example invocations:
    `{sys.argv[0]} import-keys --github-url https://github.com/tarasglek/chatcraft.org --key-types ssh-ed25519 --format sops`
    `{sys.argv[0]} import-keys --github-url https://github.com/tarasglek/chatcraft.org --format authorized_keys`
    `{sys.argv[0]} import-keys --local-github-checkout . --format sops --key-types ssh-ed25519`
    """,
    )
    import_keys_parser.add_argument("--github-url", help="GitHub repository URL.")
    import_keys_parser.add_argument("--local-github-checkout", default=".", help="Path to local Git repository.")
    import_keys_parser.add_argument(
        "--key-types",
        type=comma_separated_list,
        default=None,
        help="Comma-separated types of SSH keys to fetch (e.g., ssh-ed25519,ssh-rsa). Pass no value for all types.",
    )
    # Supported conversions with validation
    supported_conversions = ["authorized_keys", "sops"]
    import_keys_parser.add_argument(
        "--format",
        default="sops",
        type=str,
        choices=supported_conversions,
        help=f"Output/convert keys using the specified format. Supported formats: "
        f"{', '.join(supported_conversions)}.",
    )
    import_keys_parser.add_argument(
        "--inplace-edit",
        help="Edit SOPS file in-place. This takes a .sops.yaml file as input and replaces it. This sets --format to sops",
    )
    import_keys_parser.add_argument(
        "-v",
        "--verbose",
        help="Turn on debug logging to see HTTP requests and other internal Python stuff.",
        action="store_true",
    )

    args = parser.parse_args()

    # Configure logging
    log_level = logging.INFO
    if hasattr(args, "verbose") and args.verbose:
        log_level = logging.DEBUG
    logging.basicConfig(level=log_level, format="%(message)s", stream=sys.stderr)

    if args.command == "install":
        install(args)
    elif args.command == "refresh-secrets":
        refresh_secrets(args)
    elif args.command == "import-keys":
        generate_keys(args)
    else:
        parser.print_help()

if __name__ == "__main__":
    main()
