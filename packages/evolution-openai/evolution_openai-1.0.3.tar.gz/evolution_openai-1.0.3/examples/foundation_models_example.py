#!/usr/bin/env python3
"""
–ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã —Å Evolution Foundation Models
"""

import os
import time
import asyncio

from evolution_openai import OpenAI, AsyncOpenAI

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
BASE_URL = os.getenv("EVOLUTION_BASE_URL", "https://your-endpoint.cloud.ru/v1")
FOUNDATION_MODELS_URL = os.getenv(
    "EVOLUTION_FOUNDATION_MODELS_URL",
    "https://foundation-models.api.cloud.ru/api/gigacube/openai/v1",
)
KEY_ID = os.getenv("EVOLUTION_KEY_ID", "your_key_id")
SECRET = os.getenv("EVOLUTION_SECRET", "your_secret")
PROJECT_ID = os.getenv("EVOLUTION_PROJECT_ID")

# –í—ã–±–∏—Ä–∞–µ–º Foundation Models endpoint –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
ENDPOINT_URL = FOUNDATION_MODELS_URL if FOUNDATION_MODELS_URL else BASE_URL
DEFAULT_MODEL = "RefalMachine/RuadaptQwen2.5-7B-Lite-Beta"


def get_foundation_model():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è Foundation Models"""
    print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {DEFAULT_MODEL}")
    return DEFAULT_MODEL


async def get_foundation_model_async():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–æ–¥–µ–ª—å –¥–ª—è Foundation Models (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)"""
    print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å: {DEFAULT_MODEL}")
    return DEFAULT_MODEL


def basic_foundation_models_example():
    """–ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä Foundation Models"""
    print("=== –ë–∞–∑–æ–≤—ã–π Foundation Models ===")

    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Foundation Models")
        return None

    try:
        with OpenAI(
            key_id=KEY_ID,
            secret=SECRET,
            base_url=ENDPOINT_URL,
            project_id=PROJECT_ID,
        ) as client:
            model_name = get_foundation_model()

            response = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "system",
                        "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–π Evolution Foundation Models.",
                    },
                    {
                        "role": "user",
                        "content": "–†–∞—Å—Å–∫–∞–∂–∏ –∫—Ä–∞—Ç–∫–æ –æ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—è—Ö –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞",
                    },
                ],
                max_tokens=50,
                temperature=0.7,
            )

            if (
                response.choices
                and len(response.choices) > 0
                and response.choices[0].message
            ):
                content = (
                    response.choices[0].message.content
                    or "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ"
                )
                print(f"‚úÖ –û—Ç–≤–µ—Ç: {content}")
                print(f"üìä –ú–æ–¥–µ–ª—å: {response.model}")
                print(f"üî¢ –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
                return True
            else:
                print("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        return False


def streaming_foundation_models_example():
    """–ü—Ä–∏–º–µ—Ä streaming —Å Foundation Models"""
    print("\n=== Streaming Foundation Models ===")

    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è streaming")
        return None

    try:
        with OpenAI(
            key_id=KEY_ID,
            secret=SECRET,
            base_url=ENDPOINT_URL,
            project_id=PROJECT_ID,
        ) as client:
            model_name = get_foundation_model()

            print("–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ...")
            print("-" * 50)

            stream = client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "user",
                        "content": "–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å—Ç–∏—Ö–æ—Ç–≤–æ—Ä–µ–Ω–∏–µ –ø—Ä–æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏",
                    }
                ],
                stream=True,
                max_tokens=80,
                temperature=0.8,
            )

            content_parts = []
            for chunk in stream:
                if (
                    chunk.choices
                    and len(chunk.choices) > 0
                    and chunk.choices[0].delta
                    and chunk.choices[0].delta.content
                ):
                    content = chunk.choices[0].delta.content
                    content_parts.append(content)
                    print(content, end="", flush=True)

            print("\n" + "-" * 50)
            print(
                f"‚úÖ Streaming –∑–∞–≤–µ—Ä—à–µ–Ω! –ü–æ–ª—É—á–µ–Ω–æ {len(content_parts)} —á–∞—Å—Ç–µ–π."
            )
            return True

    except Exception as e:
        print(f"‚ùå Streaming –æ—à–∏–±–∫–∞: {e}")
        return False


async def async_foundation_models_example():
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø—Ä–∏–º–µ—Ä Foundation Models"""
    print("\n=== –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π Foundation Models ===")

    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è async –ø—Ä–∏–º–µ—Ä–∞")
        return None

    try:
        async with AsyncOpenAI(
            key_id=KEY_ID,
            secret=SECRET,
            base_url=ENDPOINT_URL,
            project_id=PROJECT_ID,
        ) as client:
            model_name = await get_foundation_model_async()

            response = await client.chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "user",
                        "content": "–û–±—ä—è—Å–Ω–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏, —á—Ç–æ —Ç–∞–∫–æ–µ –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
                    }
                ],
                max_tokens=60,
                temperature=0.5,
            )

            if (
                response.choices
                and len(response.choices) > 0
                and response.choices[0].message
            ):
                content = (
                    response.choices[0].message.content
                    or "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ"
                )
                print(f"‚úÖ Async –æ—Ç–≤–µ—Ç: {content}")
                print(f"üìä –ú–æ–¥–µ–ª—å: {response.model}")
                print(f"üî¢ –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
                return True
            else:
                print("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False

    except Exception as e:
        print(f"‚ùå Async –æ—à–∏–±–∫–∞: {e}")
        return False


def advanced_foundation_models_example():
    """–ü—Ä–∏–º–µ—Ä —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –æ–ø—Ü–∏—è–º–∏ Foundation Models"""
    print("\n=== Foundation Models —Å –æ–ø—Ü–∏—è–º–∏ ===")

    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è advanced –ø—Ä–∏–º–µ—Ä–∞")
        return None

    try:
        with OpenAI(
            key_id=KEY_ID,
            secret=SECRET,
            base_url=ENDPOINT_URL,
            project_id=PROJECT_ID,
        ) as client:
            model_name = get_foundation_model()

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º with_options –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            response = client.with_options(
                timeout=60.0, max_retries=3
            ).chat.completions.create(
                model=model_name,
                messages=[
                    {
                        "role": "user",
                        "content": "–°–æ–∑–¥–∞–π –ø–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è Python –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö",
                    }
                ],
                max_tokens=80,
                temperature=0.3,
            )

            if (
                response.choices
                and len(response.choices) > 0
                and response.choices[0].message
            ):
                content = (
                    response.choices[0].message.content
                    or "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ"
                )
                print(f"‚úÖ –û—Ç–≤–µ—Ç —Å –æ–ø—Ü–∏—è–º–∏: {content}")
                print(f"üìä –ú–æ–¥–µ–ª—å: {response.model}")
                print(f"üî¢ –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")

                # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–æ–∫–µ–Ω–µ
                token_info = client.get_token_info()
                print(f"üîë –°—Ç–∞—Ç—É—Å —Ç–æ–∫–µ–Ω–∞: {token_info}")
                return True
            else:
                print("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                return False

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å –æ–ø—Ü–∏—è–º–∏: {e}")
        return False


async def parallel_foundation_models_example():
    """–ü—Ä–∏–º–µ—Ä –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ Foundation Models"""
    print("\n=== –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã Foundation Models ===")

    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤")
        return None

    try:
        async with AsyncOpenAI(
            key_id=KEY_ID,
            secret=SECRET,
            base_url=ENDPOINT_URL,
            project_id=PROJECT_ID,
        ) as client:
            model_name = await get_foundation_model_async()

            # –°–ø–∏—Å–æ–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            questions = [
                "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç?",
                "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ?",
                "–ß—Ç–æ —Ç–∞–∫–æ–µ –Ω–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏?",
            ]

            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            tasks = []
            for question in questions:
                task = client.chat.completions.create(
                    model=model_name,
                    messages=[
                        {
                            "role": "system",
                            "content": "–î–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.",
                        },
                        {"role": "user", "content": question},
                    ],
                    max_tokens=50,
                    temperature=0.5,
                )
                tasks.append(task)

            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–ø—Ä–æ—Å—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            start_time = time.time()
            responses = await asyncio.gather(*tasks)
            end_time = time.time()

            elapsed = end_time - start_time
            print(
                f"‚ö° –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(questions)} –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ {elapsed:.2f} —Å–µ–∫—É–Ω–¥"
            )
            print()

            for i, (question, response) in enumerate(
                zip(questions, responses)
            ):
                print(f"‚ùì –í–æ–ø—Ä–æ—Å {i + 1}: {question}")
                if (
                    response.choices
                    and len(response.choices) > 0
                    and response.choices[0].message
                ):
                    content = (
                        response.choices[0].message.content
                        or "–ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ"
                    )
                    print(f"‚úÖ –û—Ç–≤–µ—Ç: {content}")
                    print(f"üî¢ –¢–æ–∫–µ–Ω–æ–≤: {response.usage.total_tokens}")
                else:
                    print("‚ùå –ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                print("-" * 50)

            return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤: {e}")
        return False


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ Foundation Models"""
    print("üöÄ Evolution Foundation Models - –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\n")
    print(f"üåê Endpoint: {ENDPOINT_URL}")
    print(f"ü§ñ –ú–æ–¥–µ–ª—å: {DEFAULT_MODEL}")

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º, –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –ª–∏ Foundation Models
    is_foundation_models = (
        "foundation-models" in ENDPOINT_URL or "gigacube" in ENDPOINT_URL
    )
    print(f"üîß –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è Foundation Models: {is_foundation_models}\n")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if KEY_ID == "your_key_id" or SECRET == "your_secret":
        print("‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è!")
        print(
            "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Foundation Models:"
        )
        print("export EVOLUTION_KEY_ID='your_key_id'")
        print("export EVOLUTION_SECRET='your_secret'")
        print("export EVOLUTION_PROJECT_ID='your_project_id'")
        print(
            "export EVOLUTION_FOUNDATION_MODELS_URL='https://foundation-models.api.cloud.ru/api/gigacube/openai/v1'"
        )
        print("\nüí° –ü—Ä–∏–º–µ—Ä—ã –±—É–¥—É—Ç –∑–∞–ø—É—â–µ–Ω—ã –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ")
        print()

    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    results = []

    # –°–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    results.append(basic_foundation_models_example())
    results.append(streaming_foundation_models_example())
    results.append(advanced_foundation_models_example())

    # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    async def run_async_examples():
        async_results = []
        async_results.append(await async_foundation_models_example())
        async_results.append(await parallel_foundation_models_example())
        return async_results

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã
    async_results = asyncio.run(run_async_examples())
    results.extend(async_results)

    # –ü–æ–¥–≤–æ–¥–∏–º –∏—Ç–æ–≥–∏
    successful = sum(1 for r in results if r is True)
    failed = sum(1 for r in results if r is False)
    skipped = sum(1 for r in results if r is None)

    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:")
    print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
    print(f"‚ùå –û—à–∏–±–∫–∏: {failed}")
    print(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {skipped}")

    if failed == 0 and successful > 0:
        print("\nüéâ –í—Å–µ –ø—Ä–∏–º–µ—Ä—ã Foundation Models –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
    elif failed > 0:
        print(f"\n‚ö†Ô∏è {failed} –ø—Ä–∏–º–µ—Ä–æ–≤ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")

    print("\nüí° –ü–æ–¥—Å–∫–∞–∑–∫–∏:")
    print("- –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ PROJECT_ID —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –¥–ª—è Foundation Models")
    print("- –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Foundation Models endpoint")
    print(
        "- –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ EVOLUTION_FOUNDATION_MODELS_URL –¥–ª—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ endpoint"
    )
    print("- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: docs/foundation_models.md")

    return failed == 0


if __name__ == "__main__":
    import sys

    success = main()
    sys.exit(0 if success else 1)
