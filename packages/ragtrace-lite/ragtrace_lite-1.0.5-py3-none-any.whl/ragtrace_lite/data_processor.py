"""
RAGTrace Lite Data Processor

ë°ì´í„° ì²˜ë¦¬ ê¸°ëŠ¥:
- JSON/XLSX íŒŒì¼ ë¡œë”©
- ë°ì´í„° ê²€ì¦ ë° ë³€í™˜
- RAGAS Dataset í˜•ì‹ìœ¼ë¡œ ë³€í™˜
- ë‹¤ì–‘í•œ contexts í˜•ì‹ ì§€ì›
"""

import json
import ast
import pandas as pd
from pathlib import Path
from typing import Union, List, Dict, Any, Optional
from datasets import Dataset

from .config_loader import Config


class DataProcessor:
    """RAGTrace Lite ë°ì´í„° ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    REQUIRED_COLUMNS = ["question", "answer", "contexts", "ground_truth"]
    OPTIONAL_COLUMNS = ["ground_truths"]  # RAGAS í˜¸í™˜ì„ ìœ„í•œ ë³µìˆ˜í˜•
    
    def __init__(self, config: Optional[Config] = None):
        """
        ë°ì´í„° í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
        
        Args:
            config: RAGTrace Lite ì„¤ì • (ì„ íƒì‚¬í•­)
        """
        self.config = config
        
    def load_and_prepare_data(self, file_path: Union[str, Path]) -> Dataset:
        """
        ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ RAGAS Datasetìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            file_path: ì…ë ¥ ë°ì´í„° íŒŒì¼ ê²½ë¡œ (JSON ë˜ëŠ” XLSX)
            
        Returns:
            Dataset: RAGAS í˜¸í™˜ Dataset ê°ì²´
            
        Raises:
            FileNotFoundError: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì´ê±°ë‚˜ ë°ì´í„°ê°€ ì˜ëª»ëœ ê²½ìš°
        """
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        print(f"ğŸ“ ë°ì´í„° íŒŒì¼ ë¡œë”©: {file_path}")
        
        # íŒŒì¼ í˜•ì‹ì— ë”°ë¥¸ ë¡œë”©
        if file_path.suffix.lower() == ".json":
            df = self._load_json_file(file_path)
        elif file_path.suffix.lower() in [".xlsx", ".xls"]:
            df = self._load_excel_file(file_path)
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤: {file_path.suffix}")
        
        print(f"âœ… ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)}ê°œ í•­ëª©")
        
        # ë°ì´í„° ê²€ì¦ ë° ë³€í™˜
        df = self._validate_and_transform_data(df)
        
        # RAGAS Datasetìœ¼ë¡œ ë³€í™˜
        dataset = self._convert_to_ragas_dataset(df)
        
        print(f"âœ… RAGAS Dataset ë³€í™˜ ì™„ë£Œ")
        return dataset
    
    def _load_json_file(self, file_path: Path) -> pd.DataFrame:
        """JSON íŒŒì¼ì„ ë¡œë”©í•©ë‹ˆë‹¤."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # JSON êµ¬ì¡° í™•ì¸ ë° DataFrame ë³€í™˜
            if isinstance(data, dict):
                # ì»¬ëŸ¼ë³„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ: {"question": [...], "answer": [...]}
                df = pd.DataFrame(data)
            elif isinstance(data, list):
                # ë ˆì½”ë“œ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ: [{"question": "...", "answer": "..."}]
                df = pd.DataFrame(data)
            else:
                raise ValueError("JSON íŒŒì¼ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤")
                
            return df
            
        except json.JSONDecodeError as e:
            raise ValueError(f"JSON íŒŒì¼ íŒŒì‹± ì˜¤ë¥˜: {e}")
        except Exception as e:
            raise ValueError(f"JSON íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def _load_excel_file(self, file_path: Path) -> pd.DataFrame:
        """Excel íŒŒì¼ì„ ë¡œë”©í•©ë‹ˆë‹¤."""
        try:
            # Excel íŒŒì¼ ì½ê¸°
            df = pd.read_excel(file_path)
            return df
            
        except Exception as e:
            raise ValueError(f"Excel íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {e}")
    
    def _validate_and_transform_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        print("ğŸ” ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ ì‹œì‘")
        
        # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        missing_columns = []
        for col in self.REQUIRED_COLUMNS:
            if col not in df.columns:
                missing_columns.append(col)
        
        if missing_columns:
            if 'ground_truth' in missing_columns and len(missing_columns) == 1:
                print("âš ï¸  'ground_truth' ì»¬ëŸ¼ì´ ì—†ì–´ answer_correctness í‰ê°€ê°€ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                # ground_truthê°€ ì—†ìœ¼ë©´ ë¹ˆ ê°’ìœ¼ë¡œ ì±„ì›€
                df['ground_truth'] = ""
            else:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        
        # contexts ì»¬ëŸ¼ ë³€í™˜
        df = self._transform_contexts_column(df)
        
        # ground_truth -> ground_truths ë³€í™˜ (RAGAS í˜¸í™˜)
        if 'ground_truth' in df.columns and 'ground_truths' not in df.columns:
            df['ground_truths'] = df['ground_truth'].apply(
                lambda x: [x] if isinstance(x, str) and x.strip() else []
            )
        elif 'ground_truths' in df.columns:
            # ground_truthsê°€ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            def ensure_list(x):
                if isinstance(x, str) and x.strip():
                    return [x.strip()]
                elif isinstance(x, list):
                    return [item for item in x if isinstance(item, str) and item.strip()]
                else:
                    return []
            df['ground_truths'] = df['ground_truths'].apply(ensure_list)
            
        # Context recallì„ ìœ„í•œ ground_truths ê²€ì¦
        if 'ground_truths' in df.columns:
            empty_ground_truths = df['ground_truths'].apply(lambda x: len(x) == 0).sum()
            if empty_ground_truths > 0:
                print(f"âš ï¸  Context recall ì œí•œ: {empty_ground_truths}ê°œ í•­ëª©ì— ground_truths ëˆ„ë½")
            else:
                print("âœ… Ground truths ê²€ì¦ ì™„ë£Œ: Context recall í‰ê°€ ê°€ëŠ¥")
        
        # reference ì»¬ëŸ¼ ì¶”ê°€ (context_precisionìš©)
        if 'ground_truth' in df.columns and 'reference' not in df.columns:
            df['reference'] = df['ground_truth']
        
        # ë¹ˆ ê°’ ì²˜ë¦¬
        df = df.fillna("")
        
        print("âœ… ë°ì´í„° ê²€ì¦ ë° ë³€í™˜ ì™„ë£Œ")
        return df
    
    def _transform_contexts_column(self, df: pd.DataFrame) -> pd.DataFrame:
        """contexts ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        print("ğŸ”§ contexts ì»¬ëŸ¼ ë³€í™˜ ì¤‘...")
        
        if 'contexts' not in df.columns:
            raise ValueError("'contexts' ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤")
        
        def parse_contexts(contexts_value) -> List[str]:
            """ë‹¤ì–‘í•œ í˜•íƒœì˜ contextsë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
            # Noneì´ë‚˜ NaN ì²˜ë¦¬
            try:
                if contexts_value is None:
                    return []
                if pd.isna(contexts_value):
                    return []
            except (TypeError, ValueError):
                # pandas.isna()ê°€ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš° (ì˜ˆ: ë°°ì—´)
                pass
            
            # ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
            if isinstance(contexts_value, (list, tuple)):
                return [str(item) for item in contexts_value if item is not None]
            
            # numpy ë°°ì—´ì¸ ê²½ìš°
            try:
                import numpy as np
                if isinstance(contexts_value, np.ndarray):
                    return [str(item) for item in contexts_value.tolist() if item is not None]
            except ImportError:
                pass
            
            # ë¬¸ìì—´ ë³€í™˜ ì‹œë„
            try:
                contexts_str = str(contexts_value).strip()
                if not contexts_str or contexts_str == 'nan':
                    return []
            except:
                return []
            
            # JSON ë°°ì—´ í˜•íƒœ ì‹œë„
            if contexts_str.startswith('[') and contexts_str.endswith(']'):
                try:
                    parsed = ast.literal_eval(contexts_str)
                    if isinstance(parsed, list):
                        return [str(item) for item in parsed if item is not None]
                except (ValueError, SyntaxError):
                    pass
                    
                # JSON íŒŒì‹± ì‹œë„
                try:
                    import json
                    parsed = json.loads(contexts_str)
                    if isinstance(parsed, list):
                        return [str(item) for item in parsed if item is not None]
                except json.JSONDecodeError:
                    pass
            
            # êµ¬ë¶„ìë¡œ ë¶„ë¦¬ ì‹œë„
            for separator in [';', '|', '\n']:
                if separator in contexts_str:
                    parts = [part.strip() for part in contexts_str.split(separator)]
                    return [part for part in parts if part]
            
            # ë‹¨ì¼ contextë¡œ ì²˜ë¦¬
            return [contexts_str]
        
        # contexts ì»¬ëŸ¼ ë³€í™˜
        try:
            df['contexts'] = df['contexts'].apply(parse_contexts)
        except Exception as e:
            print(f"âš ï¸  contexts ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ëŒ€ì•ˆ: ì§ì ‘ ë³€í™˜
            new_contexts = []
            for idx, contexts_value in df['contexts'].items():
                new_contexts.append(parse_contexts(contexts_value))
            df['contexts'] = new_contexts
        
        # ë¹ˆ contexts í™•ì¸
        empty_contexts = df['contexts'].apply(len) == 0
        empty_count = empty_contexts.sum()
        if empty_count > 0:
            print(f"âš ï¸  ë¹ˆ contextsê°€ ìˆëŠ” í•­ëª©: {empty_count}ê°œ")
        
        print(f"âœ… contexts ë³€í™˜ ì™„ë£Œ: í‰ê·  {df['contexts'].apply(len).mean():.1f}ê°œ ì»¨í…ìŠ¤íŠ¸/í•­ëª©")
        return df
    
    def _convert_to_ragas_dataset(self, df: pd.DataFrame) -> Dataset:
        """pandas DataFrameì„ RAGAS Datasetìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        
        # RAGASì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        ragas_columns = ['question', 'answer', 'contexts', 'ground_truths', 'reference']
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_columns = [col for col in ragas_columns if col in df.columns]
        df_ragas = df[available_columns].copy()
        
        # Dataset ë”•ì…”ë„ˆë¦¬ ìƒì„±
        dataset_dict = {}
        for col in available_columns:
            dataset_dict[col] = df_ragas[col].tolist()
        
        # RAGAS Dataset ìƒì„±
        try:
            dataset = Dataset.from_dict(dataset_dict)
            return dataset
        except Exception as e:
            raise ValueError(f"RAGAS Dataset ìƒì„± ì‹¤íŒ¨: {e}")
    
    def get_data_summary(self, dataset: Dataset) -> Dict[str, Any]:
        """ë°ì´í„°ì…‹ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        summary = {
            'total_items': len(dataset),
            'columns': list(dataset.column_names),
            'sample_data': {}
        }
        
        # ê° ì»¬ëŸ¼ì˜ ìƒ˜í”Œ ë°ì´í„°
        for col in dataset.column_names:
            if len(dataset) > 0:
                sample_value = dataset[0][col]
                if isinstance(sample_value, list):
                    summary['sample_data'][col] = f"List[{len(sample_value)} items]"
                else:
                    summary['sample_data'][col] = str(sample_value)[:50] + "..."
        
        return summary
    
    def validate_dataset_for_ragas(self, dataset: Dataset) -> List[str]:
        """RAGAS í‰ê°€ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ ê²€ì¦"""
        issues = []
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_for_ragas = ['question', 'answer', 'contexts']
        for col in required_for_ragas:
            if col not in dataset.column_names:
                issues.append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {col}")
        
        if len(dataset) == 0:
            issues.append("ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return issues
        
        # ë°ì´í„° í’ˆì§ˆ í™•ì¸
        for i, item in enumerate(dataset):
            if i >= 5:  # ì²« 5ê°œ í•­ëª©ë§Œ ê²€ì‚¬
                break
                
            # question ê²€ì¦
            if not item.get('question') or not str(item['question']).strip():
                issues.append(f"í•­ëª© {i}: ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # answer ê²€ì¦
            if not item.get('answer') or not str(item['answer']).strip():
                issues.append(f"í•­ëª© {i}: ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            
            # contexts ê²€ì¦
            contexts = item.get('contexts', [])
            if not contexts or len(contexts) == 0:
                issues.append(f"í•­ëª© {i}: ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            elif not all(str(ctx).strip() for ctx in contexts):
                issues.append(f"í•­ëª© {i}: ë¹ˆ ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
        
        return issues


def test_data_processor():
    """ë°ì´í„° í”„ë¡œì„¸ì„œ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª DataProcessor í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    sample_file = Path("data/input/sample.json")
    
    if not sample_file.exists():
        print(f"âŒ ìƒ˜í”Œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {sample_file}")
        return False
    
    try:
        processor = DataProcessor()
        dataset = processor.load_and_prepare_data(sample_file)
        
        # ìš”ì•½ ì •ë³´ ì¶œë ¥
        summary = processor.get_data_summary(dataset)
        print(f"ğŸ“Š ë°ì´í„°ì…‹ ìš”ì•½:")
        print(f"   - ì´ í•­ëª© ìˆ˜: {summary['total_items']}")
        print(f"   - ì»¬ëŸ¼: {summary['columns']}")
        
        # ê²€ì¦
        issues = processor.validate_dataset_for_ragas(dataset)
        if issues:
            print("âš ï¸  ë°ì´í„° ê²€ì¦ ì´ìŠˆ:")
            for issue in issues:
                print(f"   - {issue}")
        else:
            print("âœ… ë°ì´í„° ê²€ì¦ í†µê³¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ DataProcessor í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False


if __name__ == "__main__":
    test_data_processor()