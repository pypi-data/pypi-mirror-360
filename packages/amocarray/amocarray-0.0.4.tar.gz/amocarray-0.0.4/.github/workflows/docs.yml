name: Test documentation build

on:
  # This will run when a pull request is merged
  pull_request:
    paths:
      - '**.py'
      - '**.ipynb'
      - '**.rst'
      - '**.md'

jobs:
  build-docs:
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
    - name: Run a one-line script
      run: echo "The job was automatically triggered by a ${{ github.event_name }} event."
    - uses: actions/checkout@v4

    - name: checkout
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    # Using channel conda-forge helps deal with pandoc installation issues
    - name: Setup Micromamba ${{ matrix.python-version }}
      uses: mamba-org/setup-micromamba@v2.0.1
      with:
        environment-name: TEST
        init-shell: bash
        create-args: >-
          python=3 pip
          --file requirements-dev.txt
          --channel conda-forge

    - name: Install pip-only tools
      shell: bash -l {0}
      run: |
        pip install black[jupyter] ruff pre-commit

    - name: Install template_project
      shell: bash -l {0}
      run: |
        python -m pip install -e . --no-deps --force-reinstall

    # Assumes that the notebook to be documented is located within notebooks/ and is called demo.ipynb
    # In the example below, we've included the `--ExecutePreprocessor.allow_errors=True` flag to allow the notebook to build even if there are errors
    # For production runs (and when your code is cleaner), you can remove this flag or set it to False.
    - name: Build documentation
      shell: bash -l {0}
      run: |
        set -e
        jupyter nbconvert --to notebook --execute notebooks/demo.ipynb --output=demo-output.ipynb --ExecutePreprocessor.allow_errors=False
        mv notebooks/*output.ipynb docs/source/
        pushd docs
        make clean html
        popd
