{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "104a9ce1-5b1d-4bbc-b689-897912ba8117",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773523e1-7bcb-48ea-98bc-3c36105b7c77",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The `pytcube.extraction` function is designed to extract localized data from a spatiotemporal `DataCube` based on observations defined in a `Dataset`. It allows users to define a buffer around each observation, resulting in smaller, more manageable data subsets known as Minicubes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e293d-2da1-459b-ace0-77730f4a4b8d",
   "metadata": {},
   "source": [
    "## Function Signature\n",
    "\n",
    "```python\n",
    "pytcube.extraction(\n",
    "    datacube: xr.Dataset,\n",
    "    dataset: xr.Dataset,\n",
    "    buffer: dict[str, int],\n",
    "    n_obs_per_batch: int,\n",
    "    optimize: bool = False,\n",
    "    path: str | Path | None = None,\n",
    "    chunk: dict[str, Any] = {'time': 1, 'lon': 'auto', 'lat': 'auto'}\n",
    ") -> list\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293cfae-3a00-4e46-9f96-360cbf90a8dc",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca13b6d-900e-4b2b-a63d-86713117358e",
   "metadata": {},
   "source": [
    "- `datacube` `(xr.Dataset)`: The input DataCube containing spatiotemporal data structured with dimensions of time, lon, and lat. This dataset should include the relevant variables for extraction.\n",
    "- `dataset` `(xr.Dataset)`: The input Dataset consisting of observations. Each observation should be associated with specific spatiotemporal coordinates.\n",
    "- `buffer` `(dict[str, int])`: A dictionary that defines the size of the buffer around each observation for the extraction. The keys should include:\n",
    "    - time: The buffer size in the time dimension.\n",
    "    - lon: The buffer size in the longitude dimension.\n",
    "    - lat: The buffer size in the latitude dimension.\n",
    "- `n_obs_per_batch` `(int)`: The number of observations to process in each extraction batch.\n",
    "- `optimize` `(bool, optional)`: A flag to indicate whether to optimize the extraction process. The default value is False.\n",
    "- `path` `(str | Path | None, optional)`: The path where the extracted data should be saved, if necessary. The default is None.\n",
    "- `chunk` `(dict[str, Any], optional)`: A dictionary that specifies the chunking strategy for the output data. The default is {'time': 1, 'lon': 'auto', 'lat': 'auto'}."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a10a7b-aa75-4fc8-a1cc-69258783365b",
   "metadata": {},
   "source": [
    "## Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a636b-b181-444a-bfaf-e5654a75a406",
   "metadata": {},
   "source": [
    "- `(list)`: A list of batches, where each batch contains the extracted Minicubes corresponding to the observations from the input Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9547e4dd-2d4d-4274-8ee6-b8f953699a4d",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a814dc5d-b335-4b50-a45d-ecfb6f34b823",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-31 15:03:43,529|INFO    |Formatting of the datacube                                                                          |datacube.py:28@_format()\n",
      "2024-10-31 15:03:43,530|INFO    |Formatting of the dataset                                                                           |dataset.py:34@_format()\n",
      "2024-10-31 15:03:43,531|INFO    |Calculation of buffer indices                                                                       |datacube.py:42@get_ibuffer()\n",
      "2024-10-31 15:03:43,533|INFO    |Setup of the DataCube and the Dataset                                                               |processing.py:44@setup()\n",
      "2024-10-31 15:03:43,547|INFO    |Processing of observations and creation of batches                                                  |processing.py:190@processing()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Delayed('batch-8ee283b5-4259-4af2-a433-1a3e1e1304e2'),\n",
       " Delayed('batch-13f1e61c-d65c-4f14-a742-d31cd5e3000c')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytcube\n",
    "from pytcube.utils import datacube, dataset\n",
    "\n",
    "# Define buffer sizes\n",
    "buffer = {\n",
    "    \"time\": 360, # in minutes\n",
    "    \"lon\": 100, # in kilometers\n",
    "    \"lat\": 100 # in kilometers\n",
    "}\n",
    "\n",
    "# Specify number of observations per batch\n",
    "n_obs_per_batch = 50\n",
    "\n",
    "# Perform extraction\n",
    "batches = pytcube.extraction(\n",
    "    datacube=datacube,\n",
    "    dataset=dataset,\n",
    "    buffer=buffer,\n",
    "    n_obs_per_batch=n_obs_per_batch\n",
    ")\n",
    "\n",
    "# Display the results\n",
    "batches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data-env]",
   "language": "python",
   "name": "conda-env-data-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
