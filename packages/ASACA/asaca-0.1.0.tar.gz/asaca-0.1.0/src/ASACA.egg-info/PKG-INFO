Metadata-Version: 2.4
Name: ASACA
Version: 0.1.0
Summary: Automatic Speech Analysis for Cognitive Assessment
Author-email: Xinbo Yang <xyang2@tcd.ie>
License: Apache-2.0
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.24
Requires-Dist: pandas>=1.5
Requires-Dist: scipy>=1.10
Requires-Dist: joblib>=1.3
Requires-Dist: tqdm>=4.66
Requires-Dist: sympy>=1.12
Requires-Dist: torch
Requires-Dist: torchvision
Requires-Dist: torchaudio
Requires-Dist: scikit-learn>=1.4
Requires-Dist: transformers>=4.38
Requires-Dist: datasets>=2.18
Requires-Dist: evaluate>=0.4
Requires-Dist: safetensors>=0.4
Requires-Dist: soundfile>=0.12
Requires-Dist: librosa>=0.10
Requires-Dist: resampy>=0.4
Requires-Dist: ctc-segmentation>=1.7
Requires-Dist: webrtcvad
Requires-Dist: praat-parselmouth>=0.4
Requires-Dist: pronouncing>=0.2
Requires-Dist: pyctcdecode>=0.5
Requires-Dist: jiwer>=3.0
Requires-Dist: pyannote.audio>=3.1
Requires-Dist: pyannote.core>=5.0
Requires-Dist: matplotlib>=3.7
Requires-Dist: pillow>=10.2
Requires-Dist: shap
Requires-Dist: psutil>=5.9
Requires-Dist: openpyxl>=3.1
Requires-Dist: nltk
Requires-Dist: PyYAML>=6.0
Requires-Dist: pyqt5
Requires-Dist: pyqtgraph
Requires-Dist: reportlab
Provides-Extra: gpu
Requires-Dist: torch; extra == "gpu"
Requires-Dist: torchaudio; extra == "gpu"
Requires-Dist: pyannote.audio; extra == "gpu"
Provides-Extra: dev
Requires-Dist: ruff; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: mypy; extra == "dev"
Requires-Dist: pytest-qt; extra == "dev"
Requires-Dist: PyQt5; extra == "dev"
Provides-Extra: docs
Requires-Dist: mkdocs-material; extra == "docs"
Requires-Dist: mkdocstrings[python]; extra == "docs"
Dynamic: license-file

# ASACA â€“ Automatic Speech Analysis for Cognitive Assessments
[![CI](https://github.com/RhysonYang-2030/ASACA-Automatic-Speech-Analysis-for-Cognitive-Assessment/actions/workflows/ci.yml/badge.svg)](../../actions) 
[![PyPI](https://img.shields.io/pypi/v/asaca?logo=pypi)](https://pypi.org/project/asaca/) 
[![License](https://img.shields.io/github/license/RhysonYang-2030/ASACA-Automatic-Speech-Analysis-for-Cognitive-Assessment)](LICENSE) 
[![Python](https://img.shields.io/badge/python-3.10%2B-blue)](#)
![GUI](docs/img/asaca_gui.gif)

ASACA is an **end-to-end toolkit** that transforms raw speech into
multimodal biomarkers â€” lexical, prosodic and pause-based â€” and returns
an interpretable prediction ( *HC / MCI / AD* ) and low Word error rate transcriptions (WER <0.02)).

---

## âœ¨ Key Features
| Capability | Detail |
|------------|--------|
| **Single-command inference** | `asaca run audio.wav` outputs JSON + PDF report |
| **Fine-tuned wav2vec 2.0 ASR** | < 2 % WER on in-domain test set |
| **Explainability** | SHAP plots per classification |
| **Rich feature set** | word-error rate, syllable rate, pause stats, spectral cues |
| **Offline-ready** | Model weights stored under `Models/` via Git LFS |
| **PEP 517/621 packaging** | `pip install asaca` or editable mode |


---

## ðŸš€ Quick start

Install the package from PyPI and run inference on a WAV file:

```bash
pip install asaca
asaca-cli infer path/to/audio.wav -o out/
```

Alternatively install in editable mode for development:

```bash
git clone https://github.com/RhysonYang-2030/ASACA-Automatic-Speech-Analysis-for-Cognitive-Assessment.git
cd ASACA-Automatic-Speech-Analysis-for-Cognitive-Assessment
pip install -e .[dev]
```

The CLI outputs recognised text along with a PDF report and JSON file in the
specified output directory.

## Usage

![Pipeline](docs/img/pipeline.png)

```text
asaca/
â”œâ”€â”€ src/             # library code
â”œâ”€â”€ tests/           # unit tests
â”œâ”€â”€ docs/            # MkDocs documentation
â”œâ”€â”€ examples/        # example notebooks and data
â””â”€â”€ notebooks/       # tutorial notebooks
```

Run `asaca-cli --help` to see all commands including feature extraction.

## Documentation
Full API reference and user guide live in the [`docs/`](docs/) directory and on [Read the Docs](https://example.com/).

## Docker

Build the image and run inference in an isolated environment:

```bash
docker build -t asaca .
docker run --rm -v "$PWD:/data" asaca asaca-cli infer /data/audio.wav
```

The container entrypoint defaults to `asaca-cli`.

## License
Released under the Apache-2.0 license.

## Citation
If you use ASACA in your research, please cite the project using the
[CITATION.cff](CITATION.cff) file.

## Contact
Maintainer: [Xinbo Yang](mailto:xyang2@tcd.ie)
