"""
Neural network submodule
"""
from __future__ import annotations
import synapx._C
import typing
__all__ = ['dropout', 'flatten', 'linear', 'log_softmax', 'mse_loss', 'nll_loss', 'relu', 'sigmoid', 'softmax']
def dropout(tensor: synapx._C.Tensor, p: float, train: bool) -> synapx._C.Tensor:
    ...
def flatten(tensor: synapx._C.Tensor, start_dim: int = 0, end_dim: int = -1) -> synapx._C.Tensor:
    ...
def linear(inp: synapx._C.Tensor, weight: synapx._C.Tensor, bias: synapx._C.Tensor | None = None) -> synapx._C.Tensor:
    ...
def log_softmax(tensor: synapx._C.Tensor, dim: int) -> synapx._C.Tensor:
    ...
def mse_loss(input: synapx._C.Tensor, target: synapx._C.Tensor, reduction: str = 'mean') -> synapx._C.Tensor:
    ...
def nll_loss(input: synapx._C.Tensor, target: synapx._C.Tensor, reduction: str = 'mean') -> synapx._C.Tensor:
    ...
def relu(tensor: synapx._C.Tensor) -> synapx._C.Tensor:
    ...
def sigmoid(tensor: synapx._C.Tensor) -> synapx._C.Tensor:
    ...
def softmax(tensor: synapx._C.Tensor, dim: int) -> synapx._C.Tensor:
    ...
