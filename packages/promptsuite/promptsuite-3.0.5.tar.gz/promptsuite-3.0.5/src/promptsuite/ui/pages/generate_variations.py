"""
Step 3: Generate Variations for PromptSuiteEngine 2.0
"""
import os
import time

import streamlit as st
from dotenv import load_dotenv

from promptsuite import PromptSuiteEngine
from promptsuite.core.template_keys import (
    PROMPT_FORMAT, INSTRUCTION
)
from promptsuite.shared.constants import GenerationDefaults, PLATFORMS_API_KEYS_VARS
from promptsuite.shared.constants import GenerationInterfaceConstants
from promptsuite.shared.model_client import get_supported_platforms, is_platform_available
from results_display import display_full_results

# Load environment variables
load_dotenv()


# Get API key from environment


def render():
    """Render the variations generation interface"""
    if not st.session_state.get('template_ready', False):
        st.error("‚ö†Ô∏è Please complete the template setup first (Step 2)")
        if st.button("‚Üê Go to Step 2"):
            st.session_state.page = 2
            st.rerun()
        return

    # Enhanced header with better styling
    st.markdown("""
    <div style="background: linear-gradient(90deg, #667eea 0%, #764ba2 100%); 
                padding: 2rem; border-radius: 10px; margin-bottom: 2rem;">
        <h1 style="color: white; margin: 0; text-align: center;">
            ‚ö° Step 3: Generate Variations
        </h1>
        <p style="color: rgba(255,255,255,0.8); text-align: center; margin: 0.5rem 0 0 0;">
            Configure settings and generate your prompt variations
        </p>
    </div>
    """, unsafe_allow_html=True)

    # Get data and template
    df = st.session_state.uploaded_data
    template = st.session_state.selected_template
    template_name = st.session_state.get('template_name', 'Custom Template')

    # Display current setup
    display_current_setup(df, template, template_name)

    # Add visual separator
    st.markdown("---")

    # Generation configuration
    configure_generation()

    # Add visual separator
    st.markdown("---")

    # Generate variations
    generate_variations_interface()


def display_current_setup(df, template, template_name):
    """Display the current data and template setup with enhanced cards"""
    st.subheader("üìã Current Setup Overview")

    col1, col2 = st.columns(2, gap="large")

    with col1:
        st.markdown("**üìä Data Summary**")

        # Metrics in a more visual way
        metric_col1, metric_col2 = st.columns(2)
        with metric_col1:
            st.metric("üìù Rows", len(df))
        with metric_col2:
            st.metric("üóÇÔ∏è Columns", len(df.columns))

    with col2:
        st.markdown(f"**üìù Template: {template_name}**")

        if isinstance(template, dict):
            # Display instruction and prompt format separately if they exist
            if INSTRUCTION in template:
                st.markdown("**Instruction:**")
                st.code(template[INSTRUCTION], language="text")
            if PROMPT_FORMAT in template:
                st.markdown("**Prompt Format:**")
                st.code(template[PROMPT_FORMAT], language="text")

            # Display the rest of the template (excluding INSTRUCTION and PROMPT_FORMAT)
            template_parts = {k: v for k, v in template.items()
                              if k not in [INSTRUCTION, PROMPT_FORMAT]}

            if template_parts:
                st.markdown("**Template Variables:**")
                # Format the dictionary nicely
                template_str = "{\n"
                for key, value in template_parts.items():
                    if isinstance(value, list):
                        template_str += f"    '{key}': {value},\n"
                    elif isinstance(value, dict):
                        template_str += f"    '{key}': {{\n"
                        for sub_key, sub_value in value.items():
                            template_str += f"        '{sub_key}': {sub_value},\n"
                        template_str += "    },\n"
                    else:
                        template_str += f"    '{key}': {value},\n"
                        template_str += "}"
                st.code(template_str, language="python")
            else:
                # Old format - just display as string
                st.code(template, language="text")


def configure_generation():
    """Configure generation settings with enhanced visual design"""
    st.subheader("‚öôÔ∏è Generation Configuration")

    # Main settings in cards
    col1, col2 = st.columns(2, gap="large")

    with col1:
        st.markdown("**üî¢ Quantity Settings**")

        # Get basic data
        df = st.session_state.uploaded_data
        max_rows = st.session_state.get('max_rows', None)

        # Use only the selected number of rows for estimation
        effective_rows = len(df) if max_rows is None else min(max_rows, len(df))

        # Variations per field setting (first position)
        variations_per_field = st.number_input(
            "üîÑ Variations per field",
            min_value=1,
            max_value=10,
            value=st.session_state.get('variations_per_field', GenerationDefaults.VARIATIONS_PER_FIELD),
            help="Number of variations to generate for each field that has variations enabled"
        )
        st.session_state.variations_per_field = variations_per_field

        # Calculate estimated_per_row after variations_per_field is set
        sp = PromptSuiteEngine()
        try:
            variation_fields = sp.parse_template(st.session_state.selected_template)
            num_variation_fields = len([f for f, v in variation_fields.items() if v is not None])

            if num_variation_fields > 0:
                # The system generates combinatorial product of all field variations
                # Each field gets variations_per_field variations, and all combinations are created
                estimated_per_row = variations_per_field ** num_variation_fields
                estimated_total = estimated_per_row * effective_rows
            else:
                estimated_per_row = 1  # No variations, just one prompt per row
                estimated_total = effective_rows
        except Exception:
            estimated_per_row = 100  # Fallback default per row
            estimated_total = estimated_per_row * effective_rows

        # Initialize max_variations_per_row with estimated_per_row if not set
        if 'max_variations_per_row' not in st.session_state:
            st.session_state.max_variations_per_row = estimated_per_row

        # Ensure current value doesn't exceed estimated_per_row
        if st.session_state.get('max_variations_per_row', 1) > estimated_per_row:
            st.session_state.max_variations_per_row = estimated_per_row

        # Use only key, let Streamlit manage the value
        max_variations_per_row = st.number_input(
            "üìä Maximum variations per row",
            min_value=1,
            max_value=estimated_per_row,
            key='max_variations_per_row',
            help=f"Maximum number of variations to generate per data row (max: {estimated_per_row:,} based on your template)"
        )

        # Max rows setting
        # Ensure max_rows is initialized before use
        if 'max_rows' not in st.session_state:
            st.session_state.max_rows = None
        max_rows_options = [("All rows (default)", None)] + [(str(i), i) for i in range(1, len(df) + 1)]
        max_rows_labels = [label for label, _ in max_rows_options]
        max_rows_values = [value for _, value in max_rows_options]

        if st.session_state.max_rows is None:
            max_rows_index = 0
        else:
            max_rows_index = max_rows_values.index(st.session_state.max_rows)

        selected_label = st.selectbox(
            "üìä Maximum rows from data to use",
            options=max_rows_labels,
            index=max_rows_index,
            key='max_rows_label',
            help="Maximum number of rows from your data to use for generation (None = all rows)"
        )
        st.session_state.max_rows = max_rows_values[max_rows_labels.index(selected_label)]

    with col2:
        st.markdown("**üé≤ Randomization Settings**")

        # Random seed setting
        random_seed = st.number_input(
            "üå± Random seed",
            min_value=None,
            max_value=None,
            value=st.session_state.get('random_seed', GenerationDefaults.RANDOM_SEED),
            help="Seed for reproducible random generation (None = random)"
        )
        st.session_state.random_seed = random_seed

        # API Configuration (only show if paraphrase is enabled)
        has_paraphrase = False
        try:
            variation_fields = sp.parse_template(st.session_state.selected_template)
            has_paraphrase = any('paraphrase' in str(v).lower() for v in variation_fields.values() if v is not None)
        except Exception:
            pass

        if has_paraphrase:
            st.markdown("**ü§ñ AI Configuration**")

            # Platform selection - now dynamic based on available platforms
            available_platforms = [p for p in get_supported_platforms() if is_platform_available(p)]

            if not available_platforms:
                st.error("‚ùå No AI platforms are available. Please install required dependencies.")
                st.info("Install dependencies: pip install anthropic google-generativeai cohere")
                return

            # Default to first available platform or user's preference
            default_platform = GenerationDefaults.API_PLATFORM if GenerationDefaults.API_PLATFORM in available_platforms else \
            available_platforms[0]

            platform = st.selectbox(
                "üåê Platform",
                available_platforms,
                index=available_platforms.index(default_platform) if default_platform in available_platforms else 0,
                help="Choose the AI platform for paraphrase generation"
            )
            st.session_state.api_platform = platform

            # Show platform status
            if is_platform_available(platform):
                st.success(f"‚úÖ {platform} is available")
            else:
                st.error(f"‚ùå {platform} is not available - missing dependencies")
                return

            API_KEY = os.getenv(PLATFORMS_API_KEYS_VARS.get(platform, None))

            # Model name with platform-specific defaults
            platform_default_model = GenerationInterfaceConstants.DEFAULT_MODELS.get(platform,
                                                                                     GenerationDefaults.MODEL_NAME)

            current_model = st.session_state.get('model_name', platform_default_model)
            model_name = st.text_input(
                "üß† Model Name",
                value=current_model,
                help=f"Name of the model to use for paraphrase generation on {platform}"
            )
            st.session_state.model_name = model_name

            # Show platform-specific model suggestions
            if platform == "OpenAI":
                st.info("üí° Popular models: gpt-4o-mini, gpt-4o, gpt-3.5-turbo")
            elif platform == "Anthropic":
                st.info("üí° Popular models: claude-3-haiku-20240307, claude-3-sonnet-20240229, claude-3-opus-20240229")
            elif platform == "Google":
                st.info("üí° Popular models: gemini-1.5-flash, gemini-1.5-pro, gemini-pro")
            elif platform == "Cohere":
                st.info("üí° Popular models: command-r-plus, command-r, command")
            elif platform == "TogetherAI":
                st.info(
                    "üí° Popular models: meta-llama/Llama-3.3-70B-Instruct-Turbo-Free, meta-llama/Llama-3.1-8B-Instruct-Turbo")

            # API Key input
            api_key = st.text_input(
                f"üîê API Key for {platform}",
                type="password",
                value=st.session_state.get('api_key', API_KEY or ''),
                help=f"Required for generating paraphrase variations using {platform}"
            )
            # Use environment API key as default if nothing entered
            st.session_state.api_key = api_key

            if not api_key:
                st.warning(
                    f"‚ö†Ô∏è API key is required for paraphrase variations. Set {PLATFORMS_API_KEYS_VARS.get(platform, 'API_KEY')} environment variable or enter it above.")

            # Show platform-specific pricing/limits info
            limits = GenerationInterfaceConstants.PLATFORM_MODEL_LIMITS.get(platform, {})
            if limits:
                st.caption(
                    f"üìä Platform limits: Max tokens: {limits.get('max_tokens', 'N/A')}, Max context: {limits.get('max_context', 'N/A')}")

        else:
            # Clear API key if not needed
            for key in ['api_key', 'api_platform', 'model_name']:
                if key in st.session_state:
                    del st.session_state[key]

    # Remove the old few-shot configuration interface
    st.session_state.generation_few_shot = None


def generate_variations_interface():
    """Enhanced interface for generating variations"""
    st.subheader("üöÄ Generate Variations")

    # Estimation in a compact info box
    df = st.session_state.uploaded_data
    max_variations_per_row = st.session_state.get('max_variations_per_row', None)
    variations_per_field = st.session_state.get('variations_per_field', GenerationDefaults.VARIATIONS_PER_FIELD)
    max_rows = st.session_state.get('max_rows', None)

    # Use only the selected number of rows for estimation
    effective_rows = len(df) if max_rows is None else min(max_rows, len(df))

    # Estimate total variations
    sp = PromptSuiteEngine()
    try:
        variation_fields = sp.parse_template(st.session_state.selected_template)
        num_variation_fields = len([f for f, v in variation_fields.items() if v is not None])

        if num_variation_fields > 0:
            if max_variations_per_row is None:
                # No limit on variations - combinatorial product (power)
                estimated_per_row = variations_per_field ** num_variation_fields
                estimated_total = estimated_per_row * effective_rows
            else:
                # Limited variations per row - use the actual max_variations_per_row value
                # But still calculate the theoretical maximum as a power
                theoretical_per_row = variations_per_field ** num_variation_fields
                estimated_per_row = min(theoretical_per_row, max_variations_per_row)
                estimated_total = estimated_per_row * effective_rows
        else:
            estimated_total = effective_rows  # No variations, just one prompt per row

        # Compact estimation display with warning for large numbers
        avg_per_row = estimated_total // effective_rows if effective_rows > 0 else 0

        if num_variation_fields > 0:
            theoretical_per_row = variations_per_field ** num_variation_fields
            if theoretical_per_row > 10000:  # Warn if theoretical calculation is very large
                st.warning(
                    f"‚ö†Ô∏è **High Variation Count:** Theoretical maximum is {theoretical_per_row:,} variations per row "
                    f"({variations_per_field}^{num_variation_fields}). "
                    f"Limited to {max_variations_per_row:,} per row to keep generation manageable."
                )
            elif theoretical_per_row > 1000:  # Info for moderately large numbers
                st.info(
                    f"üìä **Generation Estimate:** ~{estimated_total:,} variations from {effective_rows:,} rows ‚Ä¢ "
                    f"~{avg_per_row} variations per row (theoretical max: {theoretical_per_row:,})"
                )
            else:
                st.info(
                    f"üìä **Generation Estimate:** ~{estimated_total:,} variations from {effective_rows:,} rows ‚Ä¢ ~{avg_per_row} variations per row"
                )
        else:
            st.info(
                f"üìä **Generation Estimate:** ~{estimated_total:,} variations from {effective_rows:,} rows ‚Ä¢ ~{avg_per_row} variations per row"
            )

    except Exception as e:
        error_message = str(e)
        if "Not enough data for few-shot examples" in error_message:
            st.info(
                "‚ö†Ô∏è Not enough data for few-shot examples - please increase data size or reduce the number of examples")
        else:
            st.warning(f"‚ùå Could not estimate variations: {str(e)}")

    # Enhanced generation button
    col1, col2, col3 = st.columns([1, 2, 1])

    with col2:
        if st.button("üöÄ Generate All Variations", type="primary", use_container_width=True):
            generate_all_variations()

    # Show existing results if available
    if st.session_state.get('variations_generated', False):
        display_generation_results()


def generate_all_variations():
    """Generate all variations with progress tracking"""

    # Create an expandable progress container
    with st.expander("üìä Generation Progress & Details", expanded=True):
        progress_container = st.container()

        with progress_container:
            st.markdown("### üîÑ Generation in Progress...")

            # Progress bar and status
            progress_bar = st.progress(0)
            status_text = st.empty()
            details_text = st.empty()

            try:
                start_time = time.time()

                # Step 1: Initialize
                status_text.text("üîÑ Step 1/5: Initializing PromptSuiteEngine...")
                details_text.info("Setting up the generation engine with your configuration")
                progress_bar.progress(0.1)

                sp = PromptSuiteEngine(max_variations_per_row=st.session_state.get('max_variations_per_row', None))

                # Set random seed if specified
                if st.session_state.get('random_seed') is not None:
                    import random
                    random.seed(st.session_state.get('random_seed'))
                    details_text.info(f"üå± Random seed set to: {st.session_state.get('random_seed')}")

                # Step 2: Prepare data
                status_text.text("üìä Step 2/5: Preparing data...")
                progress_bar.progress(0.2)

                df = st.session_state.uploaded_data
                max_rows = st.session_state.get('max_rows', None)

                # Limit data to selected number of rows
                if max_rows is not None and max_rows < len(df):
                    df = df.head(max_rows)
                    details_text.info(
                        f"üìä Using first {max_rows} rows out of {len(st.session_state.uploaded_data)} total rows")
                else:
                    details_text.info(f"üìä Using all {len(df)} rows from your data")

                # Step 3: Configure parameters
                status_text.text("‚öôÔ∏è Step 3/5: Configuring generation parameters...")
                progress_bar.progress(0.3)

                template = st.session_state.selected_template
                variations_per_field = st.session_state.get('variations_per_field',
                                                            GenerationDefaults.VARIATIONS_PER_FIELD)
                api_key = st.session_state.get('api_key')

                # Show configuration details
                config_details = []
                # Template prompt_format is already part of the template, no need for separate prompt_format
                config_details.append(f"üîÑ Variations per field: {variations_per_field}")
                if api_key:
                    config_details.append("üîë API key configured for advanced variations")

                details_text.info(" | ".join(config_details))

                # Step 4: Generate variations
                status_text.text("‚ö° Step 4/5: Generating variations...")
                details_text.warning("ü§ñ AI is working hard to create your prompt variations...")
                progress_bar.progress(0.4)

                # Show basic progress information
                progress_details = st.empty()
                progress_details.info(f"üìä Processing {len(df)} rows...")

                # Show simple progress indicator
                row_progress = st.empty()
                row_progress.info("üîÑ Starting generation...")

                # Create simple progress callback for UI updates
                def update_ui_progress(row_idx, total_rows, variations_this_row, total_variations, eta):
                    progress_percent = (row_idx + 1) / total_rows
                    progress_bar.progress(0.4 + (progress_percent * 0.4))  # 40% to 80% of total progress
                    progress_details.info(
                        f"üìä Row {row_idx + 1}/{total_rows} ‚Ä¢ "
                        f"Variations: {variations_this_row} ‚Ä¢ "
                        f"Total: {total_variations}"
                    )
                    row_progress.info(f"üîÑ Processing row {row_idx + 1} of {total_rows}...")

                # Get model name and platform from session state
                model_name = st.session_state.get('model_name')
                api_platform = st.session_state.get('api_platform')

                variations = sp.generate_variations(
                    template=template,
                    data=df,
                    variations_per_field=variations_per_field,
                    api_key=api_key,
                    model_name=model_name,
                    api_platform=api_platform,
                    progress_callback=update_ui_progress
                )

                # Clear row progress after completion
                row_progress.empty()

                # Update progress details after generation
                progress_details.success(f"‚úÖ Generated {len(variations)} variations from {len(df)} rows")

                # Step 5: Computing statistics
                status_text.text("üìà Step 5/5: Computing statistics...")
                progress_bar.progress(0.8)
                details_text.info(f"‚ú® Generated {len(variations)} variations successfully!")

                stats = sp.get_stats(variations)

                # Complete
                progress_bar.progress(1.0)
                end_time = time.time()
                generation_time = end_time - start_time

                # Store results
                st.session_state.generated_variations = variations
                st.session_state.generation_stats = stats
                st.session_state.generation_time = generation_time
                st.session_state.variations_generated = True

                # Final success message
                status_text.text("‚úÖ Generation Complete!")
                details_text.success(
                    f"üéâ Successfully generated {len(variations)} variations in {generation_time:.1f} seconds!")

                # Add summary statistics
                st.markdown("#### üìä Quick Summary:")
                summary_col1, summary_col2, summary_col3 = st.columns(3)

                with summary_col1:
                    st.metric("Total Variations", len(variations))
                with summary_col2:
                    st.metric("Processing Time", f"{generation_time:.1f}s")
                with summary_col3:
                    avg_per_row = len(variations) / len(df) if len(df) > 0 else 0
                    st.metric("Avg per Row", f"{avg_per_row:.1f}")

                # Auto-scroll to results after a short delay
                time.sleep(1)
                st.rerun()

            except Exception as e:
                # Check if this is the few-shot examples error
                error_message = str(e)
                if "Not enough data for few-shot examples" in error_message:
                    # Handle few-shot error gracefully with single clear message
                    status_text.text("‚ö†Ô∏è Data Configuration Issue")
                    details_text.error("Cannot proceed - insufficient data for few-shot examples")
                    st.error(
                        "‚ö†Ô∏è **Cannot create few-shot examples:** Not enough data rows available. Please increase your data size or reduce the number of few-shot examples in the template configuration.")
                    return  # Stop execution for few-shot error
                else:
                    # Error handling with details
                    status_text.text("‚ùå Generation Failed")
                    details_text.error(f"‚ùå Error: {str(e)}")
                    st.error(f"‚ùå Error generating variations: {str(e)}")

                    # Show debug info outside the expander to avoid nesting
                    import traceback
                    st.text("üîç Debug Information:")
                    st.code(traceback.format_exc())


def display_generation_results():
    """Display the full results using the shared display module"""
    if not st.session_state.get('variations_generated', False):
        return

    variations = st.session_state.generated_variations
    stats = st.session_state.generation_stats
    generation_time = st.session_state.generation_time
    original_data = st.session_state.uploaded_data

    # Use the shared display function with collapsible option
    with st.container():
        # Add collapsible container for the results
        display_full_results(
            variations=variations,
            original_data=original_data,
            stats=stats,
            generation_time=generation_time,
            show_export=True,
            show_header=True
        )

    # Generation complete - no more navigation needed
    st.markdown("---")
    st.markdown("""
    <div style="background: linear-gradient(135deg, #28a745 0%, #20c997 100%); 
                padding: 1.5rem; border-radius: 10px; text-align: center; color: white; margin: 2rem 0;">
        <h3 style="margin: 0;">üéâ Generation Complete!</h3>
        <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">
            Your prompt variations are ready above. You can download them using the export options.
        </p>
    </div>
    """, unsafe_allow_html=True)
