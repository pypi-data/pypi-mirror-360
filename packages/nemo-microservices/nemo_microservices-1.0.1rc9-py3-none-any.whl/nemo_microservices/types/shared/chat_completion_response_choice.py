# File generated from our OpenAPI spec by Stainless. See CONTRIBUTING.md for details.

from typing import Optional

from ..._models import BaseModel
from .choice_logprobs import ChoiceLogprobs
from .chat_completion_message import ChatCompletionMessage

__all__ = ["ChatCompletionResponseChoice"]


class ChatCompletionResponseChoice(BaseModel):
    index: int
    """The index of the choice in the list of choices."""

    message: ChatCompletionMessage
    """A chat completion message generated by the model."""

    finish_reason: Optional[str] = None
    """The reasons why the conversation ended."""

    logprobs: Optional[ChoiceLogprobs] = None
    """Log probability information for a chat completion choice.

    This is used in both regular and streaming chat completions when logprobs=true
    is provided in the request.
    """
