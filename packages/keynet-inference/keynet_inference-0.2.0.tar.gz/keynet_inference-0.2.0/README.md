# keynet-inference

Triton Inference Server í†µí•©ê³¼ ë³´ì•ˆ í•¨ìˆ˜ ì‹¤í–‰ì„ ìœ„í•œ ì¶”ë¡  ìœ í‹¸ë¦¬í‹°

## ì„¤ì¹˜

```bash
pip install keynet-inference
```

## ì£¼ìš” ê¸°ëŠ¥

### ğŸ”Œ MLflow-Triton í†µí•©

- MLflow ëª¨ë¸ì„ Triton Inference Serverë¡œ ìë™ ë°°í¬
- Python í•¨ìˆ˜ë¥¼ Triton ëª¨ë¸ë¡œ ë³€í™˜
- S3/MinIO ê¸°ë°˜ ëª¨ë¸ ì €ì¥ì†Œ ì§€ì›

### ğŸ›¡ï¸ ë³´ì•ˆ í•¨ìˆ˜ ì‹¤í–‰

- ê²©ë¦¬ëœ ê°€ìƒí™˜ê²½ì—ì„œ ì•ˆì „í•œ ì‹¤í–‰
- ë©”ëª¨ë¦¬ ë° CPU ì‚¬ìš©ëŸ‰ ì œí•œ
- íƒ€ì„ì•„ì›ƒ ê¸°ë°˜ ì‹¤í–‰ ì œì–´

### ğŸ› ï¸ Keynet CLI

- í•¨ìˆ˜ ê²€ì¦ ë° í…ŒìŠ¤íŠ¸
- ë°°í¬ ìë™í™”
- ì¸ì¦ ê´€ë¦¬
- Python 3.9~3.12 ì§€ì›

## ì‚¬ìš© ì˜ˆì œ

### Python í•¨ìˆ˜ ì‘ì„±

```python
from keynet_inference.function import keynet_function

@keynet_function(
    python_version="3.11",
    requirements=["numpy", "pandas"],
    timeout=30
)
def process_data(args):
    """ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜"""
    data = args.get("data", [])
    result = sum(data) / len(data) if data else 0

    return {
        "result": result,
        "count": len(data)
    }
```

### CLI ì‚¬ìš©

```bash
# í•¨ìˆ˜ ê²€ì¦
keynet validate my_function.py

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
keynet test my_function.py --params '{"data": [1, 2, 3, 4, 5]}'

# ë°°í¬
keynet deploy my_function.py --name my_model

# ì¸ì¦ ê´€ë¦¬
keynet login https://api.example.com
keynet logout --all
```

### MLflow í”ŒëŸ¬ê·¸ì¸ ì‚¬ìš©

```python
import mlflow
from keynet_inference import TritonPlugin

# Tritonìœ¼ë¡œ ëª¨ë¸ ë°°í¬
mlflow.deployments.create_deployment(
    name="my-deployment",
    model_uri="models:/my_model/1",
    flavor="triton",
    config={
        "triton_url": "localhost:8001",
        "model_repository": "s3://models"
    }
)
```

## API ë¬¸ì„œ

ìì„¸í•œ API ë¬¸ì„œëŠ” [GitHub Wiki](https://github.com/WIM-Corporation/keynet/wiki) ì°¸ì¡°

## ë¼ì´ì„ ìŠ¤

MIT License
